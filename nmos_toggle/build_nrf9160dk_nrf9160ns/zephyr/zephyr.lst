
zephyr.elf:     file format elf32-littlearm


Disassembly of section rom_start:

0000c000 <_vector_start>:
    c000:	20010690 	.word	0x20010690
    c004:	0000cfed 	.word	0x0000cfed
    c008:	0000f207 	.word	0x0000f207
    c00c:	0000d01d 	.word	0x0000d01d
    c010:	0000d01d 	.word	0x0000d01d
    c014:	0000d01d 	.word	0x0000d01d
    c018:	0000d01d 	.word	0x0000d01d
    c01c:	0000d01d 	.word	0x0000d01d
	...
    c02c:	0000cf49 	.word	0x0000cf49
    c030:	0000d01d 	.word	0x0000d01d
    c034:	00000000 	.word	0x00000000
    c038:	0000cef1 	.word	0x0000cef1
    c03c:	0000f1e7 	.word	0x0000f1e7

0000c040 <_irq_vector_table>:
    c040:	0000cfad 0000cfad 0000cfad 0000cfad     ................
    c050:	0000cfad 0000cfad 0000cfad 0000cfad     ................
    c060:	0000cfad 0000cfad 0000cfad 0000cfad     ................
    c070:	0000cfad 0000cfad 0000cfad 0000cfad     ................
    c080:	0000cfad 0000cfad 0000cfad 0000cfad     ................
    c090:	0000cfad 0000cfad 0000cfad 0000cfad     ................
    c0a0:	0000cfad 0000cfad 0000cfad 0000cfad     ................
    c0b0:	0000cfad 0000cfad 0000cfad 0000cfad     ................
    c0c0:	0000cfad 0000cfad 0000cfad 0000cfad     ................
    c0d0:	0000cfad 0000cfad 0000cfad 0000cfad     ................
    c0e0:	0000cfad 0000cfad 0000cfad 0000cfad     ................
    c0f0:	0000cfad 0000cfad 0000cfad 0000cfad     ................
    c100:	0000cfad 0000cfad 0000cfad 0000cfad     ................
    c110:	0000cfad 0000cfad 0000cfad 0000cfad     ................
    c120:	0000cfad 0000cfad 0000cfad 0000cfad     ................
    c130:	0000cfad 0000cfad 0000cfad 0000cfad     ................
    c140:	0000cfad                                ....

0000c144 <_vector_end>:
	...

0000c200 <m_firmware_info>:
    c200:	281ee6de 8fcebb4c 00005b02 0000003c     ...(L....[..<...
    c210:	00003c10 00000001 0000c000 0000c000     .<..............
    c220:	9102ffff 00000000 00000000 00000000     ................
	...

Disassembly of section text:

0000c23c <__aeabi_uldivmod>:
    c23c:	b953      	cbnz	r3, c254 <__aeabi_uldivmod+0x18>
    c23e:	b94a      	cbnz	r2, c254 <__aeabi_uldivmod+0x18>
    c240:	2900      	cmp	r1, #0
    c242:	bf08      	it	eq
    c244:	2800      	cmpeq	r0, #0
    c246:	bf1c      	itt	ne
    c248:	f04f 31ff 	movne.w	r1, #4294967295	; 0xffffffff
    c24c:	f04f 30ff 	movne.w	r0, #4294967295	; 0xffffffff
    c250:	f000 b970 	b.w	c534 <__aeabi_idiv0>
    c254:	f1ad 0c08 	sub.w	ip, sp, #8
    c258:	e96d ce04 	strd	ip, lr, [sp, #-16]!
    c25c:	f000 f806 	bl	c26c <__udivmoddi4>
    c260:	f8dd e004 	ldr.w	lr, [sp, #4]
    c264:	e9dd 2302 	ldrd	r2, r3, [sp, #8]
    c268:	b004      	add	sp, #16
    c26a:	4770      	bx	lr

0000c26c <__udivmoddi4>:
    c26c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    c270:	9e09      	ldr	r6, [sp, #36]	; 0x24
    c272:	4604      	mov	r4, r0
    c274:	4689      	mov	r9, r1
    c276:	2b00      	cmp	r3, #0
    c278:	f040 8083 	bne.w	c382 <__udivmoddi4+0x116>
    c27c:	428a      	cmp	r2, r1
    c27e:	4615      	mov	r5, r2
    c280:	d945      	bls.n	c30e <__udivmoddi4+0xa2>
    c282:	fab2 f282 	clz	r2, r2
    c286:	b14a      	cbz	r2, c29c <__udivmoddi4+0x30>
    c288:	f1c2 0720 	rsb	r7, r2, #32
    c28c:	fa01 f302 	lsl.w	r3, r1, r2
    c290:	4095      	lsls	r5, r2
    c292:	4094      	lsls	r4, r2
    c294:	fa20 f707 	lsr.w	r7, r0, r7
    c298:	ea47 0903 	orr.w	r9, r7, r3
    c29c:	ea4f 4e15 	mov.w	lr, r5, lsr #16
    c2a0:	0c23      	lsrs	r3, r4, #16
    c2a2:	fa1f f885 	uxth.w	r8, r5
    c2a6:	fbb9 fcfe 	udiv	ip, r9, lr
    c2aa:	fb0e 991c 	mls	r9, lr, ip, r9
    c2ae:	fb0c f108 	mul.w	r1, ip, r8
    c2b2:	ea43 4309 	orr.w	r3, r3, r9, lsl #16
    c2b6:	4299      	cmp	r1, r3
    c2b8:	d90a      	bls.n	c2d0 <__udivmoddi4+0x64>
    c2ba:	18eb      	adds	r3, r5, r3
    c2bc:	bf2c      	ite	cs
    c2be:	2001      	movcs	r0, #1
    c2c0:	2000      	movcc	r0, #0
    c2c2:	4299      	cmp	r1, r3
    c2c4:	d902      	bls.n	c2cc <__udivmoddi4+0x60>
    c2c6:	2800      	cmp	r0, #0
    c2c8:	f000 811d 	beq.w	c506 <__udivmoddi4+0x29a>
    c2cc:	f10c 3cff 	add.w	ip, ip, #4294967295	; 0xffffffff
    c2d0:	1a59      	subs	r1, r3, r1
    c2d2:	b2a3      	uxth	r3, r4
    c2d4:	fbb1 f0fe 	udiv	r0, r1, lr
    c2d8:	fb0e 1110 	mls	r1, lr, r0, r1
    c2dc:	fb00 f808 	mul.w	r8, r0, r8
    c2e0:	ea43 4401 	orr.w	r4, r3, r1, lsl #16
    c2e4:	45a0      	cmp	r8, r4
    c2e6:	d905      	bls.n	c2f4 <__udivmoddi4+0x88>
    c2e8:	192c      	adds	r4, r5, r4
    c2ea:	d202      	bcs.n	c2f2 <__udivmoddi4+0x86>
    c2ec:	45a0      	cmp	r8, r4
    c2ee:	f200 810e 	bhi.w	c50e <__udivmoddi4+0x2a2>
    c2f2:	3801      	subs	r0, #1
    c2f4:	eba4 0408 	sub.w	r4, r4, r8
    c2f8:	ea40 400c 	orr.w	r0, r0, ip, lsl #16
    c2fc:	2700      	movs	r7, #0
    c2fe:	b11e      	cbz	r6, c308 <__udivmoddi4+0x9c>
    c300:	40d4      	lsrs	r4, r2
    c302:	2300      	movs	r3, #0
    c304:	e9c6 4300 	strd	r4, r3, [r6]
    c308:	4639      	mov	r1, r7
    c30a:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    c30e:	2a00      	cmp	r2, #0
    c310:	d051      	beq.n	c3b6 <__udivmoddi4+0x14a>
    c312:	fab2 f282 	clz	r2, r2
    c316:	2a00      	cmp	r2, #0
    c318:	f040 80af 	bne.w	c47a <__udivmoddi4+0x20e>
    c31c:	1b49      	subs	r1, r1, r5
    c31e:	ea4f 4e15 	mov.w	lr, r5, lsr #16
    c322:	fa1f f885 	uxth.w	r8, r5
    c326:	2701      	movs	r7, #1
    c328:	0c23      	lsrs	r3, r4, #16
    c32a:	fbb1 fcfe 	udiv	ip, r1, lr
    c32e:	fb0e 111c 	mls	r1, lr, ip, r1
    c332:	fb08 f00c 	mul.w	r0, r8, ip
    c336:	ea43 4301 	orr.w	r3, r3, r1, lsl #16
    c33a:	4298      	cmp	r0, r3
    c33c:	d90a      	bls.n	c354 <__udivmoddi4+0xe8>
    c33e:	18eb      	adds	r3, r5, r3
    c340:	bf2c      	ite	cs
    c342:	2101      	movcs	r1, #1
    c344:	2100      	movcc	r1, #0
    c346:	4298      	cmp	r0, r3
    c348:	d902      	bls.n	c350 <__udivmoddi4+0xe4>
    c34a:	2900      	cmp	r1, #0
    c34c:	f000 80d7 	beq.w	c4fe <__udivmoddi4+0x292>
    c350:	f10c 3cff 	add.w	ip, ip, #4294967295	; 0xffffffff
    c354:	1a19      	subs	r1, r3, r0
    c356:	b2a3      	uxth	r3, r4
    c358:	fbb1 f0fe 	udiv	r0, r1, lr
    c35c:	fb0e 1110 	mls	r1, lr, r0, r1
    c360:	fb08 f800 	mul.w	r8, r8, r0
    c364:	ea43 4401 	orr.w	r4, r3, r1, lsl #16
    c368:	45a0      	cmp	r8, r4
    c36a:	d905      	bls.n	c378 <__udivmoddi4+0x10c>
    c36c:	192c      	adds	r4, r5, r4
    c36e:	d202      	bcs.n	c376 <__udivmoddi4+0x10a>
    c370:	45a0      	cmp	r8, r4
    c372:	f200 80c1 	bhi.w	c4f8 <__udivmoddi4+0x28c>
    c376:	3801      	subs	r0, #1
    c378:	eba4 0408 	sub.w	r4, r4, r8
    c37c:	ea40 400c 	orr.w	r0, r0, ip, lsl #16
    c380:	e7bd      	b.n	c2fe <__udivmoddi4+0x92>
    c382:	428b      	cmp	r3, r1
    c384:	d908      	bls.n	c398 <__udivmoddi4+0x12c>
    c386:	2e00      	cmp	r6, #0
    c388:	d074      	beq.n	c474 <__udivmoddi4+0x208>
    c38a:	2700      	movs	r7, #0
    c38c:	e9c6 0100 	strd	r0, r1, [r6]
    c390:	4638      	mov	r0, r7
    c392:	4639      	mov	r1, r7
    c394:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    c398:	fab3 f783 	clz	r7, r3
    c39c:	b967      	cbnz	r7, c3b8 <__udivmoddi4+0x14c>
    c39e:	428b      	cmp	r3, r1
    c3a0:	f0c0 80a4 	bcc.w	c4ec <__udivmoddi4+0x280>
    c3a4:	4282      	cmp	r2, r0
    c3a6:	f240 80a1 	bls.w	c4ec <__udivmoddi4+0x280>
    c3aa:	4638      	mov	r0, r7
    c3ac:	2e00      	cmp	r6, #0
    c3ae:	d0ab      	beq.n	c308 <__udivmoddi4+0x9c>
    c3b0:	e9c6 4900 	strd	r4, r9, [r6]
    c3b4:	e7a8      	b.n	c308 <__udivmoddi4+0x9c>
    c3b6:	deff      	udf	#255	; 0xff
    c3b8:	f1c7 0520 	rsb	r5, r7, #32
    c3bc:	40bb      	lsls	r3, r7
    c3be:	fa02 fc07 	lsl.w	ip, r2, r7
    c3c2:	fa01 f407 	lsl.w	r4, r1, r7
    c3c6:	40ea      	lsrs	r2, r5
    c3c8:	fa20 f805 	lsr.w	r8, r0, r5
    c3cc:	40e9      	lsrs	r1, r5
    c3ce:	fa00 fe07 	lsl.w	lr, r0, r7
    c3d2:	431a      	orrs	r2, r3
    c3d4:	ea48 0404 	orr.w	r4, r8, r4
    c3d8:	ea4f 4812 	mov.w	r8, r2, lsr #16
    c3dc:	0c20      	lsrs	r0, r4, #16
    c3de:	fa1f f982 	uxth.w	r9, r2
    c3e2:	fbb1 faf8 	udiv	sl, r1, r8
    c3e6:	fb08 111a 	mls	r1, r8, sl, r1
    c3ea:	fb0a fb09 	mul.w	fp, sl, r9
    c3ee:	ea40 4101 	orr.w	r1, r0, r1, lsl #16
    c3f2:	458b      	cmp	fp, r1
    c3f4:	d90a      	bls.n	c40c <__udivmoddi4+0x1a0>
    c3f6:	1851      	adds	r1, r2, r1
    c3f8:	bf2c      	ite	cs
    c3fa:	2301      	movcs	r3, #1
    c3fc:	2300      	movcc	r3, #0
    c3fe:	458b      	cmp	fp, r1
    c400:	d902      	bls.n	c408 <__udivmoddi4+0x19c>
    c402:	2b00      	cmp	r3, #0
    c404:	f000 8088 	beq.w	c518 <__udivmoddi4+0x2ac>
    c408:	f10a 3aff 	add.w	sl, sl, #4294967295	; 0xffffffff
    c40c:	eba1 010b 	sub.w	r1, r1, fp
    c410:	b2a4      	uxth	r4, r4
    c412:	fbb1 f0f8 	udiv	r0, r1, r8
    c416:	fb08 1110 	mls	r1, r8, r0, r1
    c41a:	fb00 f909 	mul.w	r9, r0, r9
    c41e:	ea44 4101 	orr.w	r1, r4, r1, lsl #16
    c422:	4589      	cmp	r9, r1
    c424:	d904      	bls.n	c430 <__udivmoddi4+0x1c4>
    c426:	1851      	adds	r1, r2, r1
    c428:	d201      	bcs.n	c42e <__udivmoddi4+0x1c2>
    c42a:	4589      	cmp	r9, r1
    c42c:	d87b      	bhi.n	c526 <__udivmoddi4+0x2ba>
    c42e:	3801      	subs	r0, #1
    c430:	ea40 400a 	orr.w	r0, r0, sl, lsl #16
    c434:	eba1 0109 	sub.w	r1, r1, r9
    c438:	fba0 890c 	umull	r8, r9, r0, ip
    c43c:	4549      	cmp	r1, r9
    c43e:	4644      	mov	r4, r8
    c440:	464b      	mov	r3, r9
    c442:	d302      	bcc.n	c44a <__udivmoddi4+0x1de>
    c444:	d106      	bne.n	c454 <__udivmoddi4+0x1e8>
    c446:	45c6      	cmp	lr, r8
    c448:	d204      	bcs.n	c454 <__udivmoddi4+0x1e8>
    c44a:	3801      	subs	r0, #1
    c44c:	ebb8 040c 	subs.w	r4, r8, ip
    c450:	eb69 0302 	sbc.w	r3, r9, r2
    c454:	2e00      	cmp	r6, #0
    c456:	d05d      	beq.n	c514 <__udivmoddi4+0x2a8>
    c458:	ebbe 0204 	subs.w	r2, lr, r4
    c45c:	eb61 0103 	sbc.w	r1, r1, r3
    c460:	fa01 f505 	lsl.w	r5, r1, r5
    c464:	fa22 f307 	lsr.w	r3, r2, r7
    c468:	40f9      	lsrs	r1, r7
    c46a:	2700      	movs	r7, #0
    c46c:	431d      	orrs	r5, r3
    c46e:	e9c6 5100 	strd	r5, r1, [r6]
    c472:	e749      	b.n	c308 <__udivmoddi4+0x9c>
    c474:	4637      	mov	r7, r6
    c476:	4630      	mov	r0, r6
    c478:	e746      	b.n	c308 <__udivmoddi4+0x9c>
    c47a:	f1c2 0020 	rsb	r0, r2, #32
    c47e:	4095      	lsls	r5, r2
    c480:	fa01 f702 	lsl.w	r7, r1, r2
    c484:	fa21 f300 	lsr.w	r3, r1, r0
    c488:	ea4f 4e15 	mov.w	lr, r5, lsr #16
    c48c:	fa24 f100 	lsr.w	r1, r4, r0
    c490:	fa1f f885 	uxth.w	r8, r5
    c494:	4094      	lsls	r4, r2
    c496:	4339      	orrs	r1, r7
    c498:	fbb3 f0fe 	udiv	r0, r3, lr
    c49c:	0c0f      	lsrs	r7, r1, #16
    c49e:	fb0e 3310 	mls	r3, lr, r0, r3
    c4a2:	fb00 fc08 	mul.w	ip, r0, r8
    c4a6:	ea47 4303 	orr.w	r3, r7, r3, lsl #16
    c4aa:	459c      	cmp	ip, r3
    c4ac:	d907      	bls.n	c4be <__udivmoddi4+0x252>
    c4ae:	18eb      	adds	r3, r5, r3
    c4b0:	bf2c      	ite	cs
    c4b2:	2701      	movcs	r7, #1
    c4b4:	2700      	movcc	r7, #0
    c4b6:	459c      	cmp	ip, r3
    c4b8:	d900      	bls.n	c4bc <__udivmoddi4+0x250>
    c4ba:	b38f      	cbz	r7, c520 <__udivmoddi4+0x2b4>
    c4bc:	3801      	subs	r0, #1
    c4be:	eba3 030c 	sub.w	r3, r3, ip
    c4c2:	b289      	uxth	r1, r1
    c4c4:	fbb3 f7fe 	udiv	r7, r3, lr
    c4c8:	fb0e 3317 	mls	r3, lr, r7, r3
    c4cc:	fb07 fc08 	mul.w	ip, r7, r8
    c4d0:	ea41 4103 	orr.w	r1, r1, r3, lsl #16
    c4d4:	458c      	cmp	ip, r1
    c4d6:	d904      	bls.n	c4e2 <__udivmoddi4+0x276>
    c4d8:	1869      	adds	r1, r5, r1
    c4da:	d201      	bcs.n	c4e0 <__udivmoddi4+0x274>
    c4dc:	458c      	cmp	ip, r1
    c4de:	d825      	bhi.n	c52c <__udivmoddi4+0x2c0>
    c4e0:	3f01      	subs	r7, #1
    c4e2:	eba1 010c 	sub.w	r1, r1, ip
    c4e6:	ea47 4700 	orr.w	r7, r7, r0, lsl #16
    c4ea:	e71d      	b.n	c328 <__udivmoddi4+0xbc>
    c4ec:	1a84      	subs	r4, r0, r2
    c4ee:	eb61 0303 	sbc.w	r3, r1, r3
    c4f2:	2001      	movs	r0, #1
    c4f4:	4699      	mov	r9, r3
    c4f6:	e759      	b.n	c3ac <__udivmoddi4+0x140>
    c4f8:	3802      	subs	r0, #2
    c4fa:	442c      	add	r4, r5
    c4fc:	e73c      	b.n	c378 <__udivmoddi4+0x10c>
    c4fe:	f1ac 0c02 	sub.w	ip, ip, #2
    c502:	442b      	add	r3, r5
    c504:	e726      	b.n	c354 <__udivmoddi4+0xe8>
    c506:	f1ac 0c02 	sub.w	ip, ip, #2
    c50a:	442b      	add	r3, r5
    c50c:	e6e0      	b.n	c2d0 <__udivmoddi4+0x64>
    c50e:	3802      	subs	r0, #2
    c510:	442c      	add	r4, r5
    c512:	e6ef      	b.n	c2f4 <__udivmoddi4+0x88>
    c514:	4637      	mov	r7, r6
    c516:	e6f7      	b.n	c308 <__udivmoddi4+0x9c>
    c518:	f1aa 0a02 	sub.w	sl, sl, #2
    c51c:	4411      	add	r1, r2
    c51e:	e775      	b.n	c40c <__udivmoddi4+0x1a0>
    c520:	3802      	subs	r0, #2
    c522:	442b      	add	r3, r5
    c524:	e7cb      	b.n	c4be <__udivmoddi4+0x252>
    c526:	3802      	subs	r0, #2
    c528:	4411      	add	r1, r2
    c52a:	e781      	b.n	c430 <__udivmoddi4+0x1c4>
    c52c:	3f02      	subs	r7, #2
    c52e:	4429      	add	r1, r5
    c530:	e7d7      	b.n	c4e2 <__udivmoddi4+0x276>
    c532:	bf00      	nop

0000c534 <__aeabi_idiv0>:
    c534:	4770      	bx	lr
    c536:	bf00      	nop

0000c538 <toggle_nmos>:
#include <drivers/gpio.h>

static const struct device *gpio_dev;
static bool nmos_state = false;

void toggle_nmos() {
    c538:	b508      	push	{r3, lr}
    nmos_state = !nmos_state;
    c53a:	4b13      	ldr	r3, [pc, #76]	; (c588 <toggle_nmos+0x50>)
    c53c:	781a      	ldrb	r2, [r3, #0]
    c53e:	f082 0201 	eor.w	r2, r2, #1
    c542:	701a      	strb	r2, [r3, #0]

    if (nmos_state) {
    c544:	4b11      	ldr	r3, [pc, #68]	; (c58c <toggle_nmos+0x54>)
    c546:	6818      	ldr	r0, [r3, #0]
    c548:	68c3      	ldr	r3, [r0, #12]
    c54a:	681b      	ldr	r3, [r3, #0]
    c54c:	f403 3380 	and.w	r3, r3, #65536	; 0x10000
    c550:	b172      	cbz	r2, c570 <toggle_nmos+0x38>

	(void)cfg;
	__ASSERT((cfg->port_pin_mask & (gpio_port_pins_t)BIT(pin)) != 0U,
		 "Unsupported pin");

	if (data->invert & (gpio_port_pins_t)BIT(pin)) {
    c552:	b953      	cbnz	r3, c56a <toggle_nmos+0x32>
	return api->port_set_bits_raw(port, pins);
    c554:	6883      	ldr	r3, [r0, #8]
    c556:	68db      	ldr	r3, [r3, #12]
	return api->port_clear_bits_raw(port, pins);
    c558:	f44f 3180 	mov.w	r1, #65536	; 0x10000
    c55c:	4798      	blx	r3
        // turn on 
        printk("Setting GPIO pin to 1, %d\n", gpio_pin_set(gpio_dev, 16, 1));
    c55e:	4601      	mov	r1, r0
    c560:	480b      	ldr	r0, [pc, #44]	; (c590 <toggle_nmos+0x58>)
    }
    else {
        // turn off
        printk("Setting GPIO pin to 0, %d\n", gpio_pin_set(gpio_dev, 16, 0));
    }
}
    c562:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
        printk("Setting GPIO pin to 0, %d\n", gpio_pin_set(gpio_dev, 16, 0));
    c566:	f002 bc07 	b.w	ed78 <printk>
    c56a:	6883      	ldr	r3, [r0, #8]
    c56c:	691b      	ldr	r3, [r3, #16]
    c56e:	e7f3      	b.n	c558 <toggle_nmos+0x20>
	if (data->invert & (gpio_port_pins_t)BIT(pin)) {
    c570:	b13b      	cbz	r3, c582 <toggle_nmos+0x4a>
	return api->port_set_bits_raw(port, pins);
    c572:	6883      	ldr	r3, [r0, #8]
    c574:	68db      	ldr	r3, [r3, #12]
	return api->port_clear_bits_raw(port, pins);
    c576:	f44f 3180 	mov.w	r1, #65536	; 0x10000
    c57a:	4798      	blx	r3
    c57c:	4601      	mov	r1, r0
    c57e:	4805      	ldr	r0, [pc, #20]	; (c594 <toggle_nmos+0x5c>)
    c580:	e7ef      	b.n	c562 <toggle_nmos+0x2a>
    c582:	6883      	ldr	r3, [r0, #8]
    c584:	691b      	ldr	r3, [r3, #16]
    c586:	e7f6      	b.n	c576 <toggle_nmos+0x3e>
    c588:	20010288 	.word	0x20010288
    c58c:	20010198 	.word	0x20010198
    c590:	0000fa73 	.word	0x0000fa73
    c594:	0000fa8e 	.word	0x0000fa8e

0000c598 <main>:

void main(void)
{
    c598:	b510      	push	{r4, lr}
	if (z_syscall_trap()) {
		return (const struct device *) arch_syscall_invoke1(*(uintptr_t *)&name, K_SYSCALL_DEVICE_GET_BINDING);
	}
#endif
	compiler_barrier();
	return z_impl_device_get_binding(name);
    c59a:	480c      	ldr	r0, [pc, #48]	; (c5cc <main+0x34>)
    c59c:	f001 fc4e 	bl	de3c <z_impl_device_get_binding>
    gpio_dev = device_get_binding("GPIO_0");
    c5a0:	4a0b      	ldr	r2, [pc, #44]	; (c5d0 <main+0x38>)
	struct gpio_driver_data *data =
    c5a2:	68c4      	ldr	r4, [r0, #12]
    c5a4:	6010      	str	r0, [r2, #0]
	return api->pin_configure(port, pin, flags);
    c5a6:	6883      	ldr	r3, [r0, #8]
    c5a8:	f44f 7200 	mov.w	r2, #512	; 0x200
    c5ac:	681b      	ldr	r3, [r3, #0]
    c5ae:	2110      	movs	r1, #16
    c5b0:	4798      	blx	r3
	if (ret != 0) {
    c5b2:	b918      	cbnz	r0, c5bc <main+0x24>
		data->invert &= ~(gpio_port_pins_t)BIT(pin);
    c5b4:	6823      	ldr	r3, [r4, #0]
    c5b6:	f423 3380 	bic.w	r3, r3, #65536	; 0x10000
    c5ba:	6023      	str	r3, [r4, #0]
    gpio_pin_configure(gpio_dev, 16, GPIO_OUTPUT);

    while (true) {
        toggle_nmos();
    c5bc:	f7ff ffbc 	bl	c538 <toggle_nmos>
		parm0.val = timeout;
		return (int32_t) arch_syscall_invoke2(parm0.split.lo, parm0.split.hi, K_SYSCALL_K_SLEEP);
	}
#endif
	compiler_barrier();
	return z_impl_k_sleep(timeout);
    c5c0:	2100      	movs	r1, #0
    c5c2:	f44f 30c0 	mov.w	r0, #98304	; 0x18000
    c5c6:	f002 f835 	bl	e634 <z_impl_k_sleep>
    c5ca:	e7f7      	b.n	c5bc <main+0x24>
    c5cc:	0000fa6c 	.word	0x0000fa6c
    c5d0:	20010198 	.word	0x20010198

0000c5d4 <char_out>:

static int char_out(int c, void *ctx_p)
{
	struct out_context *ctx = ctx_p;

	ctx->count++;
    c5d4:	680b      	ldr	r3, [r1, #0]
    c5d6:	3301      	adds	r3, #1
    c5d8:	600b      	str	r3, [r1, #0]
	return _char_out(c);
    c5da:	4b01      	ldr	r3, [pc, #4]	; (c5e0 <char_out+0xc>)
    c5dc:	681b      	ldr	r3, [r3, #0]
    c5de:	4718      	bx	r3
    c5e0:	20010000 	.word	0x20010000

0000c5e4 <print_digits.part.0>:
static void print_digits(out_func_t out, void *ctx, printk_val_t num, int base,
    c5e4:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    c5e8:	b087      	sub	sp, #28
    c5ea:	460f      	mov	r7, r1
    c5ec:	4619      	mov	r1, r3
		buf[i] = "0123456789abcdef"[num % base];
    c5ee:	9b10      	ldr	r3, [sp, #64]	; 0x40
static void print_digits(out_func_t out, void *ctx, printk_val_t num, int base,
    c5f0:	4606      	mov	r6, r0
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
    c5f2:	2514      	movs	r5, #20
static void print_digits(out_func_t out, void *ctx, printk_val_t num, int base,
    c5f4:	4610      	mov	r0, r2
		buf[i] = "0123456789abcdef"[num % base];
    c5f6:	4698      	mov	r8, r3
static void print_digits(out_func_t out, void *ctx, printk_val_t num, int base,
    c5f8:	f89d b044 	ldrb.w	fp, [sp, #68]	; 0x44
    c5fc:	f89d a048 	ldrb.w	sl, [sp, #72]	; 0x48
		buf[i] = "0123456789abcdef"[num % base];
    c600:	4c1c      	ldr	r4, [pc, #112]	; (c674 <print_digits.part.0+0x90>)
    c602:	ea4f 79e3 	mov.w	r9, r3, asr #31
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
    c606:	ea50 0301 	orrs.w	r3, r0, r1
    c60a:	d11a      	bne.n	c642 <print_digits.part.0+0x5e>
	if (i == DIGITS_BUFLEN - 1) {
    c60c:	2d14      	cmp	r5, #20
		buf[i] = '0';
    c60e:	bf08      	it	eq
    c610:	2330      	moveq	r3, #48	; 0x30
	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
    c612:	9c13      	ldr	r4, [sp, #76]	; 0x4c
		i++;
    c614:	bf18      	it	ne
    c616:	3501      	addne	r5, #1
	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
    c618:	442c      	add	r4, r5
		buf[i] = '0';
    c61a:	bf08      	it	eq
    c61c:	f88d 3014 	strbeq.w	r3, [sp, #20]
	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
    c620:	2c15      	cmp	r4, #21
    c622:	d017      	beq.n	c654 <print_digits.part.0+0x70>
    c624:	3c15      	subs	r4, #21
	for (/**/; pad > 0 && pad_before; pad--) {
    c626:	2c00      	cmp	r4, #0
    c628:	dc16      	bgt.n	c658 <print_digits.part.0+0x74>
		out(buf[i], ctx);
    c62a:	f81d 0005 	ldrb.w	r0, [sp, r5]
    c62e:	4639      	mov	r1, r7
	for (/**/; i < DIGITS_BUFLEN; i++) {
    c630:	3501      	adds	r5, #1
		out(buf[i], ctx);
    c632:	47b0      	blx	r6
	for (/**/; i < DIGITS_BUFLEN; i++) {
    c634:	2d15      	cmp	r5, #21
    c636:	d1f8      	bne.n	c62a <print_digits.part.0+0x46>
	for (/**/; pad > 0; pad--) {
    c638:	2c00      	cmp	r4, #0
    c63a:	dc15      	bgt.n	c668 <print_digits.part.0+0x84>
}
    c63c:	b007      	add	sp, #28
    c63e:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
		buf[i] = "0123456789abcdef"[num % base];
    c642:	4642      	mov	r2, r8
    c644:	464b      	mov	r3, r9
    c646:	f7ff fdf9 	bl	c23c <__aeabi_uldivmod>
    c64a:	5ca3      	ldrb	r3, [r4, r2]
    c64c:	f80d 3005 	strb.w	r3, [sp, r5]
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
    c650:	3d01      	subs	r5, #1
    c652:	e7d8      	b.n	c606 <print_digits.part.0+0x22>
	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
    c654:	2400      	movs	r4, #0
    c656:	e7e8      	b.n	c62a <print_digits.part.0+0x46>
	for (/**/; pad > 0 && pad_before; pad--) {
    c658:	f1bb 0f00 	cmp.w	fp, #0
    c65c:	d0e5      	beq.n	c62a <print_digits.part.0+0x46>
		out(pad_char, ctx);
    c65e:	4639      	mov	r1, r7
    c660:	4650      	mov	r0, sl
    c662:	47b0      	blx	r6
	for (/**/; pad > 0 && pad_before; pad--) {
    c664:	3c01      	subs	r4, #1
    c666:	e7de      	b.n	c626 <print_digits.part.0+0x42>
		out(pad_char, ctx);
    c668:	4639      	mov	r1, r7
    c66a:	4650      	mov	r0, sl
    c66c:	47b0      	blx	r6
	for (/**/; pad > 0; pad--) {
    c66e:	3c01      	subs	r4, #1
    c670:	e7e2      	b.n	c638 <print_digits.part.0+0x54>
    c672:	bf00      	nop
    c674:	0000faa9 	.word	0x0000faa9

0000c678 <__printk_hook_install>:
	_char_out = fn;
    c678:	4b01      	ldr	r3, [pc, #4]	; (c680 <__printk_hook_install+0x8>)
    c67a:	6018      	str	r0, [r3, #0]
}
    c67c:	4770      	bx	lr
    c67e:	bf00      	nop
    c680:	20010000 	.word	0x20010000

0000c684 <vprintk>:
	}
}
#else
void vprintk(const char *fmt, va_list ap)
{
	struct out_context ctx = { 0 };
    c684:	2300      	movs	r3, #0
{
    c686:	b507      	push	{r0, r1, r2, lr}
#ifdef CONFIG_PRINTK_SYNC
	k_spinlock_key_t key = k_spin_lock(&lock);
#endif

	z_vprintk(char_out, &ctx, fmt, ap);
    c688:	4602      	mov	r2, r0
	struct out_context ctx = { 0 };
    c68a:	9301      	str	r3, [sp, #4]
	z_vprintk(char_out, &ctx, fmt, ap);
    c68c:	4803      	ldr	r0, [pc, #12]	; (c69c <vprintk+0x18>)
    c68e:	460b      	mov	r3, r1
    c690:	a901      	add	r1, sp, #4
    c692:	f002 fa5d 	bl	eb50 <z_vprintk>

#ifdef CONFIG_PRINTK_SYNC
	k_spin_unlock(&lock, key);
#endif
}
    c696:	b003      	add	sp, #12
    c698:	f85d fb04 	ldr.w	pc, [sp], #4
    c69c:	0000c5d5 	.word	0x0000c5d5

0000c6a0 <process_event>:
 * regions.
 */
static void process_event(struct onoff_manager *mgr,
			  int evt,
			  k_spinlock_key_t key)
{
    c6a0:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
	sys_slist_t clients;
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    c6a4:	f8b0 9018 	ldrh.w	r9, [r0, #24]
{
    c6a8:	4604      	mov	r4, r0
	__ASSERT_NO_MSG(evt != EVT_NOP);

	/* If this is a nested call record the event for processing in
	 * the top invocation.
	 */
	if (processing) {
    c6aa:	f019 0808 	ands.w	r8, r9, #8
    c6ae:	d00d      	beq.n	c6cc <process_event+0x2c>
		if (evt == EVT_COMPLETE) {
    c6b0:	2901      	cmp	r1, #1
			mgr->flags |= ONOFF_FLAG_COMPLETE;
    c6b2:	bf0c      	ite	eq
    c6b4:	f049 0910 	orreq.w	r9, r9, #16
		} else {
			__ASSERT_NO_MSG(evt == EVT_RECHECK);

			mgr->flags |= ONOFF_FLAG_RECHECK;
    c6b8:	f049 0920 	orrne.w	r9, r9, #32
    c6bc:	f8a0 9018 	strh.w	r9, [r0, #24]
	__asm__ volatile(
		"cpsie i;"
		"isb"
		: : : "memory");
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	__asm__ volatile(
    c6c0:	f382 8811 	msr	BASEPRI, r2
    c6c4:	f3bf 8f6f 	isb	sy
		state = mgr->flags & ONOFF_STATE_MASK;
	} while (evt != EVT_NOP);

out:
	k_spin_unlock(&mgr->lock, key);
}
    c6c8:	e8bd 8ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, pc}
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    c6cc:	f009 0907 	and.w	r9, r9, #7
		if (evt == EVT_RECHECK) {
    c6d0:	2902      	cmp	r1, #2
    c6d2:	d107      	bne.n	c6e4 <process_event+0x44>
			evt = process_recheck(mgr);
    c6d4:	4620      	mov	r0, r4
    c6d6:	f002 fb5c 	bl	ed92 <process_recheck>
		if (evt == EVT_NOP) {
    c6da:	2800      	cmp	r0, #0
    c6dc:	d0f0      	beq.n	c6c0 <process_event+0x20>
		if (evt == EVT_COMPLETE) {
    c6de:	2801      	cmp	r0, #1
    c6e0:	8b23      	ldrh	r3, [r4, #24]
    c6e2:	d14a      	bne.n	c77a <process_event+0xda>
			res = mgr->last_res;
    c6e4:	6967      	ldr	r7, [r4, #20]
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    c6e6:	8b23      	ldrh	r3, [r4, #24]
	if (res < 0) {
    c6e8:	2f00      	cmp	r7, #0
    c6ea:	da15      	bge.n	c718 <process_event+0x78>
		*clients = mgr->clients;
    c6ec:	6825      	ldr	r5, [r4, #0]
 * @param list A pointer on the list to initialize
 */
static inline void sys_slist_init(sys_slist_t *list)
{
	list->head = NULL;
	list->tail = NULL;
    c6ee:	e9c4 8800 	strd	r8, r8, [r4]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c6f2:	f023 0307 	bic.w	r3, r3, #7
    c6f6:	f043 0301 	orr.w	r3, r3, #1
	mgr->flags = (state & ONOFF_STATE_MASK)
    c6fa:	8323      	strh	r3, [r4, #24]
		onoff_transition_fn transit = NULL;
    c6fc:	2600      	movs	r6, #0
		bool do_monitors = (state != (mgr->flags & ONOFF_STATE_MASK))
    c6fe:	8b23      	ldrh	r3, [r4, #24]
    c700:	f003 0a07 	and.w	sl, r3, #7
				   && !sys_slist_is_empty(&mgr->monitors);
    c704:	45ca      	cmp	sl, r9
    c706:	d002      	beq.n	c70e <process_event+0x6e>
		if (do_monitors
    c708:	68a1      	ldr	r1, [r4, #8]
    c70a:	2900      	cmp	r1, #0
    c70c:	d156      	bne.n	c7bc <process_event+0x11c>
		    || !sys_slist_is_empty(&clients)
    c70e:	b90d      	cbnz	r5, c714 <process_event+0x74>
		    || (transit != NULL)) {
    c710:	2e00      	cmp	r6, #0
    c712:	d06d      	beq.n	c7f0 <process_event+0x150>
    c714:	2100      	movs	r1, #0
    c716:	e052      	b.n	c7be <process_event+0x11e>
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    c718:	f003 0107 	and.w	r1, r3, #7
		   || (state == ONOFF_STATE_RESETTING)) {
    c71c:	1f48      	subs	r0, r1, #5
	} else if ((state == ONOFF_STATE_TO_ON)
    c71e:	2801      	cmp	r0, #1
    c720:	d81c      	bhi.n	c75c <process_event+0xbc>
		*clients = mgr->clients;
    c722:	f023 0307 	bic.w	r3, r3, #7
		if (state == ONOFF_STATE_TO_ON) {
    c726:	2906      	cmp	r1, #6
		*clients = mgr->clients;
    c728:	6825      	ldr	r5, [r4, #0]
	list->head = NULL;
    c72a:	b29b      	uxth	r3, r3
	list->tail = NULL;
    c72c:	e9c4 8800 	strd	r8, r8, [r4]
		if (state == ONOFF_STATE_TO_ON) {
    c730:	d10a      	bne.n	c748 <process_event+0xa8>
			SYS_SLIST_FOR_EACH_CONTAINER(clients, cp, node) {
    c732:	b13d      	cbz	r5, c744 <process_event+0xa4>
    c734:	4628      	mov	r0, r5
    c736:	8b61      	ldrh	r1, [r4, #26]
 *
 * @return a pointer on the next node (or NULL if none)
 */
static inline sys_snode_t *sys_slist_peek_next_no_check(sys_snode_t *node);

Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
    c738:	6800      	ldr	r0, [r0, #0]
				mgr->refs += 1U;
    c73a:	3101      	adds	r1, #1
    c73c:	b289      	uxth	r1, r1
			SYS_SLIST_FOR_EACH_CONTAINER(clients, cp, node) {
    c73e:	2800      	cmp	r0, #0
    c740:	d1fa      	bne.n	c738 <process_event+0x98>
    c742:	8361      	strh	r1, [r4, #26]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c744:	f043 0302 	orr.w	r3, r3, #2
	mgr->flags = (state & ONOFF_STATE_MASK)
    c748:	8323      	strh	r3, [r4, #24]
		if (process_recheck(mgr) != EVT_NOP) {
    c74a:	4620      	mov	r0, r4
    c74c:	f002 fb21 	bl	ed92 <process_recheck>
    c750:	2800      	cmp	r0, #0
    c752:	d0d3      	beq.n	c6fc <process_event+0x5c>
			mgr->flags |= ONOFF_FLAG_RECHECK;
    c754:	8b23      	ldrh	r3, [r4, #24]
    c756:	f043 0320 	orr.w	r3, r3, #32
    c75a:	e7ce      	b.n	c6fa <process_event+0x5a>
	} else if (state == ONOFF_STATE_TO_OFF) {
    c75c:	2904      	cmp	r1, #4
    c75e:	d10a      	bne.n	c776 <process_event+0xd6>
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c760:	f023 0307 	bic.w	r3, r3, #7
    c764:	b299      	uxth	r1, r3
	mgr->flags = (state & ONOFF_STATE_MASK)
    c766:	8321      	strh	r1, [r4, #24]
		if (process_recheck(mgr) != EVT_NOP) {
    c768:	4620      	mov	r0, r4
    c76a:	f002 fb12 	bl	ed92 <process_recheck>
    c76e:	b110      	cbz	r0, c776 <process_event+0xd6>
			mgr->flags |= ONOFF_FLAG_RECHECK;
    c770:	f041 0120 	orr.w	r1, r1, #32
    c774:	8321      	strh	r1, [r4, #24]
    c776:	2500      	movs	r5, #0
    c778:	e7c0      	b.n	c6fc <process_event+0x5c>
		} else if (evt == EVT_START) {
    c77a:	2803      	cmp	r0, #3
    c77c:	d109      	bne.n	c792 <process_event+0xf2>
			transit = mgr->transitions->start;
    c77e:	6921      	ldr	r1, [r4, #16]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c780:	f023 0307 	bic.w	r3, r3, #7
			transit = mgr->transitions->start;
    c784:	680e      	ldr	r6, [r1, #0]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c786:	f043 0306 	orr.w	r3, r3, #6
	mgr->flags = (state & ONOFF_STATE_MASK)
    c78a:	2500      	movs	r5, #0
    c78c:	8323      	strh	r3, [r4, #24]
		res = 0;
    c78e:	462f      	mov	r7, r5
    c790:	e7b5      	b.n	c6fe <process_event+0x5e>
		} else if (evt == EVT_STOP) {
    c792:	2804      	cmp	r0, #4
    c794:	d106      	bne.n	c7a4 <process_event+0x104>
			transit = mgr->transitions->stop;
    c796:	6921      	ldr	r1, [r4, #16]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c798:	f023 0307 	bic.w	r3, r3, #7
			transit = mgr->transitions->stop;
    c79c:	684e      	ldr	r6, [r1, #4]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c79e:	f043 0304 	orr.w	r3, r3, #4
    c7a2:	e7f2      	b.n	c78a <process_event+0xea>
		} else if (evt == EVT_RESET) {
    c7a4:	2805      	cmp	r0, #5
    c7a6:	d106      	bne.n	c7b6 <process_event+0x116>
			transit = mgr->transitions->reset;
    c7a8:	6921      	ldr	r1, [r4, #16]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c7aa:	f023 0307 	bic.w	r3, r3, #7
			transit = mgr->transitions->reset;
    c7ae:	688e      	ldr	r6, [r1, #8]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c7b0:	f043 0305 	orr.w	r3, r3, #5
    c7b4:	e7e9      	b.n	c78a <process_event+0xea>
    c7b6:	2500      	movs	r5, #0
		onoff_transition_fn transit = NULL;
    c7b8:	462e      	mov	r6, r5
    c7ba:	e7e8      	b.n	c78e <process_event+0xee>
				   && !sys_slist_is_empty(&mgr->monitors);
    c7bc:	2101      	movs	r1, #1
			uint32_t flags = mgr->flags | ONOFF_FLAG_PROCESSING;
    c7be:	f043 0308 	orr.w	r3, r3, #8
			mgr->flags = flags;
    c7c2:	8323      	strh	r3, [r4, #24]
    c7c4:	f382 8811 	msr	BASEPRI, r2
    c7c8:	f3bf 8f6f 	isb	sy
			if (do_monitors) {
    c7cc:	b9f9      	cbnz	r1, c80e <process_event+0x16e>
	while (!sys_slist_is_empty(list)) {
    c7ce:	bb85      	cbnz	r5, c832 <process_event+0x192>
			if (transit != NULL) {
    c7d0:	b116      	cbz	r6, c7d8 <process_event+0x138>
				transit(mgr, transition_complete);
    c7d2:	4921      	ldr	r1, [pc, #132]	; (c858 <process_event+0x1b8>)
    c7d4:	4620      	mov	r0, r4
    c7d6:	47b0      	blx	r6
	__asm__ volatile(
    c7d8:	f04f 0320 	mov.w	r3, #32
    c7dc:	f3ef 8211 	mrs	r2, BASEPRI
    c7e0:	f383 8811 	msr	BASEPRI, r3
    c7e4:	f3bf 8f6f 	isb	sy
			mgr->flags &= ~ONOFF_FLAG_PROCESSING;
    c7e8:	8b23      	ldrh	r3, [r4, #24]
    c7ea:	f023 0308 	bic.w	r3, r3, #8
    c7ee:	8323      	strh	r3, [r4, #24]
		if ((mgr->flags & ONOFF_FLAG_COMPLETE) != 0) {
    c7f0:	8b23      	ldrh	r3, [r4, #24]
    c7f2:	06d9      	lsls	r1, r3, #27
    c7f4:	d527      	bpl.n	c846 <process_event+0x1a6>
			evt = EVT_COMPLETE;
    c7f6:	2101      	movs	r1, #1
			mgr->flags &= ~ONOFF_FLAG_COMPLETE;
    c7f8:	f023 0310 	bic.w	r3, r3, #16
    c7fc:	8323      	strh	r3, [r4, #24]
		state = mgr->flags & ONOFF_STATE_MASK;
    c7fe:	f8b4 9018 	ldrh.w	r9, [r4, #24]
    c802:	f009 0907 	and.w	r9, r9, #7
	} while (evt != EVT_NOP);
    c806:	2900      	cmp	r1, #0
    c808:	f47f af62 	bne.w	c6d0 <process_event+0x30>
out:
    c80c:	e758      	b.n	c6c0 <process_event+0x20>
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(mlist, mon, tmp, node) {
    c80e:	68a1      	ldr	r1, [r4, #8]
    c810:	2900      	cmp	r1, #0
    c812:	d0dc      	beq.n	c7ce <process_event+0x12e>
    c814:	f8d1 9000 	ldr.w	r9, [r1]
		mon->callback(mgr, mon, state, res);
    c818:	f8d1 b004 	ldr.w	fp, [r1, #4]
    c81c:	463b      	mov	r3, r7
    c81e:	4652      	mov	r2, sl
    c820:	4620      	mov	r0, r4
    c822:	47d8      	blx	fp
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(mlist, mon, tmp, node) {
    c824:	f1b9 0f00 	cmp.w	r9, #0
    c828:	d0d1      	beq.n	c7ce <process_event+0x12e>
    c82a:	4649      	mov	r1, r9
    c82c:	f8d9 9000 	ldr.w	r9, [r9]
    c830:	e7f2      	b.n	c818 <process_event+0x178>
 *
 * @return A pointer to the first node of the list
 */
static inline sys_snode_t *sys_slist_get_not_empty(sys_slist_t *list);

Z_GENLIST_GET_NOT_EMPTY(slist, snode)
    c832:	f8d5 9000 	ldr.w	r9, [r5]
		notify_one(mgr, cli, state, res);
    c836:	4629      	mov	r1, r5
    c838:	463b      	mov	r3, r7
    c83a:	4652      	mov	r2, sl
    c83c:	4620      	mov	r0, r4
    c83e:	f002 fac4 	bl	edca <notify_one>
	while (!sys_slist_is_empty(list)) {
    c842:	464d      	mov	r5, r9
    c844:	e7c3      	b.n	c7ce <process_event+0x12e>
		} else if ((mgr->flags & ONOFF_FLAG_RECHECK) != 0) {
    c846:	f013 0120 	ands.w	r1, r3, #32
			mgr->flags &= ~ONOFF_FLAG_RECHECK;
    c84a:	bf1e      	ittt	ne
    c84c:	f023 0320 	bicne.w	r3, r3, #32
    c850:	8323      	strhne	r3, [r4, #24]
			evt = EVT_RECHECK;
    c852:	2102      	movne	r1, #2
    c854:	e7d3      	b.n	c7fe <process_event+0x15e>
    c856:	bf00      	nop
    c858:	0000edf7 	.word	0x0000edf7

0000c85c <nordicsemi_nrf91_init>:
    c85c:	f04f 0220 	mov.w	r2, #32
    c860:	f3ef 8311 	mrs	r3, BASEPRI
    c864:	f382 8811 	msr	BASEPRI, r2
    c868:	f3bf 8f6f 	isb	sy

	key = irq_lock();

#ifdef CONFIG_NRF_ENABLE_ICACHE
	/* Enable the instruction cache */
	NRF_NVMC->ICACHECNF = NVMC_ICACHECNF_CACHEEN_Msk;
    c86c:	2101      	movs	r1, #1
    c86e:	4a04      	ldr	r2, [pc, #16]	; (c880 <nordicsemi_nrf91_init+0x24>)
    c870:	f8c2 1540 	str.w	r1, [r2, #1344]	; 0x540
	__asm__ volatile(
    c874:	f383 8811 	msr	BASEPRI, r3
    c878:	f3bf 8f6f 	isb	sy
	NMI_INIT();

	irq_unlock(key);

	return 0;
}
    c87c:	2000      	movs	r0, #0
    c87e:	4770      	bx	lr
    c880:	40039000 	.word	0x40039000

0000c884 <arch_busy_wait>:

#else // NRFX_CHECK(NRFX_DELAY_DWT_BASED)

NRF_STATIC_INLINE void nrfx_coredep_delay_us(uint32_t time_us)
{
    if (time_us == 0)
    c884:	b120      	cbz	r0, c890 <arch_busy_wait+0xc>
    };

    typedef void (* delay_func_t)(uint32_t);
    const delay_func_t delay_cycles =
        // Set LSB to 1 to execute the code in the Thumb mode.
        (delay_func_t)((((uint32_t)delay_machine_code) | 1));
    c886:	4b03      	ldr	r3, [pc, #12]	; (c894 <arch_busy_wait+0x10>)
    uint32_t cycles = time_us * NRFX_DELAY_CPU_FREQ_MHZ;
    delay_cycles(cycles);
    c888:	0180      	lsls	r0, r0, #6
    c88a:	f043 0301 	orr.w	r3, r3, #1
    c88e:	4718      	bx	r3

void arch_busy_wait(uint32_t time_us)
{
	nrfx_coredep_delay_us(time_us);
}
    c890:	4770      	bx	lr
    c892:	bf00      	nop
    c894:	0000f9a0 	.word	0x0000f9a0

0000c898 <uart_console_init>:
 * @brief Initialize one UART as the console/debug port
 *
 * @return 0 if successful, otherwise failed.
 */
static int uart_console_init(const struct device *arg)
{
    c898:	b510      	push	{r4, lr}
    c89a:	4807      	ldr	r0, [pc, #28]	; (c8b8 <uart_console_init+0x20>)
    c89c:	f001 face 	bl	de3c <z_impl_device_get_binding>
	__stdout_hook_install(console_out);
    c8a0:	4c06      	ldr	r4, [pc, #24]	; (c8bc <uart_console_init+0x24>)

	ARG_UNUSED(arg);

	/* Claim console device */
	uart_console_dev = device_get_binding(CONFIG_UART_CONSOLE_ON_DEV_NAME);
    c8a2:	4b07      	ldr	r3, [pc, #28]	; (c8c0 <uart_console_init+0x28>)
    c8a4:	6018      	str	r0, [r3, #0]
	__stdout_hook_install(console_out);
    c8a6:	4620      	mov	r0, r4
    c8a8:	f000 fe64 	bl	d574 <__stdout_hook_install>
	__printk_hook_install(console_out);
    c8ac:	4620      	mov	r0, r4
    c8ae:	f7ff fee3 	bl	c678 <__printk_hook_install>

	uart_console_hook_install();

	return 0;
}
    c8b2:	2000      	movs	r0, #0
    c8b4:	bd10      	pop	{r4, pc}
    c8b6:	bf00      	nop
    c8b8:	0000faba 	.word	0x0000faba
    c8bc:	0000c8c5 	.word	0x0000c8c5
    c8c0:	2001019c 	.word	0x2001019c

0000c8c4 <console_out>:
	if ('\n' == c) {
    c8c4:	280a      	cmp	r0, #10
{
    c8c6:	b538      	push	{r3, r4, r5, lr}
    c8c8:	4604      	mov	r4, r0
    c8ca:	4d07      	ldr	r5, [pc, #28]	; (c8e8 <console_out+0x24>)
	if ('\n' == c) {
    c8cc:	d104      	bne.n	c8d8 <console_out+0x14>
    c8ce:	6828      	ldr	r0, [r5, #0]
						unsigned char out_char)
{
	const struct uart_driver_api *api =
		(const struct uart_driver_api *)dev->api;

	api->poll_out(dev, out_char);
    c8d0:	6883      	ldr	r3, [r0, #8]
    c8d2:	210d      	movs	r1, #13
    c8d4:	685b      	ldr	r3, [r3, #4]
    c8d6:	4798      	blx	r3
	uart_poll_out(uart_console_dev, c);
    c8d8:	6828      	ldr	r0, [r5, #0]
    c8da:	6883      	ldr	r3, [r0, #8]
    c8dc:	b2e1      	uxtb	r1, r4
    c8de:	685b      	ldr	r3, [r3, #4]
    c8e0:	4798      	blx	r3
}
    c8e2:	4620      	mov	r0, r4
    c8e4:	bd38      	pop	{r3, r4, r5, pc}
    c8e6:	bf00      	nop
    c8e8:	2001019c 	.word	0x2001019c

0000c8ec <onoff_stop>:
}

static clock_control_subsys_t get_subsys(struct onoff_manager *mgr)
{
	struct nrf_clock_control_data *data = DEVICE_GET(clock_nrf)->data;
	size_t offset = (size_t)(mgr - data->mgr);
    c8ec:	4a0e      	ldr	r2, [pc, #56]	; (c928 <onoff_stop+0x3c>)
	return (clock_control_subsys_t)offset;
}

static void onoff_stop(struct onoff_manager *mgr,
			onoff_notify_fn notify)
{
    c8ee:	b570      	push	{r4, r5, r6, lr}
	size_t offset = (size_t)(mgr - data->mgr);
    c8f0:	1a84      	subs	r4, r0, r2
{
    c8f2:	4605      	mov	r5, r0
	err = set_off_state(&subdata->flags, ctx);
    c8f4:	200c      	movs	r0, #12
{
    c8f6:	460e      	mov	r6, r1
	err = set_off_state(&subdata->flags, ctx);
    c8f8:	2140      	movs	r1, #64	; 0x40
	size_t offset = (size_t)(mgr - data->mgr);
    c8fa:	10a3      	asrs	r3, r4, #2
    c8fc:	4c0b      	ldr	r4, [pc, #44]	; (c92c <onoff_stop+0x40>)
    c8fe:	435c      	muls	r4, r3
    c900:	b2e4      	uxtb	r4, r4
	err = set_off_state(&subdata->flags, ctx);
    c902:	fb00 2004 	mla	r0, r0, r4, r2
    c906:	4408      	add	r0, r1
    c908:	f002 fbdf 	bl	f0ca <set_off_state>
	if (err < 0) {
    c90c:	1e01      	subs	r1, r0, #0
    c90e:	db05      	blt.n	c91c <onoff_stop+0x30>
	get_sub_config(dev, type)->stop();
    c910:	4b07      	ldr	r3, [pc, #28]	; (c930 <onoff_stop+0x44>)
    c912:	eb03 04c4 	add.w	r4, r3, r4, lsl #3
    c916:	6863      	ldr	r3, [r4, #4]
    c918:	4798      	blx	r3
	return 0;
    c91a:	2100      	movs	r1, #0
	int res;

	res = stop(DEVICE_GET(clock_nrf), get_subsys(mgr), CTX_ONOFF);
	notify(mgr, res);
    c91c:	4628      	mov	r0, r5
    c91e:	4633      	mov	r3, r6
}
    c920:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
	notify(mgr, res);
    c924:	4718      	bx	r3
    c926:	bf00      	nop
    c928:	200101b0 	.word	0x200101b0
    c92c:	b6db6db7 	.word	0xb6db6db7
    c930:	0000f9bc 	.word	0x0000f9bc

0000c934 <onoff_start>:
	notify(mgr, 0);
}

static void onoff_start(struct onoff_manager *mgr,
			onoff_notify_fn notify)
{
    c934:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	err = set_starting_state(&subdata->flags, ctx);
    c938:	250c      	movs	r5, #12
	size_t offset = (size_t)(mgr - data->mgr);
    c93a:	4e10      	ldr	r6, [pc, #64]	; (c97c <onoff_start+0x48>)
{
    c93c:	4680      	mov	r8, r0
	size_t offset = (size_t)(mgr - data->mgr);
    c93e:	1b84      	subs	r4, r0, r6
    c940:	10a3      	asrs	r3, r4, #2
    c942:	4c0f      	ldr	r4, [pc, #60]	; (c980 <onoff_start+0x4c>)
{
    c944:	460f      	mov	r7, r1
	size_t offset = (size_t)(mgr - data->mgr);
    c946:	435c      	muls	r4, r3
    c948:	b2e4      	uxtb	r4, r4
	err = set_starting_state(&subdata->flags, ctx);
    c94a:	4365      	muls	r5, r4
    c94c:	f105 0040 	add.w	r0, r5, #64	; 0x40
    c950:	2140      	movs	r1, #64	; 0x40
    c952:	4430      	add	r0, r6
    c954:	f002 fbd2 	bl	f0fc <set_starting_state>
	if (err < 0) {
    c958:	1e01      	subs	r1, r0, #0
    c95a:	db09      	blt.n	c970 <onoff_start+0x3c>
	subdata->cb = data->cb;
    c95c:	4a09      	ldr	r2, [pc, #36]	; (c984 <onoff_start+0x50>)
    c95e:	1973      	adds	r3, r6, r5
	subdata->user_data = data->user_data;
    c960:	e9c3 270e 	strd	r2, r7, [r3, #56]	; 0x38
	 get_sub_config(dev, type)->start();
    c964:	4b08      	ldr	r3, [pc, #32]	; (c988 <onoff_start+0x54>)
    c966:	f853 3034 	ldr.w	r3, [r3, r4, lsl #3]
	err = async_start(DEVICE_GET(clock_nrf), get_subsys(mgr),
			  &data, CTX_ONOFF);
	if (err < 0) {
		notify(mgr, err);
	}
}
    c96a:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
	 get_sub_config(dev, type)->start();
    c96e:	4718      	bx	r3
		notify(mgr, err);
    c970:	4640      	mov	r0, r8
    c972:	463b      	mov	r3, r7
}
    c974:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
		notify(mgr, err);
    c978:	4718      	bx	r3
    c97a:	bf00      	nop
    c97c:	200101b0 	.word	0x200101b0
    c980:	b6db6db7 	.word	0xb6db6db7
    c984:	0000f15f 	.word	0x0000f15f
    c988:	0000f9bc 	.word	0x0000f9bc

0000c98c <clk_init>:
		break;
	}
}

static int clk_init(const struct device *dev)
{
    c98c:	b570      	push	{r4, r5, r6, lr}
	static const struct onoff_transitions transitions = {
		.start = onoff_start,
		.stop = onoff_stop
	};

	IRQ_CONNECT(DT_INST_IRQN(0), DT_INST_IRQ(0, priority),
    c98e:	2200      	movs	r2, #0
    c990:	2101      	movs	r1, #1
{
    c992:	4604      	mov	r4, r0
	IRQ_CONNECT(DT_INST_IRQN(0), DT_INST_IRQ(0, priority),
    c994:	2005      	movs	r0, #5
    c996:	f000 fa3b 	bl	ce10 <z_arm_irq_priority_set>
		    nrfx_isr, nrfx_power_clock_irq_handler, 0);
	irq_enable(DT_INST_IRQN(0));
    c99a:	2005      	movs	r0, #5
    c99c:	f000 fa1a 	bl	cdd4 <arch_irq_enable>
					NRF_GPIO_PIN_MCUSEL_PERIPHERAL);
		nrf_gpio_pin_mcu_select(PIN_XL2,
					NRF_GPIO_PIN_MCUSEL_PERIPHERAL);
	}
#endif
	nrfx_err = nrfx_clock_init(clock_event_handler);
    c9a0:	480f      	ldr	r0, [pc, #60]	; (c9e0 <clk_init+0x54>)
    c9a2:	f001 f957 	bl	dc54 <nrfx_clock_init>
	if (nrfx_err != NRFX_SUCCESS) {
    c9a6:	4b0f      	ldr	r3, [pc, #60]	; (c9e4 <clk_init+0x58>)
    c9a8:	4298      	cmp	r0, r3
    c9aa:	d115      	bne.n	c9d8 <clk_init+0x4c>
		struct nrf_clock_control_data *data = dev->data;

		z_nrf_clock_calibration_init(data->mgr);
	}

	nrfx_clock_enable();
    c9ac:	f002 fd7e 	bl	f4ac <nrfx_clock_enable>

	for (enum clock_control_nrf_type i = 0;
		i < CLOCK_CONTROL_NRF_TYPE_COUNT; i++) {
		struct nrf_clock_control_sub_data *subdata =
						get_sub_data(dev, i);
    c9b0:	68e6      	ldr	r6, [r4, #12]

		err = onoff_manager_init(get_onoff_manager(dev, i),
    c9b2:	490d      	ldr	r1, [pc, #52]	; (c9e8 <clk_init+0x5c>)
    c9b4:	4630      	mov	r0, r6
    c9b6:	f002 fa3b 	bl	ee30 <onoff_manager_init>
					 &transitions);
		if (err < 0) {
    c9ba:	2800      	cmp	r0, #0
    c9bc:	db0b      	blt.n	c9d6 <clk_init+0x4a>
			return err;
		}

		subdata->flags = CLOCK_CONTROL_STATUS_OFF;
    c9be:	2501      	movs	r5, #1
    c9c0:	6435      	str	r5, [r6, #64]	; 0x40
						get_sub_data(dev, i);
    c9c2:	68e4      	ldr	r4, [r4, #12]
		err = onoff_manager_init(get_onoff_manager(dev, i),
    c9c4:	4908      	ldr	r1, [pc, #32]	; (c9e8 <clk_init+0x5c>)
    c9c6:	f104 001c 	add.w	r0, r4, #28
    c9ca:	f002 fa31 	bl	ee30 <onoff_manager_init>
		if (err < 0) {
    c9ce:	2800      	cmp	r0, #0
    c9d0:	db01      	blt.n	c9d6 <clk_init+0x4a>
	}

	return 0;
    c9d2:	2000      	movs	r0, #0
		subdata->flags = CLOCK_CONTROL_STATUS_OFF;
    c9d4:	64e5      	str	r5, [r4, #76]	; 0x4c
}
    c9d6:	bd70      	pop	{r4, r5, r6, pc}
		return -EIO;
    c9d8:	f06f 0004 	mvn.w	r0, #4
    c9dc:	e7fb      	b.n	c9d6 <clk_init+0x4a>
    c9de:	bf00      	nop
    c9e0:	0000ca85 	.word	0x0000ca85
    c9e4:	0bad0000 	.word	0x0bad0000
    c9e8:	0000f9cc 	.word	0x0000f9cc

0000c9ec <clkstarted_handle.constprop.10>:
static void clkstarted_handle(const struct device *dev,
    c9ec:	4601      	mov	r1, r0
	clock_control_cb_t callback = sub_data->cb;
    c9ee:	230c      	movs	r3, #12
	sub_data->cb = NULL;
    c9f0:	2200      	movs	r2, #0
	clock_control_cb_t callback = sub_data->cb;
    c9f2:	434b      	muls	r3, r1
    c9f4:	4808      	ldr	r0, [pc, #32]	; (ca18 <clkstarted_handle.constprop.10+0x2c>)
static void clkstarted_handle(const struct device *dev,
    c9f6:	b570      	push	{r4, r5, r6, lr}
	clock_control_cb_t callback = sub_data->cb;
    c9f8:	18c4      	adds	r4, r0, r3
	set_on_state(&sub_data->flags);
    c9fa:	3340      	adds	r3, #64	; 0x40
	void *user_data = sub_data->user_data;
    c9fc:	e9d4 560e 	ldrd	r5, r6, [r4, #56]	; 0x38
	set_on_state(&sub_data->flags);
    ca00:	4418      	add	r0, r3
	sub_data->cb = NULL;
    ca02:	63a2      	str	r2, [r4, #56]	; 0x38
	set_on_state(&sub_data->flags);
    ca04:	f002 fb98 	bl	f138 <set_on_state>
	if (callback) {
    ca08:	b12d      	cbz	r5, ca16 <clkstarted_handle.constprop.10+0x2a>
		callback(dev, (clock_control_subsys_t)type, user_data);
    ca0a:	4632      	mov	r2, r6
    ca0c:	462b      	mov	r3, r5
}
    ca0e:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
		callback(dev, (clock_control_subsys_t)type, user_data);
    ca12:	4802      	ldr	r0, [pc, #8]	; (ca1c <clkstarted_handle.constprop.10+0x30>)
    ca14:	4718      	bx	r3
}
    ca16:	bd70      	pop	{r4, r5, r6, pc}
    ca18:	200101b0 	.word	0x200101b0
    ca1c:	2001003c 	.word	0x2001003c

0000ca20 <generic_hfclk_start>:
{
    ca20:	b508      	push	{r3, lr}
	__asm__ volatile(
    ca22:	f04f 0320 	mov.w	r3, #32
    ca26:	f3ef 8111 	mrs	r1, BASEPRI
    ca2a:	f383 8811 	msr	BASEPRI, r3
    ca2e:	f3bf 8f6f 	isb	sy
	hfclk_users |= HF_USER_GENERIC;
    ca32:	4a11      	ldr	r2, [pc, #68]	; (ca78 <generic_hfclk_start+0x58>)
    ca34:	6813      	ldr	r3, [r2, #0]
    ca36:	f043 0002 	orr.w	r0, r3, #2
	if (hfclk_users & HF_USER_BT) {
    ca3a:	f013 0301 	ands.w	r3, r3, #1
	hfclk_users |= HF_USER_GENERIC;
    ca3e:	6010      	str	r0, [r2, #0]
	if (hfclk_users & HF_USER_BT) {
    ca40:	d00b      	beq.n	ca5a <generic_hfclk_start+0x3a>
            break;
        case NRF_CLOCK_DOMAIN_HFCLK:
            if (p_clk_src != NULL)
            {
                (*(nrf_clock_hfclk_t *)p_clk_src) =
                    (nrf_clock_hfclk_t)((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_SRC_Msk)
    ca42:	4a0e      	ldr	r2, [pc, #56]	; (ca7c <generic_hfclk_start+0x5c>)
    ca44:	f8d2 340c 	ldr.w	r3, [r2, #1036]	; 0x40c
                                        >> CLOCK_HFCLKSTAT_SRC_Pos);
            }
            if ((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_STATE_Msk)
    ca48:	f8d2 240c 	ldr.w	r2, [r2, #1036]	; 0x40c
		if (type == NRF_CLOCK_HFCLK_HIGH_ACCURACY) {
    ca4c:	f013 0301 	ands.w	r3, r3, #1
    ca50:	d003      	beq.n	ca5a <generic_hfclk_start+0x3a>
			set_on_state(get_hf_flags());
    ca52:	480b      	ldr	r0, [pc, #44]	; (ca80 <generic_hfclk_start+0x60>)
    ca54:	f002 fb70 	bl	f138 <set_on_state>
			already_started = true;
    ca58:	2301      	movs	r3, #1
	__asm__ volatile(
    ca5a:	f381 8811 	msr	BASEPRI, r1
    ca5e:	f3bf 8f6f 	isb	sy
	if (already_started) {
    ca62:	b123      	cbz	r3, ca6e <generic_hfclk_start+0x4e>
}
    ca64:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
		clkstarted_handle(DEVICE_GET(clock_nrf),
    ca68:	2000      	movs	r0, #0
    ca6a:	f7ff bfbf 	b.w	c9ec <clkstarted_handle.constprop.10>
    nrfx_clock_stop(NRF_CLOCK_DOMAIN_LFCLK);
}

NRFX_STATIC_INLINE void nrfx_clock_hfclk_start(void)
{
    nrfx_clock_start(NRF_CLOCK_DOMAIN_HFCLK);
    ca6e:	2001      	movs	r0, #1
}
    ca70:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
    ca74:	f001 b8fe 	b.w	dc74 <nrfx_clock_start>
    ca78:	20010200 	.word	0x20010200
    ca7c:	40005000 	.word	0x40005000
    ca80:	200101f0 	.word	0x200101f0

0000ca84 <clock_event_handler>:
	switch (event) {
    ca84:	b110      	cbz	r0, ca8c <clock_event_handler+0x8>
    ca86:	2801      	cmp	r0, #1
    ca88:	d004      	beq.n	ca94 <clock_event_handler+0x10>
    ca8a:	4770      	bx	lr
		if (GET_STATUS(data->flags) == CLOCK_CONTROL_STATUS_STARTING) {
    ca8c:	4b03      	ldr	r3, [pc, #12]	; (ca9c <clock_event_handler+0x18>)
    ca8e:	6c1b      	ldr	r3, [r3, #64]	; 0x40
    ca90:	075b      	lsls	r3, r3, #29
    ca92:	d101      	bne.n	ca98 <clock_event_handler+0x14>
		clkstarted_handle(dev, CLOCK_CONTROL_NRF_TYPE_LFCLK);
    ca94:	f7ff bfaa 	b.w	c9ec <clkstarted_handle.constprop.10>
}
    ca98:	4770      	bx	lr
    ca9a:	bf00      	nop
    ca9c:	200101b0 	.word	0x200101b0

0000caa0 <generic_hfclk_stop>:
 * @return Previous value of @a target.
 */
#ifdef CONFIG_ATOMIC_OPERATIONS_BUILTIN
static inline atomic_val_t atomic_and(atomic_t *target, atomic_val_t value)
{
	return __atomic_fetch_and(target, value, __ATOMIC_SEQ_CST);
    caa0:	4b07      	ldr	r3, [pc, #28]	; (cac0 <generic_hfclk_stop+0x20>)
    caa2:	e8d3 2fef 	ldaex	r2, [r3]
    caa6:	f022 0102 	bic.w	r1, r2, #2
    caaa:	e8c3 1fe0 	stlex	r0, r1, [r3]
    caae:	2800      	cmp	r0, #0
    cab0:	d1f7      	bne.n	caa2 <generic_hfclk_stop+0x2>
	if (atomic_and(&hfclk_users, ~HF_USER_GENERIC) & HF_USER_BT) {
    cab2:	07d3      	lsls	r3, r2, #31
    cab4:	d402      	bmi.n	cabc <generic_hfclk_stop+0x1c>
}

NRFX_STATIC_INLINE void nrfx_clock_hfclk_stop(void)
{
    nrfx_clock_stop(NRF_CLOCK_DOMAIN_HFCLK);
    cab6:	2001      	movs	r0, #1
    cab8:	f001 b90e 	b.w	dcd8 <nrfx_clock_stop>
}
    cabc:	4770      	bx	lr
    cabe:	bf00      	nop
    cac0:	20010200 	.word	0x20010200

0000cac4 <api_blocking_start>:
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    cac4:	2300      	movs	r3, #0
    cac6:	2201      	movs	r2, #1
{
    cac8:	b510      	push	{r4, lr}
    caca:	b088      	sub	sp, #32
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    cacc:	e9cd 3206 	strd	r3, r2, [sp, #24]
	struct clock_control_async_data data = {
    cad0:	9301      	str	r3, [sp, #4]
    cad2:	4b09      	ldr	r3, [pc, #36]	; (caf8 <api_blocking_start+0x34>)
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    cad4:	ac04      	add	r4, sp, #16
	err = api_start(dev, subsys, &data);
    cad6:	aa01      	add	r2, sp, #4
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    cad8:	e9cd 4404 	strd	r4, r4, [sp, #16]
	struct clock_control_async_data data = {
    cadc:	e9cd 3402 	strd	r3, r4, [sp, #8]
	err = api_start(dev, subsys, &data);
    cae0:	f002 fb63 	bl	f1aa <api_start>
	if (err < 0) {
    cae4:	2800      	cmp	r0, #0
    cae6:	db05      	blt.n	caf4 <api_blocking_start+0x30>
		parm0.val = timeout;
		return (int) arch_syscall_invoke3(*(uintptr_t *)&sem, parm0.split.lo, parm0.split.hi, K_SYSCALL_K_SEM_TAKE);
	}
#endif
	compiler_barrier();
	return z_impl_k_sem_take(sem, timeout);
    cae8:	f44f 4280 	mov.w	r2, #16384	; 0x4000
    caec:	2300      	movs	r3, #0
    caee:	4620      	mov	r0, r4
    caf0:	f001 fde6 	bl	e6c0 <z_impl_k_sem_take>
}
    caf4:	b008      	add	sp, #32
    caf6:	bd10      	pop	{r4, pc}
    caf8:	0000f171 	.word	0x0000f171

0000cafc <z_nrf_clock_control_lf_on>:
{
    cafc:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
	return __atomic_exchange_n(target, value, __ATOMIC_SEQ_CST);
    cb00:	2201      	movs	r2, #1
    cb02:	4606      	mov	r6, r0
    cb04:	4934      	ldr	r1, [pc, #208]	; (cbd8 <z_nrf_clock_control_lf_on+0xdc>)
    cb06:	e8d1 3fef 	ldaex	r3, [r1]
    cb0a:	e8c1 2fe0 	stlex	r0, r2, [r1]
    cb0e:	2800      	cmp	r0, #0
    cb10:	d1f9      	bne.n	cb06 <z_nrf_clock_control_lf_on+0xa>
	if (atomic_set(&on, 1) == 0) {
    cb12:	b933      	cbnz	r3, cb22 <z_nrf_clock_control_lf_on+0x26>
 */
static inline void sys_notify_init_spinwait(struct sys_notify *notify)
{
	__ASSERT_NO_MSG(notify != NULL);

	*notify = (struct sys_notify){
    cb14:	4931      	ldr	r1, [pc, #196]	; (cbdc <z_nrf_clock_control_lf_on+0xe0>)
		err = onoff_request(mgr, &cli);
    cb16:	4832      	ldr	r0, [pc, #200]	; (cbe0 <z_nrf_clock_control_lf_on+0xe4>)
    cb18:	604b      	str	r3, [r1, #4]
    cb1a:	60cb      	str	r3, [r1, #12]
    cb1c:	608a      	str	r2, [r1, #8]
    cb1e:	f002 f99a 	bl	ee56 <onoff_request>
	switch (start_mode) {
    cb22:	1e73      	subs	r3, r6, #1
    cb24:	2b01      	cmp	r3, #1
    cb26:	d82c      	bhi.n	cb82 <z_nrf_clock_control_lf_on+0x86>
	if ((mode == CLOCK_CONTROL_NRF_LF_START_AVAILABLE) &&
    cb28:	2e01      	cmp	r6, #1
    cb2a:	d106      	bne.n	cb3a <z_nrf_clock_control_lf_on+0x3e>
    return clk_src;
}

NRF_STATIC_INLINE nrf_clock_lfclk_t nrf_clock_lf_srccopy_get(NRF_CLOCK_Type const * p_reg)
{
    return (nrf_clock_lfclk_t)((p_reg->LFCLKSRCCOPY & CLOCK_LFCLKSRCCOPY_SRC_Msk)
    cb2c:	4b2d      	ldr	r3, [pc, #180]	; (cbe4 <z_nrf_clock_control_lf_on+0xe8>)
    cb2e:	f8d3 341c 	ldr.w	r3, [r3, #1052]	; 0x41c
	    (target_type == NRF_CLOCK_LFCLK_Xtal) &&
    cb32:	f003 0303 	and.w	r3, r3, #3
    cb36:	2b02      	cmp	r3, #2
    cb38:	d023      	beq.n	cb82 <z_nrf_clock_control_lf_on+0x86>
	bool isr_mode = k_is_in_isr() || k_is_pre_kernel();
    cb3a:	f002 fd85 	bl	f648 <k_is_in_isr>
    cb3e:	b918      	cbnz	r0, cb48 <z_nrf_clock_control_lf_on+0x4c>
 */
static inline bool k_is_pre_kernel(void)
{
	extern bool z_sys_post_kernel; /* in init.c */

	return !z_sys_post_kernel;
    cb40:	4b29      	ldr	r3, [pc, #164]	; (cbe8 <z_nrf_clock_control_lf_on+0xec>)
	int key = isr_mode ? irq_lock() : 0;
    cb42:	781b      	ldrb	r3, [r3, #0]
    cb44:	2b00      	cmp	r3, #0
    cb46:	d140      	bne.n	cbca <z_nrf_clock_control_lf_on+0xce>
	__asm__ volatile(
    cb48:	f04f 0320 	mov.w	r3, #32
    cb4c:	f3ef 8911 	mrs	r9, BASEPRI
    cb50:	f383 8811 	msr	BASEPRI, r3
    cb54:	f3bf 8f6f 	isb	sy
    cb58:	2401      	movs	r4, #1
                    (nrf_clock_lfclk_t)((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_SRC_Msk)
    cb5a:	4d22      	ldr	r5, [pc, #136]	; (cbe4 <z_nrf_clock_control_lf_on+0xe8>)
    return (bool)*((volatile uint32_t *)((uint8_t *)p_reg + event));
    cb5c:	4f23      	ldr	r7, [pc, #140]	; (cbec <z_nrf_clock_control_lf_on+0xf0>)
    cb5e:	46a8      	mov	r8, r5
                    (nrf_clock_lfclk_t)((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_SRC_Msk)
    cb60:	f8d5 3418 	ldr.w	r3, [r5, #1048]	; 0x418
            if ((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_STATE_Msk)
    cb64:	f8d5 2418 	ldr.w	r2, [r5, #1048]	; 0x418
    cb68:	03d2      	lsls	r2, r2, #15
    cb6a:	d50c      	bpl.n	cb86 <z_nrf_clock_control_lf_on+0x8a>
	while (!(nrfx_clock_is_running(d, (void *)&type)
    cb6c:	f003 0303 	and.w	r3, r3, #3
    cb70:	2b02      	cmp	r3, #2
    cb72:	d001      	beq.n	cb78 <z_nrf_clock_control_lf_on+0x7c>
		     || (mode == CLOCK_CONTROL_NRF_LF_START_AVAILABLE)))) {
    cb74:	2e01      	cmp	r6, #1
    cb76:	d106      	bne.n	cb86 <z_nrf_clock_control_lf_on+0x8a>
	if (isr_mode) {
    cb78:	b31c      	cbz	r4, cbc2 <z_nrf_clock_control_lf_on+0xc6>
	__asm__ volatile(
    cb7a:	f389 8811 	msr	BASEPRI, r9
    cb7e:	f3bf 8f6f 	isb	sy
}
    cb82:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
			if (isr_mode) {
    cb86:	b1bc      	cbz	r4, cbb8 <z_nrf_clock_control_lf_on+0xbc>
 *
 * @return N/A
 */
static inline void k_cpu_atomic_idle(unsigned int key)
{
	arch_cpu_atomic_idle(key);
    cb88:	4648      	mov	r0, r9
    cb8a:	f000 fa01 	bl	cf90 <arch_cpu_atomic_idle>
    return (nrf_clock_lfclk_t)(p_reg->LFCLKSRC);
    cb8e:	f8d5 3518 	ldr.w	r3, [r5, #1304]	; 0x518
		if ((target_type ==  NRF_CLOCK_LFCLK_Xtal)
    cb92:	b2db      	uxtb	r3, r3
    cb94:	2b01      	cmp	r3, #1
    cb96:	d1e3      	bne.n	cb60 <z_nrf_clock_control_lf_on+0x64>
    return (bool)*((volatile uint32_t *)((uint8_t *)p_reg + event));
    cb98:	683a      	ldr	r2, [r7, #0]
		    && nrf_clock_event_check(NRF_CLOCK,
    cb9a:	2a00      	cmp	r2, #0
    cb9c:	d0e0      	beq.n	cb60 <z_nrf_clock_control_lf_on+0x64>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    cb9e:	2200      	movs	r2, #0
    cba0:	603a      	str	r2, [r7, #0]
#ifndef NRF_DECLARE_ONLY

NRF_STATIC_INLINE void nrf_event_readback(void * p_event_reg)
{
#if NRFX_CHECK(NRFX_EVENT_READBACK_ENABLED) && !defined(NRF51)
    (void)*((volatile uint32_t *)(p_event_reg));
    cba2:	683a      	ldr	r2, [r7, #0]
    p_reg->LFCLKSRC = (uint32_t)(source);
    cba4:	2202      	movs	r2, #2
 */
__STATIC_INLINE void __NVIC_ClearPendingIRQ(IRQn_Type IRQn)
{
  if ((int32_t)(IRQn) >= 0)
  {
    NVIC->ICPR[(((uint32_t)IRQn) >> 5UL)] = (uint32_t)(1UL << (((uint32_t)IRQn) & 0x1FUL));
    cba6:	2120      	movs	r1, #32
    cba8:	f8c5 2518 	str.w	r2, [r5, #1304]	; 0x518
    cbac:	4a10      	ldr	r2, [pc, #64]	; (cbf0 <z_nrf_clock_control_lf_on+0xf4>)
    cbae:	f8c2 1180 	str.w	r1, [r2, #384]	; 0x180
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    cbb2:	4a10      	ldr	r2, [pc, #64]	; (cbf4 <z_nrf_clock_control_lf_on+0xf8>)
    cbb4:	6013      	str	r3, [r2, #0]
    cbb6:	e7d3      	b.n	cb60 <z_nrf_clock_control_lf_on+0x64>
	return z_impl_k_sleep(timeout);
    cbb8:	2100      	movs	r1, #0
    cbba:	2021      	movs	r0, #33	; 0x21
    cbbc:	f001 fd3a 	bl	e634 <z_impl_k_sleep>
    cbc0:	e7e5      	b.n	cb8e <z_nrf_clock_control_lf_on+0x92>
    p_reg->INTENSET = mask;
    cbc2:	2302      	movs	r3, #2
    cbc4:	f8c8 3304 	str.w	r3, [r8, #772]	; 0x304
		__ASSERT_NO_MSG(false);
    cbc8:	e7db      	b.n	cb82 <z_nrf_clock_control_lf_on+0x86>
    p_reg->INTENCLR = mask;
    cbca:	2202      	movs	r2, #2
    cbcc:	4b05      	ldr	r3, [pc, #20]	; (cbe4 <z_nrf_clock_control_lf_on+0xe8>)
	bool isr_mode = k_is_in_isr() || k_is_pre_kernel();
    cbce:	4604      	mov	r4, r0
    cbd0:	f8c3 2308 	str.w	r2, [r3, #776]	; 0x308
	int key = isr_mode ? irq_lock() : 0;
    cbd4:	4681      	mov	r9, r0
    cbd6:	e7c0      	b.n	cb5a <z_nrf_clock_control_lf_on+0x5e>
    cbd8:	20010204 	.word	0x20010204
    cbdc:	200101a0 	.word	0x200101a0
    cbe0:	200101cc 	.word	0x200101cc
    cbe4:	40005000 	.word	0x40005000
    cbe8:	2001028b 	.word	0x2001028b
    cbec:	40005104 	.word	0x40005104
    cbf0:	e000e100 	.word	0xe000e100
    cbf4:	40005008 	.word	0x40005008

0000cbf8 <handle_next_cycle_case>:
 * counter progresses during that time it means that 1 cycle elapsed and
 * interrupt is set pending.
 */
static void handle_next_cycle_case(uint32_t t)
{
	set_comparator(t + 2);
    cbf8:	1c82      	adds	r2, r0, #2

#ifndef NRF_DECLARE_ONLY

NRF_STATIC_INLINE  void nrf_rtc_cc_set(NRF_RTC_Type * p_reg, uint32_t ch, uint32_t cc_val)
{
    p_reg->CC[ch] = cc_val;
    cbfa:	4b08      	ldr	r3, [pc, #32]	; (cc1c <handle_next_cycle_case+0x24>)
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    cbfc:	f022 427f 	bic.w	r2, r2, #4278190080	; 0xff000000
    cc00:	f8c3 2540 	str.w	r2, [r3, #1344]	; 0x540
    nrf_event_readback((uint8_t *)p_reg + (uint32_t)event);
}

NRF_STATIC_INLINE uint32_t nrf_rtc_counter_get(NRF_RTC_Type const * p_reg)
{
     return p_reg->COUNTER;
    cc04:	f8d3 2504 	ldr.w	r2, [r3, #1284]	; 0x504
	while (t != counter()) {
    cc08:	4290      	cmp	r0, r2
    cc0a:	d100      	bne.n	cc0e <handle_next_cycle_case+0x16>
		 * generated. Trigger interrupt.
		 */
		t = counter();
		set_comparator(t + 2);
	}
}
    cc0c:	4770      	bx	lr
    cc0e:	f8d3 0504 	ldr.w	r0, [r3, #1284]	; 0x504
		set_comparator(t + 2);
    cc12:	1c82      	adds	r2, r0, #2
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    cc14:	f022 427f 	bic.w	r2, r2, #4278190080	; 0xff000000
    cc18:	e7f2      	b.n	cc00 <handle_next_cycle_case+0x8>
    cc1a:	bf00      	nop
    cc1c:	40015000 	.word	0x40015000

0000cc20 <rtc_nrf_isr>:
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0;
    cc20:	2200      	movs	r2, #0
    cc22:	4b07      	ldr	r3, [pc, #28]	; (cc40 <rtc_nrf_isr+0x20>)
    cc24:	601a      	str	r2, [r3, #0]
    cc26:	681b      	ldr	r3, [r3, #0]
{
	ARG_UNUSED(arg);
	event_clear();

	uint32_t t = get_comparator();
	uint32_t dticks = counter_sub(t, last_count) / CYC_PER_TICK;
    cc28:	4a06      	ldr	r2, [pc, #24]	; (cc44 <rtc_nrf_isr+0x24>)
    return p_reg->CC[ch];
    cc2a:	4b07      	ldr	r3, [pc, #28]	; (cc48 <rtc_nrf_isr+0x28>)
    cc2c:	f8d3 0540 	ldr.w	r0, [r3, #1344]	; 0x540
    cc30:	6813      	ldr	r3, [r2, #0]
	return (a - b) & COUNTER_MAX;
    cc32:	1ac0      	subs	r0, r0, r3
    cc34:	f020 407f 	bic.w	r0, r0, #4278190080	; 0xff000000

	last_count += dticks * CYC_PER_TICK;
    cc38:	4403      	add	r3, r0
    cc3a:	6013      	str	r3, [r2, #0]
		 * so it won't get preempted by the interrupt.
		 */
		set_absolute_alarm(last_count + CYC_PER_TICK);
	}

	z_clock_announce(IS_ENABLED(CONFIG_TICKLESS_KERNEL) ? dticks : (dticks > 0));
    cc3c:	f001 becc 	b.w	e9d8 <z_clock_announce>
    cc40:	40015140 	.word	0x40015140
    cc44:	20010208 	.word	0x20010208
    cc48:	40015000 	.word	0x40015000

0000cc4c <z_clock_driver_init>:
}

int z_clock_driver_init(const struct device *device)
{
    cc4c:	b538      	push	{r3, r4, r5, lr}
}

NRF_STATIC_INLINE void nrf_rtc_prescaler_set(NRF_RTC_Type * p_reg, uint32_t val)
{
    NRFX_ASSERT(val <= (RTC_PRESCALER_PRESCALER_Msk >> RTC_PRESCALER_PRESCALER_Pos));
    p_reg->PRESCALER = val;
    cc4e:	2400      	movs	r4, #0
    cc50:	f44f 1200 	mov.w	r2, #2097152	; 0x200000
    cc54:	4d0e      	ldr	r5, [pc, #56]	; (cc90 <z_clock_driver_init+0x44>)
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0;
    cc56:	4b0f      	ldr	r3, [pc, #60]	; (cc94 <z_clock_driver_init+0x48>)
    p_reg->PRESCALER = val;
    cc58:	f8c5 4508 	str.w	r4, [r5, #1288]	; 0x508
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0;
    cc5c:	601c      	str	r4, [r3, #0]
    cc5e:	681b      	ldr	r3, [r3, #0]
    cc60:	4b0d      	ldr	r3, [pc, #52]	; (cc98 <z_clock_driver_init+0x4c>)
	nrf_rtc_prescaler_set(RTC, 0);
	event_clear();
	NVIC_ClearPendingIRQ(RTC_IRQn);
	int_enable();

	IRQ_CONNECT(RTC_IRQn, 1, rtc_nrf_isr, 0, 0);
    cc62:	2101      	movs	r1, #1
    cc64:	f8c3 2180 	str.w	r2, [r3, #384]	; 0x180
    p_reg->INTENSET = mask;
    cc68:	f44f 3380 	mov.w	r3, #65536	; 0x10000
    cc6c:	4622      	mov	r2, r4
    cc6e:	f8c5 3304 	str.w	r3, [r5, #772]	; 0x304
    cc72:	2015      	movs	r0, #21
    cc74:	f000 f8cc 	bl	ce10 <z_arm_irq_priority_set>
	irq_enable(RTC_IRQn);
    cc78:	2015      	movs	r0, #21
    cc7a:	f000 f8ab 	bl	cdd4 <arch_irq_enable>
    return (uint32_t)p_reg + task;
}

NRF_STATIC_INLINE void nrf_rtc_task_trigger(NRF_RTC_Type * p_reg, nrf_rtc_task_t task)
{
    *(__IO uint32_t *)((uint32_t)p_reg + task) = 1;
    cc7e:	2301      	movs	r3, #1
    cc80:	4a06      	ldr	r2, [pc, #24]	; (cc9c <z_clock_driver_init+0x50>)

	if (!IS_ENABLED(CONFIG_TICKLESS_KERNEL)) {
		set_comparator(counter() + CYC_PER_TICK);
	}

	z_nrf_clock_control_lf_on(mode);
    cc82:	2002      	movs	r0, #2
    cc84:	6013      	str	r3, [r2, #0]
    cc86:	602b      	str	r3, [r5, #0]
    cc88:	f7ff ff38 	bl	cafc <z_nrf_clock_control_lf_on>

	return 0;
}
    cc8c:	4620      	mov	r0, r4
    cc8e:	bd38      	pop	{r3, r4, r5, pc}
    cc90:	40015000 	.word	0x40015000
    cc94:	40015140 	.word	0x40015140
    cc98:	e000e100 	.word	0xe000e100
    cc9c:	40015008 	.word	0x40015008

0000cca0 <z_clock_set_timeout>:

void z_clock_set_timeout(int32_t ticks, bool idle)
{
    cca0:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
     return p_reg->COUNTER;
    cca2:	4b2d      	ldr	r3, [pc, #180]	; (cd58 <z_clock_set_timeout+0xb8>)

	if (!IS_ENABLED(CONFIG_TICKLESS_KERNEL)) {
		return;
	}

	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
    cca4:	4c2d      	ldr	r4, [pc, #180]	; (cd5c <z_clock_set_timeout+0xbc>)
    cca6:	f8d3 2504 	ldr.w	r2, [r3, #1284]	; 0x504
	ticks = MAX(MIN(ticks - 1, (int32_t)MAX_TICKS), 0);

	uint32_t unannounced = counter_sub(counter(), last_count);
    ccaa:	4b2d      	ldr	r3, [pc, #180]	; (cd60 <z_clock_set_timeout+0xc0>)
	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
    ccac:	f1b0 3fff 	cmp.w	r0, #4294967295	; 0xffffffff
    ccb0:	bf08      	it	eq
    ccb2:	4620      	moveq	r0, r4
	uint32_t unannounced = counter_sub(counter(), last_count);
    ccb4:	6819      	ldr	r1, [r3, #0]
	return (a - b) & COUNTER_MAX;
    ccb6:	1a52      	subs	r2, r2, r1
    ccb8:	f022 437f 	bic.w	r3, r2, #4278190080	; 0xff000000
	/* If we haven't announced for more than half the 24-bit wrap
	 * duration, then force an announce to avoid loss of a wrap
	 * event.  This can happen if new timeouts keep being set
	 * before the existing one triggers the interrupt.
	 */
	if (unannounced >= COUNTER_HALF_SPAN) {
    ccbc:	0212      	lsls	r2, r2, #8
    ccbe:	d438      	bmi.n	cd32 <z_clock_set_timeout+0x92>
	ticks = MAX(MIN(ticks - 1, (int32_t)MAX_TICKS), 0);
    ccc0:	3801      	subs	r0, #1
    ccc2:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
    ccc6:	42a0      	cmp	r0, r4
    ccc8:	bfa8      	it	ge
    ccca:	4620      	movge	r0, r4
	}

	/* Get the cycles from last_count to the tick boundary after
	 * the requested ticks have passed starting now.
	 */
	cyc = ticks * CYC_PER_TICK + 1 + unannounced;
    cccc:	3301      	adds	r3, #1
    ccce:	4418      	add	r0, r3
	 */
	if (cyc > MAX_CYCLES) {
		cyc = MAX_CYCLES;
	}

	cyc += last_count;
    ccd0:	42a0      	cmp	r0, r4
    ccd2:	bf94      	ite	ls
    ccd4:	180c      	addls	r4, r1, r0
    ccd6:	190c      	addhi	r4, r1, r4
    p_reg->INTENCLR = mask;
    ccd8:	f44f 3080 	mov.w	r0, #65536	; 0x10000
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0;
    ccdc:	2600      	movs	r6, #0
    p_reg->INTENCLR = mask;
    ccde:	4a1e      	ldr	r2, [pc, #120]	; (cd58 <z_clock_set_timeout+0xb8>)
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0;
    cce0:	4d20      	ldr	r5, [pc, #128]	; (cd64 <z_clock_set_timeout+0xc4>)
    p_reg->INTENCLR = mask;
    cce2:	f8c2 0308 	str.w	r0, [r2, #776]	; 0x308
     return p_reg->COUNTER;
    cce6:	f8d2 1504 	ldr.w	r1, [r2, #1284]	; 0x504
    return p_reg->CC[ch];
    ccea:	f8d2 3540 	ldr.w	r3, [r2, #1344]	; 0x540
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0;
    ccee:	602e      	str	r6, [r5, #0]
	return (a - b) & COUNTER_MAX;
    ccf0:	1a5b      	subs	r3, r3, r1
    ccf2:	f023 437f 	bic.w	r3, r3, #4278190080	; 0xff000000
    ccf6:	682f      	ldr	r7, [r5, #0]
	if (counter_sub(prev_val, now) == 1) {
    ccf8:	2b01      	cmp	r3, #1
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    ccfa:	f021 477f 	bic.w	r7, r1, #4278190080	; 0xff000000
    p_reg->CC[ch] = cc_val;
    ccfe:	f8c2 7540 	str.w	r7, [r2, #1344]	; 0x540
}

NRF_STATIC_INLINE void nrf_rtc_event_enable(NRF_RTC_Type * p_reg, uint32_t mask)
{
    p_reg->EVTENSET = mask;
    cd02:	f8c2 0344 	str.w	r0, [r2, #836]	; 0x344
	if (counter_sub(prev_val, now) == 1) {
    cd06:	d104      	bne.n	cd12 <z_clock_set_timeout+0x72>
	z_impl_k_busy_wait(usec_to_wait);
    cd08:	200f      	movs	r0, #15
    cd0a:	f002 fca3 	bl	f654 <z_impl_k_busy_wait>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0;
    cd0e:	602e      	str	r6, [r5, #0]
    cd10:	682b      	ldr	r3, [r5, #0]
    cd12:	f44f 1200 	mov.w	r2, #2097152	; 0x200000
    cd16:	4b14      	ldr	r3, [pc, #80]	; (cd68 <z_clock_set_timeout+0xc8>)
    cd18:	f8c3 2180 	str.w	r2, [r3, #384]	; 0x180
     return p_reg->COUNTER;
    cd1c:	4b0e      	ldr	r3, [pc, #56]	; (cd58 <z_clock_set_timeout+0xb8>)
    cd1e:	f8d3 0504 	ldr.w	r0, [r3, #1284]	; 0x504
	return (a - b) & COUNTER_MAX;
    cd22:	1a22      	subs	r2, r4, r0
    cd24:	f022 427f 	bic.w	r2, r2, #4278190080	; 0xff000000
	if (diff == 1) {
    cd28:	2a01      	cmp	r2, #1
    cd2a:	d104      	bne.n	cd36 <z_clock_set_timeout+0x96>
		handle_next_cycle_case(t);
    cd2c:	f7ff ff64 	bl	cbf8 <handle_next_cycle_case>
    cd30:	e00b      	b.n	cd4a <z_clock_set_timeout+0xaa>
		ticks = 0;
    cd32:	2000      	movs	r0, #0
    cd34:	e7ca      	b.n	cccc <z_clock_set_timeout+0x2c>
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    cd36:	f024 427f 	bic.w	r2, r4, #4278190080	; 0xff000000
    p_reg->CC[ch] = cc_val;
    cd3a:	f8c3 2540 	str.w	r2, [r3, #1344]	; 0x540
     return p_reg->COUNTER;
    cd3e:	f8d3 0504 	ldr.w	r0, [r3, #1284]	; 0x504
	return (a - b) & COUNTER_MAX;
    cd42:	1a24      	subs	r4, r4, r0
    cd44:	3c02      	subs	r4, #2
	if (diff > MAX_CYCLES) {
    cd46:	0223      	lsls	r3, r4, #8
    cd48:	d4f0      	bmi.n	cd2c <z_clock_set_timeout+0x8c>
    p_reg->INTENSET = mask;
    cd4a:	f44f 3280 	mov.w	r2, #65536	; 0x10000
    cd4e:	4b02      	ldr	r3, [pc, #8]	; (cd58 <z_clock_set_timeout+0xb8>)
    cd50:	f8c3 2304 	str.w	r2, [r3, #772]	; 0x304
	set_protected_absolute_alarm(cyc);
}
    cd54:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    cd56:	bf00      	nop
    cd58:	40015000 	.word	0x40015000
    cd5c:	007fffff 	.word	0x007fffff
    cd60:	20010208 	.word	0x20010208
    cd64:	40015140 	.word	0x40015140
    cd68:	e000e100 	.word	0xe000e100

0000cd6c <z_clock_elapsed>:
	__asm__ volatile(
    cd6c:	f04f 0220 	mov.w	r2, #32
    cd70:	f3ef 8311 	mrs	r3, BASEPRI
    cd74:	f382 8811 	msr	BASEPRI, r2
    cd78:	f3bf 8f6f 	isb	sy
     return p_reg->COUNTER;
    cd7c:	4a06      	ldr	r2, [pc, #24]	; (cd98 <z_clock_elapsed+0x2c>)
    cd7e:	f8d2 0504 	ldr.w	r0, [r2, #1284]	; 0x504
	if (!IS_ENABLED(CONFIG_TICKLESS_KERNEL)) {
		return 0;
	}

	k_spinlock_key_t key = k_spin_lock(&lock);
	uint32_t ret = counter_sub(counter(), last_count) / CYC_PER_TICK;
    cd82:	4a06      	ldr	r2, [pc, #24]	; (cd9c <z_clock_elapsed+0x30>)
	return (a - b) & COUNTER_MAX;
    cd84:	6812      	ldr	r2, [r2, #0]
    cd86:	1a80      	subs	r0, r0, r2
    cd88:	f020 407f 	bic.w	r0, r0, #4278190080	; 0xff000000
	__asm__ volatile(
    cd8c:	f383 8811 	msr	BASEPRI, r3
    cd90:	f3bf 8f6f 	isb	sy

	k_spin_unlock(&lock, key);
	return ret;
}
    cd94:	4770      	bx	lr
    cd96:	bf00      	nop
    cd98:	40015000 	.word	0x40015000
    cd9c:	20010208 	.word	0x20010208

0000cda0 <arch_swap>:
 * as BASEPRI is not available.
 */
int arch_swap(unsigned int key)
{
	/* store off key and return value */
	_current->arch.basepri = key;
    cda0:	4a09      	ldr	r2, [pc, #36]	; (cdc8 <arch_swap+0x28>)
	_current->arch.swap_return_value = _k_neg_eagain;
    cda2:	490a      	ldr	r1, [pc, #40]	; (cdcc <arch_swap+0x2c>)
	_current->arch.basepri = key;
    cda4:	6893      	ldr	r3, [r2, #8]
	_current->arch.swap_return_value = _k_neg_eagain;
    cda6:	6809      	ldr	r1, [r1, #0]
	_current->arch.basepri = key;
    cda8:	6798      	str	r0, [r3, #120]	; 0x78
	_current->arch.swap_return_value = _k_neg_eagain;
    cdaa:	67d9      	str	r1, [r3, #124]	; 0x7c

#if defined(CONFIG_CPU_CORTEX_M)
	/* set pending bit to make sure we will take a PendSV exception */
	SCB->ICSR |= SCB_ICSR_PENDSVSET_Msk;
    cdac:	4908      	ldr	r1, [pc, #32]	; (cdd0 <arch_swap+0x30>)
    cdae:	684b      	ldr	r3, [r1, #4]
    cdb0:	f043 5380 	orr.w	r3, r3, #268435456	; 0x10000000
    cdb4:	604b      	str	r3, [r1, #4]
    cdb6:	2300      	movs	r3, #0
    cdb8:	f383 8811 	msr	BASEPRI, r3
    cdbc:	f3bf 8f6f 	isb	sy
#endif

	/* Context switch is performed here. Returning implies the
	 * thread has been context-switched-in again.
	 */
	return _current->arch.swap_return_value;
    cdc0:	6893      	ldr	r3, [r2, #8]
}
    cdc2:	6fd8      	ldr	r0, [r3, #124]	; 0x7c
    cdc4:	4770      	bx	lr
    cdc6:	bf00      	nop
    cdc8:	20010248 	.word	0x20010248
    cdcc:	0000fa68 	.word	0x0000fa68
    cdd0:	e000ed00 	.word	0xe000ed00

0000cdd4 <arch_irq_enable>:
#define REG_FROM_IRQ(irq) (irq / NUM_IRQS_PER_REG)
#define BIT_FROM_IRQ(irq) (irq % NUM_IRQS_PER_REG)

void arch_irq_enable(unsigned int irq)
{
	NVIC_EnableIRQ((IRQn_Type)irq);
    cdd4:	b243      	sxtb	r3, r0
  if ((int32_t)(IRQn) >= 0)
    cdd6:	2b00      	cmp	r3, #0
    cdd8:	db08      	blt.n	cdec <arch_irq_enable+0x18>
    NVIC->ISER[(((uint32_t)IRQn) >> 5UL)] = (uint32_t)(1UL << (((uint32_t)IRQn) & 0x1FUL));
    cdda:	2201      	movs	r2, #1
    cddc:	f000 001f 	and.w	r0, r0, #31
    cde0:	fa02 f000 	lsl.w	r0, r2, r0
    cde4:	4a02      	ldr	r2, [pc, #8]	; (cdf0 <arch_irq_enable+0x1c>)
    cde6:	095b      	lsrs	r3, r3, #5
    cde8:	f842 0023 	str.w	r0, [r2, r3, lsl #2]
}
    cdec:	4770      	bx	lr
    cdee:	bf00      	nop
    cdf0:	e000e100 	.word	0xe000e100

0000cdf4 <arch_irq_is_enabled>:
	NVIC_DisableIRQ((IRQn_Type)irq);
}

int arch_irq_is_enabled(unsigned int irq)
{
	return NVIC->ISER[REG_FROM_IRQ(irq)] & BIT(BIT_FROM_IRQ(irq));
    cdf4:	4b05      	ldr	r3, [pc, #20]	; (ce0c <arch_irq_is_enabled+0x18>)
    cdf6:	0942      	lsrs	r2, r0, #5
    cdf8:	f853 2022 	ldr.w	r2, [r3, r2, lsl #2]
    cdfc:	2301      	movs	r3, #1
    cdfe:	f000 001f 	and.w	r0, r0, #31
    ce02:	fa03 f000 	lsl.w	r0, r3, r0
}
    ce06:	4010      	ands	r0, r2
    ce08:	4770      	bx	lr
    ce0a:	bf00      	nop
    ce0c:	e000e100 	.word	0xe000e100

0000ce10 <z_arm_irq_priority_set>:
	 */
	__ASSERT(prio <= (BIT(NUM_IRQ_PRIO_BITS) - 1),
		 "invalid priority %d! values must be less than %lu\n",
		 prio - _IRQ_PRIO_OFFSET,
		 BIT(NUM_IRQ_PRIO_BITS) - (_IRQ_PRIO_OFFSET));
	NVIC_SetPriority((IRQn_Type)irq, prio);
    ce10:	b243      	sxtb	r3, r0
  \param [in]  priority  Priority to set.
  \note    The priority cannot be set for every processor exception.
 */
__STATIC_INLINE void __NVIC_SetPriority(IRQn_Type IRQn, uint32_t priority)
{
  if ((int32_t)(IRQn) >= 0)
    ce12:	2b00      	cmp	r3, #0
	prio += _IRQ_PRIO_OFFSET;
    ce14:	f101 0101 	add.w	r1, r1, #1
  {
    NVIC->IPR[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    ce18:	bfa8      	it	ge
    ce1a:	f103 4360 	addge.w	r3, r3, #3758096384	; 0xe0000000
    ce1e:	ea4f 1141 	mov.w	r1, r1, lsl #5
  }
  else
  {
    SCB->SHPR[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    ce22:	bfb8      	it	lt
    ce24:	4b05      	ldrlt	r3, [pc, #20]	; (ce3c <z_arm_irq_priority_set+0x2c>)
    ce26:	b2c9      	uxtb	r1, r1
    NVIC->IPR[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    ce28:	bfab      	itete	ge
    ce2a:	f503 4361 	addge.w	r3, r3, #57600	; 0xe100
    SCB->SHPR[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    ce2e:	f000 000f 	andlt.w	r0, r0, #15
    NVIC->IPR[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    ce32:	f883 1300 	strbge.w	r1, [r3, #768]	; 0x300
    SCB->SHPR[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    ce36:	5419      	strblt	r1, [r3, r0]
}
    ce38:	4770      	bx	lr
    ce3a:	bf00      	nop
    ce3c:	e000ed14 	.word	0xe000ed14

0000ce40 <arch_new_thread>:

#if defined(CONFIG_CPU_CORTEX_M)
	/* force ARM mode by clearing LSB of address */
	iframe->pc &= 0xfffffffe;
#endif
	iframe->a1 = (uint32_t)entry;
    ce40:	f842 3c20 	str.w	r3, [r2, #-32]
	iframe->a2 = (uint32_t)p1;
    ce44:	9b00      	ldr	r3, [sp, #0]
	iframe->pc &= 0xfffffffe;
    ce46:	490b      	ldr	r1, [pc, #44]	; (ce74 <arch_new_thread+0x34>)
	iframe->a2 = (uint32_t)p1;
    ce48:	f842 3c1c 	str.w	r3, [r2, #-28]
	iframe->a3 = (uint32_t)p2;
    ce4c:	9b01      	ldr	r3, [sp, #4]
	iframe->pc &= 0xfffffffe;
    ce4e:	f021 0101 	bic.w	r1, r1, #1
	iframe->a3 = (uint32_t)p2;
    ce52:	f842 3c18 	str.w	r3, [r2, #-24]
	iframe->a4 = (uint32_t)p3;
    ce56:	9b02      	ldr	r3, [sp, #8]
	iframe->pc &= 0xfffffffe;
    ce58:	f842 1c08 	str.w	r1, [r2, #-8]
	iframe->a4 = (uint32_t)p3;
    ce5c:	f842 3c14 	str.w	r3, [r2, #-20]

#if defined(CONFIG_CPU_CORTEX_M)
	iframe->xpsr =
    ce60:	f04f 7380 	mov.w	r3, #16777216	; 0x1000000
    ce64:	f842 3c04 	str.w	r3, [r2, #-4]
	iframe->xpsr |= T_BIT;
#endif /* CONFIG_COMPILER_ISA_THUMB2 */
#endif /* CONFIG_CPU_CORTEX_M */

	thread->callee_saved.psp = (uint32_t)iframe;
	thread->arch.basepri = 0;
    ce68:	2300      	movs	r3, #0
	iframe = Z_STACK_PTR_TO_FRAME(struct __basic_sf, stack_ptr);
    ce6a:	3a20      	subs	r2, #32
	thread->callee_saved.psp = (uint32_t)iframe;
    ce6c:	6582      	str	r2, [r0, #88]	; 0x58
	thread->arch.basepri = 0;
    ce6e:	6783      	str	r3, [r0, #120]	; 0x78
#endif
	/*
	 * initial values in all other registers/thread entries are
	 * irrelevant.
	 */
}
    ce70:	4770      	bx	lr
    ce72:	bf00      	nop
    ce74:	0000eee9 	.word	0x0000eee9

0000ce78 <arch_switch_to_main_thread>:
#endif
}

void arch_switch_to_main_thread(struct k_thread *main_thread, char *stack_ptr,
				k_thread_entry_t _main)
{
    ce78:	4604      	mov	r4, r0
    ce7a:	b508      	push	{r3, lr}
    ce7c:	460e      	mov	r6, r1
    ce7e:	4615      	mov	r5, r2
	z_arm_configure_static_mpu_regions();
    ce80:	f000 fa06 	bl	d290 <z_arm_configure_static_mpu_regions>
	z_arm_prepare_switch_to_main();

	_current = main_thread;
    ce84:	4b08      	ldr	r3, [pc, #32]	; (cea8 <arch_switch_to_main_thread+0x30>)
    ce86:	609c      	str	r4, [r3, #8]
#if (!(defined (__ARM_ARCH_8M_MAIN__ ) && (__ARM_ARCH_8M_MAIN__ == 1)) && \
    (!defined (__ARM_FEATURE_CMSE) || (__ARM_FEATURE_CMSE < 3)))
  // without main extensions, the non-secure PSPLIM is RAZ/WI
  (void)ProcStackPtrLimit;
#else
  __ASM volatile ("MSR psplim, %0" : : "r" (ProcStackPtrLimit));
    ce88:	6ea3      	ldr	r3, [r4, #104]	; 0x68
    ce8a:	f383 880b 	msr	PSPLIM, r3

	/*
	 * Set PSP to the highest address of the main stack
	 * before enabling interrupts and jumping to main.
	 */
	__asm__ volatile (
    ce8e:	4628      	mov	r0, r5
    ce90:	f386 8809 	msr	PSP, r6
    ce94:	2100      	movs	r1, #0
    ce96:	b663      	cpsie	if
    ce98:	f381 8811 	msr	BASEPRI, r1
    ce9c:	f3bf 8f6f 	isb	sy
    cea0:	2200      	movs	r2, #0
    cea2:	2300      	movs	r3, #0
    cea4:	f002 f820 	bl	eee8 <z_thread_entry>
	:
	: "r" (_main), "r" (stack_ptr)
	: "r0" /* not to be overwritten by msr PSP, %1 */
	);

	CODE_UNREACHABLE;
    cea8:	20010248 	.word	0x20010248

0000ceac <z_arm_prep_c>:
#else
#define VECTOR_ADDRESS CONFIG_SRAM_BASE_ADDRESS
#endif
static inline void relocate_vector_table(void)
{
	SCB->VTOR = VECTOR_ADDRESS & SCB_VTOR_TBLOFF_Msk;
    ceac:	4a0e      	ldr	r2, [pc, #56]	; (cee8 <z_arm_prep_c+0x3c>)
 * This routine prepares for the execution of and runs C code.
 *
 * @return N/A
 */
void z_arm_prep_c(void)
{
    ceae:	b508      	push	{r3, lr}
	SCB->VTOR = VECTOR_ADDRESS & SCB_VTOR_TBLOFF_Msk;
    ceb0:	4b0e      	ldr	r3, [pc, #56]	; (ceec <z_arm_prep_c+0x40>)
    ceb2:	f022 027f 	bic.w	r2, r2, #127	; 0x7f
    ceb6:	609a      	str	r2, [r3, #8]
  \details Acts as a special kind of Data Memory Barrier.
           It completes when all explicit memory accesses before this instruction complete.
 */
__STATIC_FORCEINLINE void __DSB(void)
{
  __ASM volatile ("dsb 0xF":::"memory");
    ceb8:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
    cebc:	f3bf 8f6f 	isb	sy
	SCB->CPACR &= (~(CPACR_CP10_Msk | CPACR_CP11_Msk));
    cec0:	f8d3 2088 	ldr.w	r2, [r3, #136]	; 0x88
    cec4:	f422 0270 	bic.w	r2, r2, #15728640	; 0xf00000
    cec8:	f8c3 2088 	str.w	r2, [r3, #136]	; 0x88
  __ASM volatile ("MRS %0, control" : "=r" (result) );
    cecc:	f3ef 8314 	mrs	r3, CONTROL
	__set_CONTROL(__get_CONTROL() & (~(CONTROL_FPCA_Msk)));
    ced0:	f023 0304 	bic.w	r3, r3, #4
  __ASM volatile ("MSR control, %0" : : "r" (control) : "memory");
    ced4:	f383 8814 	msr	CONTROL, r3
	relocate_vector_table();
#if defined(CONFIG_CPU_HAS_FPU)
	z_arm_floating_point_init();
#endif
	z_bss_zero();
    ced8:	f000 fff2 	bl	dec0 <z_bss_zero>
	z_data_copy();
    cedc:	f000 fffa 	bl	ded4 <z_data_copy>
#if defined(CONFIG_ARMV7_R) && defined(CONFIG_INIT_STACKS)
	z_arm_init_stacks();
#endif
	z_arm_interrupt_init();
    cee0:	f000 f99e 	bl	d220 <z_arm_interrupt_init>
	z_cstart();
    cee4:	f001 f834 	bl	df50 <z_cstart>
    cee8:	0000c000 	.word	0x0000c000
    ceec:	e000ed00 	.word	0xe000ed00

0000cef0 <z_arm_pendsv>:
    pop {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
#endif /* CONFIG_TRACING */

    /* load _kernel into r1 and current k_thread into r2 */
    ldr r1, =_kernel
    cef0:	4913      	ldr	r1, [pc, #76]	; (cf40 <z_arm_pendsv+0x50>)
    ldr r2, [r1, #_kernel_offset_to_current]
    cef2:	688a      	ldr	r2, [r1, #8]

    /* addr of callee-saved regs in thread in r0 */
    ldr r0, =_thread_offset_to_callee_saved
    cef4:	f04f 0038 	mov.w	r0, #56	; 0x38
    add r0, r2
    cef8:	4410      	add	r0, r2

    /* save callee-saved + psp in thread */
#if defined(CONFIG_CPU_CORTEX_M)
    mrs ip, PSP
    cefa:	f3ef 8c09 	mrs	ip, PSP
    mov r6, r11
    mov r7, ip
    /* store r8-12 */
    stmea r0!, {r3-r7}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    stmia r0, {v1-v8, ip}
    cefe:	e880 1ff0 	stmia.w	r0, {r4, r5, r6, r7, r8, r9, sl, fp, ip}

    /* Protect the kernel state while we play with the thread lists */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    cpsid i
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    movs.n r0, #_EXC_IRQ_DEFAULT_PRIO
    cf02:	2020      	movs	r0, #32
    msr BASEPRI, r0
    cf04:	f380 8811 	msr	BASEPRI, r0
    isb /* Make the effect of disabling interrupts be realized immediately */
    cf08:	f3bf 8f6f 	isb	sy
     * the new thread is context-switched in since all decisions
     * to pend PendSV have been taken with the current kernel
     * state and this is what we're handling currently.
     */
#if defined(CONFIG_CPU_CORTEX_M)
    ldr v4, =_SCS_ICSR
    cf0c:	4f0d      	ldr	r7, [pc, #52]	; (cf44 <z_arm_pendsv+0x54>)
    ldr v3, =_SCS_ICSR_UNPENDSV
    cf0e:	f04f 6600 	mov.w	r6, #134217728	; 0x8000000
#endif

    /* _kernel is still in r1 */

    /* fetch the thread to run from the ready queue cache */
    ldr r2, [r1, #_kernel_offset_to_ready_q_cache]
    cf12:	6a4a      	ldr	r2, [r1, #36]	; 0x24

    str r2, [r1, #_kernel_offset_to_current]
    cf14:	608a      	str	r2, [r1, #8]
     * has been handled.
     */

    /* _SCS_ICSR is still in v4 and _SCS_ICSR_UNPENDSV in v3 */
#if defined(CONFIG_CPU_CORTEX_M)
    str v3, [v4, #0]
    cf16:	603e      	str	r6, [r7, #0]

    ldr r0, [r4]
    movs.n r3, #0
    str r3, [r4]
#else
    ldr r0, [r2, #_thread_offset_to_basepri]
    cf18:	6f90      	ldr	r0, [r2, #120]	; 0x78
    movs r3, #0
    cf1a:	2300      	movs	r3, #0
    str r3, [r2, #_thread_offset_to_basepri]
    cf1c:	6793      	str	r3, [r2, #120]	; 0x78
    /* restore r4-r7, go back 9*4 bytes to the start of the stored block */
    subs r0, #36
    ldmia r0!, {r4-r7}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    /* restore BASEPRI for the incoming thread */
    msr BASEPRI, r0
    cf1e:	f380 8811 	msr	BASEPRI, r0
    isb

#endif

    /* load callee-saved + psp from thread */
    add r0, r2, #_thread_offset_to_callee_saved
    cf22:	f102 0038 	add.w	r0, r2, #56	; 0x38
    ldmia r0, {v1-v8, ip}
    cf26:	e890 1ff0 	ldmia.w	r0, {r4, r5, r6, r7, r8, r9, sl, fp, ip}
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */

#if defined(CONFIG_CPU_CORTEX_M)
    msr PSP, ip
    cf2a:	f38c 8809 	msr	PSP, ip
#endif

#ifdef CONFIG_BUILTIN_STACK_GUARD
    /* r2 contains k_thread */
    add r0, r2, #0
    cf2e:	f102 0000 	add.w	r0, r2, #0
    push {r2, lr}
    cf32:	b504      	push	{r2, lr}
    bl configure_builtin_stack_guard
    cf34:	f002 f95d 	bl	f1f2 <configure_builtin_stack_guard>
    pop {r2, lr}
    cf38:	e8bd 4004 	ldmia.w	sp!, {r2, lr}

    /*
     * Cortex-M: return from PendSV exception
     * Cortex-R: return to the caller (_IntExit or z_arm_svc)
     */
    bx lr
    cf3c:	4770      	bx	lr
    cf3e:	0000      	.short	0x0000
    ldr r1, =_kernel
    cf40:	20010248 	.word	0x20010248
    ldr v4, =_SCS_ICSR
    cf44:	e000ed04 	.word	0xe000ed04

0000cf48 <z_arm_svc>:
  bne _stack_frame_endif
_stack_frame_msp:
  mrs r0, MSP
_stack_frame_endif:
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    tst lr, #0x4    /* did we come from thread mode ? */
    cf48:	f01e 0f04 	tst.w	lr, #4
    ite eq  /* if zero (equal), came from handler mode */
    cf4c:	bf0c      	ite	eq
        mrseq r0, MSP   /* handler mode, stack frame is on MSP */
    cf4e:	f3ef 8008 	mrseq	r0, MSP
        mrsne r0, PSP   /* thread mode, stack frame is on PSP */
    cf52:	f3ef 8009 	mrsne	r0, PSP
#endif


    /* Figure out what SVC call number was invoked */

    ldr r1, [r0, #24]   /* grab address of PC from stack frame */
    cf56:	6981      	ldr	r1, [r0, #24]
     */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    subs r1, r1, #2
    ldrb r1, [r1]
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldrb r1, [r1, #-2]
    cf58:	f811 1c02 	ldrb.w	r1, [r1, #-2]
#endif
    bne _oops

#endif /* CONFIG_USERSPACE */

    cmp r1, #2
    cf5c:	2902      	cmp	r1, #2
    beq _oops
    cf5e:	d0ff      	beq.n	cf60 <_oops>

0000cf60 <_oops>:
    /* exception return is done in z_arm_int_exit() */
    b z_arm_int_exit
#endif

_oops:
    push {r0, lr}
    cf60:	b501      	push	{r0, lr}
    bl z_do_kernel_oops
    cf62:	f002 f94c 	bl	f1fe <z_do_kernel_oops>
    /* return from SVC exception is done here */
    pop {r0, pc}
    cf66:	bd01      	pop	{r0, pc}

0000cf68 <z_arm_cpu_idle_init>:
 * void z_arm_cpu_idle_init(void);
 */

SECTION_FUNC(TEXT, z_arm_cpu_idle_init)
#if defined(CONFIG_CPU_CORTEX_M)
	ldr	r1, =_SCB_SCR
    cf68:	4901      	ldr	r1, [pc, #4]	; (cf70 <z_arm_cpu_idle_init+0x8>)
	movs.n	r2, #_SCR_INIT_BITS
    cf6a:	2210      	movs	r2, #16
	str	r2, [r1]
    cf6c:	600a      	str	r2, [r1, #0]
#endif
	bx	lr
    cf6e:	4770      	bx	lr
	ldr	r1, =_SCB_SCR
    cf70:	e000ed10 	.word	0xe000ed10

0000cf74 <arch_cpu_idle>:
	 * before entering low power state.
	 *
	 * Set PRIMASK before configuring BASEPRI to prevent interruption
	 * before wake-up.
	 */
	cpsid	i
    cf74:	b672      	cpsid	i

	/*
	 * Set wake-up interrupt priority to the lowest and synchronise to
	 * ensure that this is visible to the WFI instruction.
	 */
	eors.n	r0, r0
    cf76:	4040      	eors	r0, r0
	msr	BASEPRI, r0
    cf78:	f380 8811 	msr	BASEPRI, r0
	isb
    cf7c:	f3bf 8f6f 	isb	sy

	/*
	 * Wait for all memory transactions to complete before entering low
	 * power state.
	 */
	dsb
    cf80:	f3bf 8f4f 	dsb	sy

	/* Enter low power state */
	wfi
    cf84:	bf30      	wfi

	/*
	 * Clear PRIMASK and flush instruction buffer to immediately service
	 * the wake-up interrupt.
	 */
	cpsie	i
    cf86:	b662      	cpsie	i
	isb
    cf88:	f3bf 8f6f 	isb	sy

	bx	lr
    cf8c:	4770      	bx	lr
    cf8e:	bf00      	nop

0000cf90 <arch_cpu_atomic_idle>:

	/*
	 * Lock PRIMASK while sleeping: wfe will still get interrupted by
	 * incoming interrupts but the CPU will not service them right away.
	 */
	cpsid	i
    cf90:	b672      	cpsid	i
	cpsie	i
_irq_disabled:

#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	/* r1: zero, for setting BASEPRI (needs a register) */
	eors.n	r1, r1
    cf92:	4049      	eors	r1, r1

	/* unlock BASEPRI so wfe gets interrupted by incoming interrupts */
	msr	BASEPRI, r1
    cf94:	f381 8811 	msr	BASEPRI, r1

	wfe
    cf98:	bf20      	wfe

	msr	BASEPRI, r0
    cf9a:	f380 8811 	msr	BASEPRI, r0
	cpsie	i
    cf9e:	b662      	cpsie	i
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
	bx	lr
    cfa0:	4770      	bx	lr
    cfa2:	bf00      	nop

0000cfa4 <z_SysNmiOnReset>:
_ASM_FILE_PROLOGUE

GTEXT(z_SysNmiOnReset)

SECTION_FUNC(TEXT, z_SysNmiOnReset)
    wfi
    cfa4:	bf30      	wfi
    b z_SysNmiOnReset
    cfa6:	f7ff bffd 	b.w	cfa4 <z_SysNmiOnReset>
    cfaa:	bf00      	nop

0000cfac <_isr_wrapper>:
 * @return N/A
 */
SECTION_FUNC(TEXT, _isr_wrapper)

#if defined(CONFIG_CPU_CORTEX_M)
	push {r0,lr}		/* r0, lr are now the first items on the stack */
    cfac:	b501      	push	{r0, lr}
	 * Disable interrupts to prevent nesting while exiting idle state. This
	 * is only necessary for the Cortex-M because it is the only ARM
	 * architecture variant that automatically enables interrupts when
	 * entering an ISR.
	 */
	cpsid i  /* PRIMASK = 1 */
    cfae:	b672      	cpsid	i
#endif

	/* is this a wakeup from idle ? */
	ldr r2, =_kernel
    cfb0:	4a0b      	ldr	r2, [pc, #44]	; (cfe0 <_isr_wrapper+0x34>)
	/* requested idle duration, in ticks */
	ldr r0, [r2, #_kernel_offset_to_idle]
    cfb2:	6a10      	ldr	r0, [r2, #32]
	cmp r0, #0
    cfb4:	2800      	cmp	r0, #0
	str r1, [r2, #_kernel_offset_to_idle]
	bl z_sys_power_save_idle_exit
_idle_state_cleared:

#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	ittt ne
    cfb6:	bf1e      	ittt	ne
	movne	r1, #0
    cfb8:	2100      	movne	r1, #0
		/* clear kernel idle state */
		strne	r1, [r2, #_kernel_offset_to_idle]
    cfba:	6211      	strne	r1, [r2, #32]
		blne	z_sys_power_save_idle_exit
    cfbc:	f002 fa9c 	blne	f4f8 <z_sys_power_save_idle_exit>
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */

#if defined(CONFIG_CPU_CORTEX_M)
	cpsie i		/* re-enable interrupts (PRIMASK = 0) */
    cfc0:	b662      	cpsie	i
#endif

#endif /* CONFIG_SYS_POWER_MANAGEMENT */

#if defined(CONFIG_CPU_CORTEX_M)
	mrs r0, IPSR	/* get exception number */
    cfc2:	f3ef 8005 	mrs	r0, IPSR
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
	ldr r1, =16
	subs r0, r1	/* get IRQ number */
	lsls r0, #3	/* table is 8-byte wide */
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	sub r0, r0, #16	/* get IRQ number */
    cfc6:	f1a0 0010 	sub.w	r0, r0, #16
	lsl r0, r0, #3	/* table is 8-byte wide */
    cfca:	ea4f 00c0 	mov.w	r0, r0, lsl #3
	 * interface function.
	 */
	cpsie i
#endif /* !CONFIG_CPU_CORTEX_M */

	ldr r1, =_sw_isr_table
    cfce:	4905      	ldr	r1, [pc, #20]	; (cfe4 <_isr_wrapper+0x38>)
	add r1, r1, r0	/* table entry: ISRs must have their MSB set to stay
    cfd0:	4401      	add	r1, r0
			 * in thumb mode */

	ldm r1!,{r0,r3}	/* arg in r0, ISR in r3 */
    cfd2:	c909      	ldmia	r1!, {r0, r3}
	blx r3		/* call ISR */
    cfd4:	4798      	blx	r3

#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
	pop {r0, r3}
	mov lr, r3
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	pop {r0, lr}
    cfd6:	e8bd 4001 	ldmia.w	sp!, {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */

	/* Use 'bx' instead of 'b' because 'bx' can jump further, and use
	 * 'bx' instead of 'blx' because exception return is done in
	 * z_arm_int_exit() */
	ldr r1, =z_arm_int_exit
    cfda:	4903      	ldr	r1, [pc, #12]	; (cfe8 <_isr_wrapper+0x3c>)
	bx r1
    cfdc:	4708      	bx	r1
    cfde:	0000      	.short	0x0000
	ldr r2, =_kernel
    cfe0:	20010248 	.word	0x20010248
	ldr r1, =_sw_isr_table
    cfe4:	0000f74c 	.word	0x0000f74c
	ldr r1, =z_arm_int_exit
    cfe8:	0000d031 	.word	0x0000d031

0000cfec <__start>:
 * search for a __start symbol instead, so create that alias here.
 */
SECTION_SUBSEC_FUNC(TEXT,_reset_section,__start)

#if defined(CONFIG_PLATFORM_SPECIFIC_INIT)
    bl z_platform_init
    cfec:	f002 f862 	bl	f0b4 <z_platform_init>

    /* lock interrupts: will get unlocked when switch to main task */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    cpsid i
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    movs.n r0, #_EXC_IRQ_DEFAULT_PRIO
    cff0:	2020      	movs	r0, #32
    msr BASEPRI, r0
    cff2:	f380 8811 	msr	BASEPRI, r0

    /*
     * Set PSP and use it to boot without using MSP, so that it
     * gets set to z_interrupt_stacks during initialization.
     */
    ldr r0, =z_interrupt_stacks
    cff6:	4808      	ldr	r0, [pc, #32]	; (d018 <__start+0x2c>)
    ldr r1, =CONFIG_ISR_STACK_SIZE + MPU_GUARD_ALIGN_AND_SIZE
    cff8:	f44f 6100 	mov.w	r1, #2048	; 0x800
    adds r0, r0, r1
    cffc:	1840      	adds	r0, r0, r1
    msr PSP, r0
    cffe:	f380 8809 	msr	PSP, r0
    mrs r0, CONTROL
    d002:	f3ef 8014 	mrs	r0, CONTROL
    movs r1, #2
    d006:	2102      	movs	r1, #2
    orrs r0, r1 /* CONTROL_SPSEL_Msk */
    d008:	4308      	orrs	r0, r1
    msr CONTROL, r0
    d00a:	f380 8814 	msr	CONTROL, r0
    /*
     * When changing the stack pointer, software must use an ISB instruction
     * immediately after the MSR instruction. This ensures that instructions
     * after the ISB instruction execute using the new stack pointer.
     */
    isb
    d00e:	f3bf 8f6f 	isb	sy
    /*
     * 'bl' jumps the furthest of the branch instructions that are
     * supported on all platforms. So it is used when jumping to z_arm_prep_c
     * (even though we do not intend to return).
     */
    bl z_arm_prep_c
    d012:	f7ff ff4b 	bl	ceac <z_arm_prep_c>
    d016:	0000      	.short	0x0000
    ldr r0, =z_interrupt_stacks
    d018:	200107d0 	.word	0x200107d0

0000d01c <z_arm_bus_fault>:
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
SECTION_SUBSEC_FUNC(TEXT,__fault,z_arm_exc_spurious)

	mrs r0, MSP
    d01c:	f3ef 8008 	mrs	r0, MSP
	mrs r1, PSP
    d020:	f3ef 8109 	mrs	r1, PSP
	push {r0, lr}
    d024:	b501      	push	{r0, lr}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	push {r4-r11}
#endif
	mov  r3, sp /* pointer to _callee_saved_t */
#endif /* CONFIG_EXTRA_EXCEPTION_INFO */
	mov r2, lr /* EXC_RETURN */
    d026:	4672      	mov	r2, lr
	bl z_arm_fault
    d028:	f000 f860 	bl	d0ec <z_arm_fault>
	 * in this routine. Therefore, we can just reset
	 * the MSP to its value prior to entering the function
	 */
	add sp, #40
#endif
	pop {r0, pc}
    d02c:	bd01      	pop	{r0, pc}
    d02e:	bf00      	nop

0000d030 <z_arm_exc_exit>:
 */

SECTION_SUBSEC_FUNC(TEXT, _HandlerModeExit, z_arm_exc_exit)

#ifdef CONFIG_PREEMPT_ENABLED
	ldr r3, =_kernel
    d030:	4b04      	ldr	r3, [pc, #16]	; (d044 <_EXIT_EXC+0x2>)

	ldr r1, [r3, #_kernel_offset_to_current]
    d032:	6899      	ldr	r1, [r3, #8]
	ldr r0, [r3, #_kernel_offset_to_ready_q_cache]
    d034:	6a58      	ldr	r0, [r3, #36]	; 0x24
	cmp r0, r1
    d036:	4288      	cmp	r0, r1
	beq _EXIT_EXC
    d038:	d003      	beq.n	d042 <_EXIT_EXC>

	/* context switch required, pend the PendSV exception */
	ldr r1, =_SCS_ICSR
    d03a:	4903      	ldr	r1, [pc, #12]	; (d048 <_EXIT_EXC+0x6>)
	ldr r2, =_SCS_ICSR_PENDSV
    d03c:	f04f 5280 	mov.w	r2, #268435456	; 0x10000000
	str r2, [r1]
    d040:	600a      	str	r2, [r1, #0]

0000d042 <_EXIT_EXC>:
#else
	pop {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
#endif /* CONFIG_STACK_SENTINEL */

	bx lr
    d042:	4770      	bx	lr
	ldr r3, =_kernel
    d044:	20010248 	.word	0x20010248
	ldr r1, =_SCS_ICSR
    d048:	e000ed04 	.word	0xe000ed04

0000d04c <mem_manage_fault.isra.2>:
	uint32_t reason = K_ERR_CPU_EXCEPTION;
	uint32_t mmfar = -EINVAL;

	PR_FAULT_INFO("***** MPU FAULT *****");

	if ((SCB->CFSR & SCB_CFSR_MSTKERR_Msk) != 0) {
    d04c:	4b0c      	ldr	r3, [pc, #48]	; (d080 <mem_manage_fault.isra.2+0x34>)
    d04e:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Stacking error (context area might be"
			" not valid)");
	}
	if ((SCB->CFSR & SCB_CFSR_MUNSTKERR_Msk) != 0) {
    d050:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Unstacking error");
	}
	if ((SCB->CFSR & SCB_CFSR_DACCVIOL_Msk) != 0) {
    d052:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d054:	0792      	lsls	r2, r2, #30
    d056:	d508      	bpl.n	d06a <mem_manage_fault.isra.2+0x1e>
		 * The MMFAR address is valid only if this bit is 1.
		 *
		 * Software must follow this sequence because another higher
		 * priority exception might change the MMFAR value.
		 */
		mmfar = SCB->MMFAR;
    d058:	6b5a      	ldr	r2, [r3, #52]	; 0x34

		if ((SCB->CFSR & SCB_CFSR_MMARVALID_Msk) != 0) {
    d05a:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d05c:	0612      	lsls	r2, r2, #24
    d05e:	d504      	bpl.n	d06a <mem_manage_fault.isra.2+0x1e>
			PR_EXC("  MMFAR Address: 0x%x", mmfar);
			if (from_hard_fault) {
    d060:	b118      	cbz	r0, d06a <mem_manage_fault.isra.2+0x1e>
				/* clear SCB_MMAR[VALID] to reset */
				SCB->CFSR &= ~SCB_CFSR_MMARVALID_Msk;
    d062:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d064:	f022 0280 	bic.w	r2, r2, #128	; 0x80
    d068:	629a      	str	r2, [r3, #40]	; 0x28

	/* clear MMFSR sticky bits */
	SCB->CFSR |= SCB_CFSR_MEMFAULTSR_Msk;

	/* Assess whether system shall ignore/recover from this MPU fault. */
	*recoverable = memory_fault_recoverable(esf);
    d06a:	2000      	movs	r0, #0
	if ((SCB->CFSR & SCB_CFSR_IACCVIOL_Msk) != 0) {
    d06c:	4b04      	ldr	r3, [pc, #16]	; (d080 <mem_manage_fault.isra.2+0x34>)
    d06e:	6a9a      	ldr	r2, [r3, #40]	; 0x28
	if ((SCB->CFSR & SCB_CFSR_MLSPERR_Msk) != 0) {
    d070:	6a9a      	ldr	r2, [r3, #40]	; 0x28
	if (SCB->CFSR & SCB_CFSR_MSTKERR_Msk) {
    d072:	6a9a      	ldr	r2, [r3, #40]	; 0x28
	SCB->CFSR |= SCB_CFSR_MEMFAULTSR_Msk;
    d074:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d076:	f042 02ff 	orr.w	r2, r2, #255	; 0xff
    d07a:	629a      	str	r2, [r3, #40]	; 0x28
	*recoverable = memory_fault_recoverable(esf);
    d07c:	7008      	strb	r0, [r1, #0]

	return reason;
}
    d07e:	4770      	bx	lr
    d080:	e000ed00 	.word	0xe000ed00

0000d084 <bus_fault.isra.3>:
{
	uint32_t reason = K_ERR_CPU_EXCEPTION;

	PR_FAULT_INFO("***** BUS FAULT *****");

	if (SCB->CFSR & SCB_CFSR_STKERR_Msk) {
    d084:	4b0d      	ldr	r3, [pc, #52]	; (d0bc <bus_fault.isra.3+0x38>)
    d086:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Stacking error");
	}
	if (SCB->CFSR & SCB_CFSR_UNSTKERR_Msk) {
    d088:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Unstacking error");
	}
	if (SCB->CFSR & SCB_CFSR_PRECISERR_Msk) {
    d08a:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d08c:	0592      	lsls	r2, r2, #22
    d08e:	d508      	bpl.n	d0a2 <bus_fault.isra.3+0x1e>
		 * The BFAR address is valid only if this bit is 1.
		 *
		 * Software must follow this sequence because another
		 * higher priority exception might change the BFAR value.
		 */
		STORE_xFAR(bfar, SCB->BFAR);
    d090:	6b9a      	ldr	r2, [r3, #56]	; 0x38

		if ((SCB->CFSR & SCB_CFSR_BFARVALID_Msk) != 0) {
    d092:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d094:	0412      	lsls	r2, r2, #16
    d096:	d504      	bpl.n	d0a2 <bus_fault.isra.3+0x1e>
			PR_EXC("  BFAR Address: 0x%x", bfar);
			if (from_hard_fault) {
    d098:	b118      	cbz	r0, d0a2 <bus_fault.isra.3+0x1e>
				/* clear SCB_CFSR_BFAR[VALID] to reset */
				SCB->CFSR &= ~SCB_CFSR_BFARVALID_Msk;
    d09a:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d09c:	f422 4200 	bic.w	r2, r2, #32768	; 0x8000
    d0a0:	629a      	str	r2, [r3, #40]	; 0x28
#endif /* defined(CONFIG_ARM_MPU) && defined(CONFIG_CPU_HAS_NXP_MPU) */

	/* clear BFSR sticky bits */
	SCB->CFSR |= SCB_CFSR_BUSFAULTSR_Msk;

	*recoverable = memory_fault_recoverable(esf);
    d0a2:	2000      	movs	r0, #0
	if (SCB->CFSR & SCB_CFSR_IMPRECISERR_Msk) {
    d0a4:	4b05      	ldr	r3, [pc, #20]	; (d0bc <bus_fault.isra.3+0x38>)
    d0a6:	6a9a      	ldr	r2, [r3, #40]	; 0x28
	if ((SCB->CFSR & SCB_CFSR_IBUSERR_Msk) != 0) {
    d0a8:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d0aa:	05d2      	lsls	r2, r2, #23
	} else if (SCB->CFSR & SCB_CFSR_LSPERR_Msk) {
    d0ac:	bf58      	it	pl
    d0ae:	6a9a      	ldrpl	r2, [r3, #40]	; 0x28
	SCB->CFSR |= SCB_CFSR_BUSFAULTSR_Msk;
    d0b0:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d0b2:	f442 427f 	orr.w	r2, r2, #65280	; 0xff00
    d0b6:	629a      	str	r2, [r3, #40]	; 0x28
	*recoverable = memory_fault_recoverable(esf);
    d0b8:	7008      	strb	r0, [r1, #0]

	return reason;
}
    d0ba:	4770      	bx	lr
    d0bc:	e000ed00 	.word	0xe000ed00

0000d0c0 <usage_fault.isra.4>:
	uint32_t reason = K_ERR_CPU_EXCEPTION;

	PR_FAULT_INFO("***** USAGE FAULT *****");

	/* bits are sticky: they stack and must be reset */
	if ((SCB->CFSR & SCB_CFSR_DIVBYZERO_Msk) != 0) {
    d0c0:	4b09      	ldr	r3, [pc, #36]	; (d0e8 <usage_fault.isra.4+0x28>)
    d0c2:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Division by zero");
	}
	if ((SCB->CFSR & SCB_CFSR_UNALIGNED_Msk) != 0) {
    d0c4:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Unaligned memory access");
	}
#if defined(CONFIG_ARMV8_M_MAINLINE)
	if ((SCB->CFSR & SCB_CFSR_STKOF_Msk) != 0) {
    d0c6:	6a98      	ldr	r0, [r3, #40]	; 0x28
		 */
		reason = K_ERR_STACK_CHK_FAIL;
#endif /* CONFIG_BUILTIN_STACK_GUARD */
	}
#endif /* CONFIG_ARMV8_M_MAINLINE */
	if ((SCB->CFSR & SCB_CFSR_NOCP_Msk) != 0) {
    d0c8:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  No coprocessor instructions");
	}
	if ((SCB->CFSR & SCB_CFSR_INVPC_Msk) != 0) {
    d0ca:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Illegal load of EXC_RETURN into PC");
	}
	if ((SCB->CFSR & SCB_CFSR_INVSTATE_Msk) != 0) {
    d0cc:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Illegal use of the EPSR");
	}
	if ((SCB->CFSR & SCB_CFSR_UNDEFINSTR_Msk) != 0) {
    d0ce:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Attempt to execute undefined instruction");
	}

	/* clear UFSR sticky bits */
	SCB->CFSR |= SCB_CFSR_USGFAULTSR_Msk;
    d0d0:	6a9a      	ldr	r2, [r3, #40]	; 0x28
	if ((SCB->CFSR & SCB_CFSR_STKOF_Msk) != 0) {
    d0d2:	f410 1080 	ands.w	r0, r0, #1048576	; 0x100000
	SCB->CFSR |= SCB_CFSR_USGFAULTSR_Msk;
    d0d6:	ea6f 4202 	mvn.w	r2, r2, lsl #16
    d0da:	ea6f 4212 	mvn.w	r2, r2, lsr #16

	return reason;
}
    d0de:	bf18      	it	ne
    d0e0:	2002      	movne	r0, #2
	SCB->CFSR |= SCB_CFSR_USGFAULTSR_Msk;
    d0e2:	629a      	str	r2, [r3, #40]	; 0x28
}
    d0e4:	4770      	bx	lr
    d0e6:	bf00      	nop
    d0e8:	e000ed00 	.word	0xe000ed00

0000d0ec <z_arm_fault>:
 * @param callee_regs Callee-saved registers (R4-R11, PSP)
 *
 */
void z_arm_fault(uint32_t msp, uint32_t psp, uint32_t exc_return,
	_callee_saved_t *callee_regs)
{
    d0ec:	b570      	push	{r4, r5, r6, lr}
	uint32_t reason = K_ERR_CPU_EXCEPTION;
	int fault = SCB->ICSR & SCB_ICSR_VECTACTIVE_Msk;
    d0ee:	4b3a      	ldr	r3, [pc, #232]	; (d1d8 <z_arm_fault+0xec>)
{
    d0f0:	b08a      	sub	sp, #40	; 0x28
	int fault = SCB->ICSR & SCB_ICSR_VECTACTIVE_Msk;
    d0f2:	685b      	ldr	r3, [r3, #4]
    d0f4:	2500      	movs	r5, #0
    d0f6:	f3c3 0308 	ubfx	r3, r3, #0, #9
    d0fa:	f385 8811 	msr	BASEPRI, r5
    d0fe:	f3bf 8f6f 	isb	sy
	if ((exc_return & EXC_RETURN_INDICATOR_PREFIX) !=
    d102:	f002 447f 	and.w	r4, r2, #4278190080	; 0xff000000
    d106:	f1b4 4f7f 	cmp.w	r4, #4278190080	; 0xff000000
    d10a:	d119      	bne.n	d140 <z_arm_fault+0x54>
	if (exc_return & EXC_RETURN_EXCEPTION_SECURE_Secure) {
    d10c:	07d6      	lsls	r6, r2, #31
    d10e:	d417      	bmi.n	d140 <z_arm_fault+0x54>
	if (exc_return & EXC_RETURN_RETURN_STACK_Secure) {
    d110:	0655      	lsls	r5, r2, #25
    d112:	d404      	bmi.n	d11e <z_arm_fault+0x32>
		if (exc_return & EXC_RETURN_MODE_THREAD) {
    d114:	0714      	lsls	r4, r2, #28
    d116:	d405      	bmi.n	d124 <z_arm_fault+0x38>
			ptr_esf = (z_arch_esf_t *)msp;
    d118:	4606      	mov	r6, r0
			*nested_exc = true;
    d11a:	2501      	movs	r5, #1
    d11c:	e004      	b.n	d128 <z_arm_fault+0x3c>
		if (exc_return & EXC_RETURN_SPSEL_PROCESS) {
    d11e:	f012 0504 	ands.w	r5, r2, #4
    d122:	d00b      	beq.n	d13c <z_arm_fault+0x50>
			ptr_esf = (z_arch_esf_t *)psp;
    d124:	460e      	mov	r6, r1
	*nested_exc = false;
    d126:	2500      	movs	r5, #0
	*recoverable = false;
    d128:	2200      	movs	r2, #0
	switch (fault) {
    d12a:	3b03      	subs	r3, #3
	*recoverable = false;
    d12c:	f88d 2007 	strb.w	r2, [sp, #7]
	switch (fault) {
    d130:	2b03      	cmp	r3, #3
    d132:	d849      	bhi.n	d1c8 <z_arm_fault+0xdc>
    d134:	e8df f003 	tbb	[pc, r3]
    d138:	3d444006 	.word	0x3d444006
			ptr_esf = (z_arch_esf_t *)msp;
    d13c:	4606      	mov	r6, r0
	if (!alternative_state_exc) {
    d13e:	e7f3      	b.n	d128 <z_arm_fault+0x3c>
		return NULL;
    d140:	462e      	mov	r6, r5
    d142:	e7f1      	b.n	d128 <z_arm_fault+0x3c>
	if ((SCB->HFSR & SCB_HFSR_VECTTBL_Msk) != 0) {
    d144:	4b24      	ldr	r3, [pc, #144]	; (d1d8 <z_arm_fault+0xec>)
    d146:	6ada      	ldr	r2, [r3, #44]	; 0x2c
    d148:	0792      	lsls	r2, r2, #30
    d14a:	d43d      	bmi.n	d1c8 <z_arm_fault+0xdc>
	} else if ((SCB->HFSR & SCB_HFSR_FORCED_Msk) != 0) {
    d14c:	6adc      	ldr	r4, [r3, #44]	; 0x2c
    d14e:	f014 4480 	ands.w	r4, r4, #1073741824	; 0x40000000
    d152:	d008      	beq.n	d166 <z_arm_fault+0x7a>
		if (SCB_MMFSR != 0) {
    d154:	3328      	adds	r3, #40	; 0x28
    d156:	781b      	ldrb	r3, [r3, #0]
    d158:	b1eb      	cbz	r3, d196 <z_arm_fault+0xaa>
			reason = mem_manage_fault(esf, 1, recoverable);
    d15a:	2001      	movs	r0, #1
    d15c:	f10d 0107 	add.w	r1, sp, #7
		reason = mem_manage_fault(esf, 0, recoverable);
    d160:	f7ff ff74 	bl	d04c <mem_manage_fault.isra.2>
		reason = usage_fault(esf);
    d164:	4604      	mov	r4, r0
#ifdef CONFIG_DEBUG_COREDUMP
	z_arm_coredump_fault_sp = POINTER_TO_UINT(esf);
#endif

	reason = fault_handle(esf, fault, &recoverable);
	if (recoverable) {
    d166:	f89d 3007 	ldrb.w	r3, [sp, #7]
    d16a:	b993      	cbnz	r3, d192 <z_arm_fault+0xa6>
		return;
	}

	/* Copy ESF */
#if !defined(CONFIG_EXTRA_EXCEPTION_INFO)
	memcpy(&esf_copy, esf, sizeof(z_arch_esf_t));
    d16c:	2220      	movs	r2, #32
    d16e:	4631      	mov	r1, r6
    d170:	a802      	add	r0, sp, #8
    d172:	f002 f896 	bl	f2a2 <memcpy>
	/* Overwrite stacked IPSR to mark a nested exception,
	 * or a return to Thread mode. Note that this may be
	 * required, if the retrieved ESF contents are invalid
	 * due to, for instance, a stacking error.
	 */
	if (nested_exc) {
    d176:	9b09      	ldr	r3, [sp, #36]	; 0x24
    d178:	b345      	cbz	r5, d1cc <z_arm_fault+0xe0>
		if ((esf_copy.basic.xpsr & IPSR_ISR_Msk) == 0) {
    d17a:	f3c3 0208 	ubfx	r2, r3, #0, #9
    d17e:	b922      	cbnz	r2, d18a <z_arm_fault+0x9e>
			esf_copy.basic.xpsr |= IPSR_ISR_Msk;
    d180:	ea6f 2353 	mvn.w	r3, r3, lsr #9
    d184:	ea6f 2343 	mvn.w	r3, r3, lsl #9
		}
	} else {
		esf_copy.basic.xpsr &= ~(IPSR_ISR_Msk);
    d188:	9309      	str	r3, [sp, #36]	; 0x24
	}

	z_arm_fatal_error(reason, &esf_copy);
    d18a:	a902      	add	r1, sp, #8
    d18c:	4620      	mov	r0, r4
    d18e:	f002 f834 	bl	f1fa <z_arm_fatal_error>
}
    d192:	b00a      	add	sp, #40	; 0x28
    d194:	bd70      	pop	{r4, r5, r6, pc}
		} else if (SCB_BFSR != 0) {
    d196:	4b11      	ldr	r3, [pc, #68]	; (d1dc <z_arm_fault+0xf0>)
    d198:	781b      	ldrb	r3, [r3, #0]
    d19a:	b12b      	cbz	r3, d1a8 <z_arm_fault+0xbc>
			reason = bus_fault(esf, 1, recoverable);
    d19c:	2001      	movs	r0, #1
    d19e:	f10d 0107 	add.w	r1, sp, #7
		reason = bus_fault(esf, 0, recoverable);
    d1a2:	f7ff ff6f 	bl	d084 <bus_fault.isra.3>
    d1a6:	e7dd      	b.n	d164 <z_arm_fault+0x78>
		} else if (SCB_UFSR != 0) {
    d1a8:	4b0d      	ldr	r3, [pc, #52]	; (d1e0 <z_arm_fault+0xf4>)
    d1aa:	881c      	ldrh	r4, [r3, #0]
    d1ac:	b2a4      	uxth	r4, r4
    d1ae:	2c00      	cmp	r4, #0
    d1b0:	d0d9      	beq.n	d166 <z_arm_fault+0x7a>
		reason = usage_fault(esf);
    d1b2:	f7ff ff85 	bl	d0c0 <usage_fault.isra.4>
    d1b6:	e7d5      	b.n	d164 <z_arm_fault+0x78>
		reason = mem_manage_fault(esf, 0, recoverable);
    d1b8:	f10d 0107 	add.w	r1, sp, #7
    d1bc:	2000      	movs	r0, #0
    d1be:	e7cf      	b.n	d160 <z_arm_fault+0x74>
		reason = bus_fault(esf, 0, recoverable);
    d1c0:	f10d 0107 	add.w	r1, sp, #7
    d1c4:	2000      	movs	r0, #0
    d1c6:	e7ec      	b.n	d1a2 <z_arm_fault+0xb6>
	uint32_t reason = K_ERR_CPU_EXCEPTION;
    d1c8:	2400      	movs	r4, #0
    d1ca:	e7cc      	b.n	d166 <z_arm_fault+0x7a>
		esf_copy.basic.xpsr &= ~(IPSR_ISR_Msk);
    d1cc:	f423 73ff 	bic.w	r3, r3, #510	; 0x1fe
    d1d0:	f023 0301 	bic.w	r3, r3, #1
    d1d4:	e7d8      	b.n	d188 <z_arm_fault+0x9c>
    d1d6:	bf00      	nop
    d1d8:	e000ed00 	.word	0xe000ed00
    d1dc:	e000ed29 	.word	0xe000ed29
    d1e0:	e000ed2a 	.word	0xe000ed2a

0000d1e4 <z_arm_fault_init>:
 */
void z_arm_fault_init(void)
{
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	SCB->CCR |= SCB_CCR_DIV_0_TRP_Msk;
    d1e4:	4b04      	ldr	r3, [pc, #16]	; (d1f8 <z_arm_fault_init+0x14>)
    d1e6:	695a      	ldr	r2, [r3, #20]
    d1e8:	f042 0210 	orr.w	r2, r2, #16
    d1ec:	615a      	str	r2, [r3, #20]
	 *
	 * For Non-Secure Firmware this could allow the Non-Secure Main
	 * Stack to attempt to descend into secure region, in which case a
	 * Secure Hard Fault will occur and we can track the fault from there.
	 */
	SCB->CCR |= SCB_CCR_STKOFHFNMIGN_Msk;
    d1ee:	695a      	ldr	r2, [r3, #20]
    d1f0:	f442 6280 	orr.w	r2, r2, #1024	; 0x400
    d1f4:	615a      	str	r2, [r3, #20]
#endif /* CONFIG_BUILTIN_STACK_GUARD */
}
    d1f6:	4770      	bx	lr
    d1f8:	e000ed00 	.word	0xe000ed00

0000d1fc <sys_arch_reboot>:
  __ASM volatile ("dsb 0xF":::"memory");
    d1fc:	f3bf 8f4f 	dsb	sy
__NO_RETURN __STATIC_INLINE void __NVIC_SystemReset(void)
{
  __DSB();                                                          /* Ensure all outstanding memory accesses included
                                                                       buffered write are completed before reset */
  SCB->AIRCR  = (uint32_t)((0x5FAUL << SCB_AIRCR_VECTKEY_Pos)    |
                           (SCB->AIRCR & SCB_AIRCR_PRIGROUP_Msk) |
    d200:	4905      	ldr	r1, [pc, #20]	; (d218 <sys_arch_reboot+0x1c>)
    d202:	4b06      	ldr	r3, [pc, #24]	; (d21c <sys_arch_reboot+0x20>)
    d204:	68ca      	ldr	r2, [r1, #12]
    d206:	f402 62e0 	and.w	r2, r2, #1792	; 0x700
    d20a:	4313      	orrs	r3, r2
  SCB->AIRCR  = (uint32_t)((0x5FAUL << SCB_AIRCR_VECTKEY_Pos)    |
    d20c:	60cb      	str	r3, [r1, #12]
    d20e:	f3bf 8f4f 	dsb	sy
                            SCB_AIRCR_SYSRESETREQ_Msk    );         /* Keep priority group unchanged */
  __DSB();                                                          /* Ensure completion of memory access */

  for(;;)                                                           /* wait until reset */
  {
    __NOP();
    d212:	bf00      	nop
    d214:	e7fd      	b.n	d212 <sys_arch_reboot+0x16>
    d216:	bf00      	nop
    d218:	e000ed00 	.word	0xe000ed00
    d21c:	05fa0004 	.word	0x05fa0004

0000d220 <z_arm_interrupt_init>:
 * @return N/A
 */

void z_arm_interrupt_init(void)
{
	int irq = 0;
    d220:	2300      	movs	r3, #0
    NVIC->IPR[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    d222:	2120      	movs	r1, #32
    d224:	4803      	ldr	r0, [pc, #12]	; (d234 <z_arm_interrupt_init+0x14>)
    d226:	18c2      	adds	r2, r0, r3

	for (; irq < CONFIG_NUM_IRQS; irq++) {
    d228:	3301      	adds	r3, #1
    d22a:	2b41      	cmp	r3, #65	; 0x41
    d22c:	f882 1300 	strb.w	r1, [r2, #768]	; 0x300
    d230:	d1f9      	bne.n	d226 <z_arm_interrupt_init+0x6>
		NVIC_SetPriority((IRQn_Type)irq, _IRQ_PRIO_OFFSET);
	}
}
    d232:	4770      	bx	lr
    d234:	e000e100 	.word	0xe000e100

0000d238 <z_impl_k_thread_abort>:
#include <kswap.h>
#include <wait_q.h>
#include <sys/__assert.h>

void z_impl_k_thread_abort(k_tid_t thread)
{
    d238:	b510      	push	{r4, lr}
    d23a:	4604      	mov	r4, r0
	z_thread_single_abort(thread);
    d23c:	f001 f8c2 	bl	e3c4 <z_thread_single_abort>

	if (_current == thread) {
    d240:	4b11      	ldr	r3, [pc, #68]	; (d288 <z_impl_k_thread_abort+0x50>)
    d242:	689b      	ldr	r3, [r3, #8]
    d244:	42a3      	cmp	r3, r4
    d246:	d107      	bne.n	d258 <z_impl_k_thread_abort+0x20>
  __ASM volatile ("MRS %0, ipsr" : "=r" (result) );
    d248:	f3ef 8305 	mrs	r3, IPSR
		if (arch_is_in_isr()) {
    d24c:	b183      	cbz	r3, d270 <z_impl_k_thread_abort+0x38>
			 * should no longer run after we return, so
			 * Trigger PendSV, in case we are in one of the
			 * situations where the isr check is true but there
			 * is not an implicit scheduler invocation.
			 */
			SCB->ICSR |= SCB_ICSR_PENDSVSET_Msk;
    d24e:	4a0f      	ldr	r2, [pc, #60]	; (d28c <z_impl_k_thread_abort+0x54>)
    d250:	6853      	ldr	r3, [r2, #4]
    d252:	f043 5380 	orr.w	r3, r3, #268435456	; 0x10000000
    d256:	6053      	str	r3, [r2, #4]
	__asm__ volatile(
    d258:	f04f 0320 	mov.w	r3, #32
    d25c:	f3ef 8011 	mrs	r0, BASEPRI
    d260:	f383 8811 	msr	BASEPRI, r3
    d264:	f3bf 8f6f 	isb	sy
		}
	}

	/* The abort handler might have altered the ready queue. */
	z_reschedule_unlocked();
}
    d268:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	(void) z_pend_curr_irqlock(arch_irq_lock(), wait_q, timeout);
}

static inline void z_reschedule_unlocked(void)
{
	(void) z_reschedule_irqlock(arch_irq_lock());
    d26c:	f002 b946 	b.w	f4fc <z_reschedule_irqlock>
    d270:	f04f 0320 	mov.w	r3, #32
    d274:	f3ef 8011 	mrs	r0, BASEPRI
    d278:	f383 8811 	msr	BASEPRI, r3
    d27c:	f3bf 8f6f 	isb	sy

static inline int z_swap_irqlock(unsigned int key)
{
	int ret;
	z_check_stack_sentinel();
	ret = arch_swap(key);
    d280:	f7ff fd8e 	bl	cda0 <arch_swap>
	return ret;
    d284:	e7e8      	b.n	d258 <z_impl_k_thread_abort+0x20>
    d286:	bf00      	nop
    d288:	20010248 	.word	0x20010248
    d28c:	e000ed00 	.word	0xe000ed00

0000d290 <z_arm_configure_static_mpu_regions>:
 *
 * For some MPU architectures, such as the unmodified ARMv8-M MPU,
 * the function must execute with MPU enabled.
 */
void z_arm_configure_static_mpu_regions(void)
{
    d290:	b510      	push	{r4, lr}
		.size = (uint32_t)&_nocache_ram_size,
		.attr = K_MEM_PARTITION_P_RW_U_NA_NOCACHE,
		};
#endif /* CONFIG_NOCACHE_MEMORY */
#if defined(CONFIG_ARCH_HAS_RAMFUNC_SUPPORT)
		const struct k_mem_partition ramfunc_region =
    d292:	4b0e      	ldr	r3, [pc, #56]	; (d2cc <z_arm_configure_static_mpu_regions+0x3c>)
{
    d294:	b088      	sub	sp, #32
		const struct k_mem_partition ramfunc_region =
    d296:	9302      	str	r3, [sp, #8]
    d298:	4b0d      	ldr	r3, [pc, #52]	; (d2d0 <z_arm_configure_static_mpu_regions+0x40>)
	/* Configure the static MPU regions within firmware SRAM boundaries.
	 * Start address of the image is given by _image_ram_start. The end
	 * of the firmware SRAM area is marked by __kernel_ram_end, taking
	 * into account the unused SRAM area, as well.
	 */
	arm_core_mpu_configure_static_mpu_regions(static_regions,
    d29a:	4c0e      	ldr	r4, [pc, #56]	; (d2d4 <z_arm_configure_static_mpu_regions+0x44>)
		const struct k_mem_partition ramfunc_region =
    d29c:	9303      	str	r3, [sp, #12]
    d29e:	4b0e      	ldr	r3, [pc, #56]	; (d2d8 <z_arm_configure_static_mpu_regions+0x48>)
	arm_core_mpu_configure_static_mpu_regions(static_regions,
    d2a0:	4a0e      	ldr	r2, [pc, #56]	; (d2dc <z_arm_configure_static_mpu_regions+0x4c>)
		const struct k_mem_partition ramfunc_region =
    d2a2:	9304      	str	r3, [sp, #16]
	const struct k_mem_partition *static_regions[] = {
    d2a4:	ab02      	add	r3, sp, #8
    d2a6:	9301      	str	r3, [sp, #4]
	arm_core_mpu_configure_static_mpu_regions(static_regions,
    d2a8:	a801      	add	r0, sp, #4
    d2aa:	4623      	mov	r3, r4
    d2ac:	2101      	movs	r1, #1
    d2ae:	f000 f903 	bl	d4b8 <arm_core_mpu_configure_static_mpu_regions>
	/* Define a constant array of k_mem_partition objects that holds the
	 * boundaries of the areas, inside which dynamic region programming
	 * is allowed. The information is passed to the underlying driver at
	 * initialization.
	 */
	const struct k_mem_partition dyn_region_areas[] = {
    d2b2:	2300      	movs	r3, #0
    d2b4:	9307      	str	r3, [sp, #28]
		{
		.start = _MPU_DYNAMIC_REGIONS_AREA_START,
    d2b6:	4b0a      	ldr	r3, [pc, #40]	; (d2e0 <z_arm_configure_static_mpu_regions+0x50>)
		.size =  _MPU_DYNAMIC_REGIONS_AREA_SIZE,
		}
	};

	arm_core_mpu_mark_areas_for_dynamic_regions(dyn_region_areas,
    d2b8:	2101      	movs	r1, #1
		.size =  _MPU_DYNAMIC_REGIONS_AREA_SIZE,
    d2ba:	1ae4      	subs	r4, r4, r3
	arm_core_mpu_mark_areas_for_dynamic_regions(dyn_region_areas,
    d2bc:	a805      	add	r0, sp, #20
	const struct k_mem_partition dyn_region_areas[] = {
    d2be:	9305      	str	r3, [sp, #20]
    d2c0:	9406      	str	r4, [sp, #24]
	arm_core_mpu_mark_areas_for_dynamic_regions(dyn_region_areas,
    d2c2:	f000 f903 	bl	d4cc <arm_core_mpu_mark_areas_for_dynamic_regions>
		ARRAY_SIZE(dyn_region_areas));
#endif /* CONFIG_MPU_REQUIRES_NON_OVERLAPPING_REGIONS */
}
    d2c6:	b008      	add	sp, #32
    d2c8:	bd10      	pop	{r4, pc}
    d2ca:	bf00      	nop
    d2cc:	20010000 	.word	0x20010000
    d2d0:	00000000 	.word	0x00000000
    d2d4:	20040000 	.word	0x20040000
    d2d8:	00010006 	.word	0x00010006
    d2dc:	20010000 	.word	0x20010000
    d2e0:	20010090 	.word	0x20010090

0000d2e4 <region_init>:
 * Note:
 *   The caller must provide a valid region index.
 */
static void region_init(const uint32_t index,
	const struct arm_mpu_region *region_conf)
{
    d2e4:	b510      	push	{r4, lr}
	ARM_MPU_SetRegion(
		/* RNR */
		index,
		/* RBAR */
		(region_conf->base & MPU_RBAR_BASE_Msk)
    d2e6:	680b      	ldr	r3, [r1, #0]
		| (region_conf->attr.rbar &
    d2e8:	7a0c      	ldrb	r4, [r1, #8]
		(region_conf->base & MPU_RBAR_BASE_Msk)
    d2ea:	f023 021f 	bic.w	r2, r3, #31
		| (region_conf->attr.rbar &
    d2ee:	f004 031f 	and.w	r3, r4, #31
    d2f2:	431a      	orrs	r2, r3
			(MPU_RBAR_XN_Msk | MPU_RBAR_AP_Msk | MPU_RBAR_SH_Msk)),
		/* RLAR */
		(region_conf->attr.r_limit & MPU_RLAR_LIMIT_Msk)
    d2f4:	68cb      	ldr	r3, [r1, #12]
		| ((region_conf->attr.mair_idx << MPU_RLAR_AttrIndx_Pos)
    d2f6:	0964      	lsrs	r4, r4, #5
		(region_conf->attr.r_limit & MPU_RLAR_LIMIT_Msk)
    d2f8:	f023 031f 	bic.w	r3, r3, #31
* \param rbar Value for RBAR register.
* \param rlar Value for RLAR register.
*/   
__STATIC_INLINE void ARM_MPU_SetRegionEx(MPU_Type* mpu, uint32_t rnr, uint32_t rbar, uint32_t rlar)
{
  mpu->RNR = rnr;
    d2fc:	4904      	ldr	r1, [pc, #16]	; (d310 <region_init+0x2c>)
		| ((region_conf->attr.mair_idx << MPU_RLAR_AttrIndx_Pos)
    d2fe:	ea43 0344 	orr.w	r3, r3, r4, lsl #1
			& MPU_RLAR_AttrIndx_Msk)
		| MPU_RLAR_EN_Msk
    d302:	f043 0301 	orr.w	r3, r3, #1
    d306:	6088      	str	r0, [r1, #8]
  mpu->RBAR = rbar;
    d308:	60ca      	str	r2, [r1, #12]
  mpu->RLAR = rlar;
    d30a:	610b      	str	r3, [r1, #16]
	);

	LOG_DBG("[%d] 0x%08x 0x%08x 0x%08x 0x%08x",
			index, region_conf->base, region_conf->attr.rbar,
			region_conf->attr.mair_idx, region_conf->attr.r_limit);
}
    d30c:	bd10      	pop	{r4, pc}
    d30e:	bf00      	nop
    d310:	e000ed90 	.word	0xe000ed90

0000d314 <mpu_configure_regions_and_partition.constprop.1>:
 * sanity check of the memory regions to be programmed.
 *
 * The function performs a full partition of the background memory
 * area, effectively, leaving no space in this area uncovered by MPU.
 */
static int mpu_configure_regions_and_partition(const struct k_mem_partition
    d314:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    d318:	4680      	mov	r8, r0
    d31a:	4689      	mov	r9, r1
    d31c:	4614      	mov	r4, r2
	bool do_sanity_check)
{
	int i;
	int reg_index = start_reg_index;

	for (i = 0; i < regions_num; i++) {
    d31e:	2700      	movs	r7, #0
	MPU->RNR = index;
    d320:	4d48      	ldr	r5, [pc, #288]	; (d444 <mpu_configure_regions_and_partition.constprop.1+0x130>)
static int mpu_configure_regions_and_partition(const struct k_mem_partition
    d322:	b085      	sub	sp, #20
	for (i = 0; i < regions_num; i++) {
    d324:	454f      	cmp	r7, r9
    d326:	da07      	bge.n	d338 <mpu_configure_regions_and_partition.constprop.1+0x24>
		if (regions[i]->size == 0U) {
    d328:	f858 3027 	ldr.w	r3, [r8, r7, lsl #2]
    d32c:	685e      	ldr	r6, [r3, #4]
    d32e:	b3c6      	cbz	r6, d3a2 <mpu_configure_regions_and_partition.constprop.1+0x8e>
		&&
    d330:	2e1f      	cmp	r6, #31
    d332:	d805      	bhi.n	d340 <mpu_configure_regions_and_partition.constprop.1+0x2c>

			reg_index =
				mpu_configure_region(reg_index, regions[i]);

			if (reg_index == -EINVAL) {
				return reg_index;
    d334:	f06f 0415 	mvn.w	r4, #21
			reg_index++;
		}
	}

	return reg_index;
}
    d338:	4620      	mov	r0, r4
    d33a:	b005      	add	sp, #20
    d33c:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
		&&
    d340:	06f2      	lsls	r2, r6, #27
    d342:	d1f7      	bne.n	d334 <mpu_configure_regions_and_partition.constprop.1+0x20>
		((part->start &
    d344:	f8d3 a000 	ldr.w	sl, [r3]
		&&
    d348:	f01a 0f1f 	tst.w	sl, #31
    d34c:	d1f2      	bne.n	d334 <mpu_configure_regions_and_partition.constprop.1+0x20>
	uint32_t region_start_addr = arm_cmse_mpu_region_get(start);
    d34e:	4650      	mov	r0, sl
    d350:	f001 ff82 	bl	f258 <arm_cmse_mpu_region_get>
    d354:	4683      	mov	fp, r0
	uint32_t region_end_addr = arm_cmse_mpu_region_get(start + size - 1);
    d356:	eb06 000a 	add.w	r0, r6, sl
    d35a:	3801      	subs	r0, #1
    d35c:	f001 ff7c 	bl	f258 <arm_cmse_mpu_region_get>
	if (region_start_addr == region_end_addr) {
    d360:	4583      	cmp	fp, r0
    d362:	d1e7      	bne.n	d334 <mpu_configure_regions_and_partition.constprop.1+0x20>
		if ((u_reg_index == -EINVAL) ||
    d364:	f11b 0f16 	cmn.w	fp, #22
    d368:	d0e4      	beq.n	d334 <mpu_configure_regions_and_partition.constprop.1+0x20>
			(u_reg_index > (reg_index - 1))) {
    d36a:	1e63      	subs	r3, r4, #1
		if ((u_reg_index == -EINVAL) ||
    d36c:	455b      	cmp	r3, fp
    d36e:	dbe1      	blt.n	d334 <mpu_configure_regions_and_partition.constprop.1+0x20>
	MPU->RNR = index;
    d370:	f8c5 b008 	str.w	fp, [r5, #8]
	return MPU->RBAR & MPU_RBAR_BASE_Msk;
    d374:	68e8      	ldr	r0, [r5, #12]
		uint32_t reg_last = regions[i]->start + regions[i]->size - 1;
    d376:	f858 1027 	ldr.w	r1, [r8, r7, lsl #2]
	MPU->RNR = index;
    d37a:	f8c5 b008 	str.w	fp, [r5, #8]
	return (MPU->RLAR & MPU_RLAR_LIMIT_Msk) | (~MPU_RLAR_LIMIT_Msk);
    d37e:	692e      	ldr	r6, [r5, #16]
	return MPU->RBAR & MPU_RBAR_BASE_Msk;
    d380:	f020 001f 	bic.w	r0, r0, #31
		uint32_t reg_last = regions[i]->start + regions[i]->size - 1;
    d384:	e9d1 3200 	ldrd	r3, r2, [r1]
    d388:	441a      	add	r2, r3
		if ((regions[i]->start == u_reg_base) &&
    d38a:	4298      	cmp	r0, r3
	return (MPU->RLAR & MPU_RLAR_LIMIT_Msk) | (~MPU_RLAR_LIMIT_Msk);
    d38c:	f046 061f 	orr.w	r6, r6, #31
		uint32_t reg_last = regions[i]->start + regions[i]->size - 1;
    d390:	f102 3aff 	add.w	sl, r2, #4294967295	; 0xffffffff
		if ((regions[i]->start == u_reg_base) &&
    d394:	d118      	bne.n	d3c8 <mpu_configure_regions_and_partition.constprop.1+0xb4>
    d396:	4556      	cmp	r6, sl
    d398:	d105      	bne.n	d3a6 <mpu_configure_regions_and_partition.constprop.1+0x92>
			mpu_configure_region(u_reg_index, regions[i]);
    d39a:	fa5f f08b 	uxtb.w	r0, fp
    d39e:	f001 ff39 	bl	f214 <mpu_configure_region>
	for (i = 0; i < regions_num; i++) {
    d3a2:	3701      	adds	r7, #1
    d3a4:	e7be      	b.n	d324 <mpu_configure_regions_and_partition.constprop.1+0x10>
	MPU->RNR = index;
    d3a6:	f8c5 b008 	str.w	fp, [r5, #8]
	MPU->RBAR = (MPU->RBAR & (~MPU_RBAR_BASE_Msk))
    d3aa:	68eb      	ldr	r3, [r5, #12]
		| (base & MPU_RBAR_BASE_Msk);
    d3ac:	f022 021f 	bic.w	r2, r2, #31
	MPU->RBAR = (MPU->RBAR & (~MPU_RBAR_BASE_Msk))
    d3b0:	f003 031f 	and.w	r3, r3, #31
		| (base & MPU_RBAR_BASE_Msk);
    d3b4:	431a      	orrs	r2, r3
	MPU->RBAR = (MPU->RBAR & (~MPU_RBAR_BASE_Msk))
    d3b6:	60ea      	str	r2, [r5, #12]
				mpu_configure_region(reg_index, regions[i]);
    d3b8:	b2e0      	uxtb	r0, r4
				mpu_configure_region(reg_index, regions[i]);
    d3ba:	f001 ff2b 	bl	f214 <mpu_configure_region>
			if (reg_index == -EINVAL) {
    d3be:	f110 0f16 	cmn.w	r0, #22
    d3c2:	d0b7      	beq.n	d334 <mpu_configure_regions_and_partition.constprop.1+0x20>
			reg_index++;
    d3c4:	1c44      	adds	r4, r0, #1
    d3c6:	e7ec      	b.n	d3a2 <mpu_configure_regions_and_partition.constprop.1+0x8e>
	MPU->RNR = index;
    d3c8:	f8c5 b008 	str.w	fp, [r5, #8]
	MPU->RLAR = (MPU->RLAR & (~MPU_RLAR_LIMIT_Msk))
    d3cc:	692a      	ldr	r2, [r5, #16]
    d3ce:	3b01      	subs	r3, #1
    d3d0:	f023 031f 	bic.w	r3, r3, #31
    d3d4:	f002 021f 	and.w	r2, r2, #31
		| (limit & MPU_RLAR_LIMIT_Msk);
    d3d8:	4313      	orrs	r3, r2
		} else if (reg_last == u_reg_last) {
    d3da:	4556      	cmp	r6, sl
    d3dc:	b2e0      	uxtb	r0, r4
	MPU->RLAR = (MPU->RLAR & (~MPU_RLAR_LIMIT_Msk))
    d3de:	612b      	str	r3, [r5, #16]
		} else if (reg_last == u_reg_last) {
    d3e0:	d0eb      	beq.n	d3ba <mpu_configure_regions_and_partition.constprop.1+0xa6>
				mpu_configure_region(reg_index, regions[i]);
    d3e2:	f001 ff17 	bl	f214 <mpu_configure_region>
			if (reg_index == -EINVAL) {
    d3e6:	f110 0f16 	cmn.w	r0, #22
    d3ea:	d0a3      	beq.n	d334 <mpu_configure_regions_and_partition.constprop.1+0x20>
	MPU->RNR = index;
    d3ec:	f8c5 b008 	str.w	fp, [r5, #8]
	attr->rbar = MPU->RBAR &
    d3f0:	68ea      	ldr	r2, [r5, #12]
    d3f2:	f89d 3008 	ldrb.w	r3, [sp, #8]
			REGION_LIMIT_ADDR((regions[i]->start +
    d3f6:	3e01      	subs	r6, #1
	attr->rbar = MPU->RBAR &
    d3f8:	f362 0304 	bfi	r3, r2, #0, #5
    d3fc:	f88d 3008 	strb.w	r3, [sp, #8]
	attr->mair_idx = (MPU->RLAR & MPU_RLAR_AttrIndx_Msk) >>
    d400:	692b      	ldr	r3, [r5, #16]
    d402:	f89d 2008 	ldrb.w	r2, [sp, #8]
    d406:	085b      	lsrs	r3, r3, #1
    d408:	f363 1247 	bfi	r2, r3, #5, #3
    d40c:	f88d 2008 	strb.w	r2, [sp, #8]
			fill_region.base = regions[i]->start +
    d410:	f858 2027 	ldr.w	r2, [r8, r7, lsl #2]
			reg_index++;
    d414:	3001      	adds	r0, #1
			fill_region.base = regions[i]->start +
    d416:	e9d2 3200 	ldrd	r3, r2, [r2]
    d41a:	4413      	add	r3, r2
    d41c:	9300      	str	r3, [sp, #0]
			REGION_LIMIT_ADDR((regions[i]->start +
    d41e:	f023 031f 	bic.w	r3, r3, #31
    d422:	441e      	add	r6, r3
    d424:	eba6 060a 	sub.w	r6, r6, sl
    d428:	b2c4      	uxtb	r4, r0
    d42a:	f026 061f 	bic.w	r6, r6, #31

static int region_allocate_and_init(const uint8_t index,
	const struct arm_mpu_region *region_conf)
{
	/* Attempt to allocate new region index. */
	if (index > (get_num_regions() - 1)) {
    d42e:	2c0f      	cmp	r4, #15
			fill_region.attr.r_limit =
    d430:	9603      	str	r6, [sp, #12]
    d432:	f63f af7f 	bhi.w	d334 <mpu_configure_regions_and_partition.constprop.1+0x20>
	}

	LOG_DBG("Program MPU region at index 0x%x", index);

	/* Program region */
	region_init(index, region_conf);
    d436:	4620      	mov	r0, r4
    d438:	4669      	mov	r1, sp
    d43a:	f7ff ff53 	bl	d2e4 <region_init>
			reg_index++;
    d43e:	3401      	adds	r4, #1
    d440:	e7af      	b.n	d3a2 <mpu_configure_regions_and_partition.constprop.1+0x8e>
    d442:	bf00      	nop
    d444:	e000ed90 	.word	0xe000ed90

0000d448 <arm_core_mpu_enable>:
void arm_core_mpu_enable(void)
{
	/* Enable MPU and use the default memory map as a
	 * background region for privileged software access.
	 */
	MPU->CTRL = MPU_CTRL_ENABLE_Msk | MPU_CTRL_PRIVDEFENA_Msk;
    d448:	2205      	movs	r2, #5
    d44a:	4b03      	ldr	r3, [pc, #12]	; (d458 <arm_core_mpu_enable+0x10>)
    d44c:	605a      	str	r2, [r3, #4]
  __ASM volatile ("dsb 0xF":::"memory");
    d44e:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
    d452:	f3bf 8f6f 	isb	sy

	/* Make sure that all the registers are set before proceeding */
	__DSB();
	__ISB();
}
    d456:	4770      	bx	lr
    d458:	e000ed90 	.word	0xe000ed90

0000d45c <arm_core_mpu_disable>:
  \details Ensures the apparent order of the explicit memory operations before
           and after the instruction, without ensuring their completion.
 */
__STATIC_FORCEINLINE void __DMB(void)
{
  __ASM volatile ("dmb 0xF":::"memory");
    d45c:	f3bf 8f5f 	dmb	sy
{
	/* Force any outstanding transfers to complete before disabling MPU */
	__DMB();

	/* Disable MPU */
	MPU->CTRL = 0;
    d460:	2200      	movs	r2, #0
    d462:	4b01      	ldr	r3, [pc, #4]	; (d468 <arm_core_mpu_disable+0xc>)
    d464:	605a      	str	r2, [r3, #4]
}
    d466:	4770      	bx	lr
    d468:	e000ed90 	.word	0xe000ed90

0000d46c <arm_mpu_init>:
 *
 * This function provides the default configuration mechanism for the Memory
 * Protection Unit (MPU).
 */
static int arm_mpu_init(const struct device *arg)
{
    d46c:	b570      	push	{r4, r5, r6, lr}
	uint32_t r_index;

	if (mpu_config.num_regions > get_num_regions()) {
    d46e:	4d0e      	ldr	r5, [pc, #56]	; (d4a8 <arm_mpu_init+0x3c>)
    d470:	682e      	ldr	r6, [r5, #0]
    d472:	2e10      	cmp	r6, #16
    d474:	d815      	bhi.n	d4a2 <arm_mpu_init+0x36>

	/* Architecture-specific configuration */
	mpu_init();

	/* Program fixed regions configured at SOC definition. */
	for (r_index = 0U; r_index < mpu_config.num_regions; r_index++) {
    d476:	2400      	movs	r4, #0
	arm_core_mpu_disable();
    d478:	f7ff fff0 	bl	d45c <arm_core_mpu_disable>
	MPU->MAIR0 =
    d47c:	4b0b      	ldr	r3, [pc, #44]	; (d4ac <arm_mpu_init+0x40>)
    d47e:	4a0c      	ldr	r2, [pc, #48]	; (d4b0 <arm_mpu_init+0x44>)
    d480:	631a      	str	r2, [r3, #48]	; 0x30
	for (r_index = 0U; r_index < mpu_config.num_regions; r_index++) {
    d482:	42a6      	cmp	r6, r4
    d484:	d105      	bne.n	d492 <arm_mpu_init+0x26>
		region_init(r_index, &mpu_config.mpu_regions[r_index]);
	}

	/* Update the number of programmed MPU regions. */
	static_regions_num = mpu_config.num_regions;
    d486:	4b0b      	ldr	r3, [pc, #44]	; (d4b4 <arm_mpu_init+0x48>)
    d488:	701e      	strb	r6, [r3, #0]


	arm_core_mpu_enable();
    d48a:	f7ff ffdd 	bl	d448 <arm_core_mpu_enable>
	__ASSERT(
		(MPU->TYPE & MPU_TYPE_DREGION_Msk) >> MPU_TYPE_DREGION_Pos ==
		NUM_MPU_REGIONS,
		"Invalid number of MPU regions\n");
#endif /* CORTEX_M0PLUS || CPU_CORTEX_M3 || CPU_CORTEX_M4 */
	return 0;
    d48e:	2000      	movs	r0, #0
}
    d490:	bd70      	pop	{r4, r5, r6, pc}
		region_init(r_index, &mpu_config.mpu_regions[r_index]);
    d492:	6869      	ldr	r1, [r5, #4]
    d494:	4620      	mov	r0, r4
    d496:	eb01 1104 	add.w	r1, r1, r4, lsl #4
    d49a:	f7ff ff23 	bl	d2e4 <region_init>
	for (r_index = 0U; r_index < mpu_config.num_regions; r_index++) {
    d49e:	3401      	adds	r4, #1
    d4a0:	e7ef      	b.n	d482 <arm_mpu_init+0x16>
		return -1;
    d4a2:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    d4a6:	e7f3      	b.n	d490 <arm_mpu_init+0x24>
    d4a8:	0000f9d8 	.word	0x0000f9d8
    d4ac:	e000ed90 	.word	0xe000ed90
    d4b0:	0044ffaa 	.word	0x0044ffaa
    d4b4:	20010289 	.word	0x20010289

0000d4b8 <arm_core_mpu_configure_static_mpu_regions>:
{
    d4b8:	b510      	push	{r4, lr}
static int mpu_configure_static_mpu_regions(const struct k_mem_partition
	*static_regions[], const uint8_t regions_num,
	const uint32_t background_area_base,
	const uint32_t background_area_end)
{
	int mpu_reg_index = static_regions_num;
    d4ba:	4c03      	ldr	r4, [pc, #12]	; (d4c8 <arm_core_mpu_configure_static_mpu_regions+0x10>)
	 * given boundaries.
	 */
	ARG_UNUSED(background_area_base);
	ARG_UNUSED(background_area_end);

	mpu_reg_index = mpu_configure_regions_and_partition(static_regions,
    d4bc:	7822      	ldrb	r2, [r4, #0]
    d4be:	f7ff ff29 	bl	d314 <mpu_configure_regions_and_partition.constprop.1>
		regions_num, mpu_reg_index, true);

	static_regions_num = mpu_reg_index;
    d4c2:	7020      	strb	r0, [r4, #0]
}
    d4c4:	bd10      	pop	{r4, pc}
    d4c6:	bf00      	nop
    d4c8:	20010289 	.word	0x20010289

0000d4cc <arm_core_mpu_mark_areas_for_dynamic_regions>:
{
    d4cc:	e92d 4ff7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, sl, fp, lr}
    d4d0:	4c25      	ldr	r4, [pc, #148]	; (d568 <arm_core_mpu_mark_areas_for_dynamic_regions+0x9c>)
    d4d2:	468a      	mov	sl, r1
{
	/* In ARMv8-M architecture we need to store the index values
	 * and the default configuration of the MPU regions, inside
	 * which dynamic memory regions may be programmed at run-time.
	 */
	for (int i = 0; i < dyn_region_areas_num; i++) {
    d4d4:	4680      	mov	r8, r0
    d4d6:	2700      	movs	r7, #0
    d4d8:	46a1      	mov	r9, r4
	attr->rbar = MPU->RBAR &
    d4da:	f04f 0b14 	mov.w	fp, #20
	MPU->RNR = index;
    d4de:	4d23      	ldr	r5, [pc, #140]	; (d56c <arm_core_mpu_mark_areas_for_dynamic_regions+0xa0>)
	for (int i = 0; i < dyn_region_areas_num; i++) {
    d4e0:	4557      	cmp	r7, sl
    d4e2:	da1a      	bge.n	d51a <arm_core_mpu_mark_areas_for_dynamic_regions+0x4e>
		if (dyn_region_areas[i].size == 0U) {
    d4e4:	f8d8 3004 	ldr.w	r3, [r8, #4]
    d4e8:	9301      	str	r3, [sp, #4]
    d4ea:	2b00      	cmp	r3, #0
    d4ec:	d036      	beq.n	d55c <arm_core_mpu_mark_areas_for_dynamic_regions+0x90>
		}
		/* Non-empty area */

		/* Retrieve HW MPU region index */
		dyn_reg_info[i].index =
			get_region_index(dyn_region_areas[i].start,
    d4ee:	f8d8 1000 	ldr.w	r1, [r8]
	uint32_t region_start_addr = arm_cmse_mpu_region_get(start);
    d4f2:	4608      	mov	r0, r1
    d4f4:	9100      	str	r1, [sp, #0]
    d4f6:	f001 feaf 	bl	f258 <arm_cmse_mpu_region_get>
	uint32_t region_end_addr = arm_cmse_mpu_region_get(start + size - 1);
    d4fa:	e9dd 1300 	ldrd	r1, r3, [sp]
	uint32_t region_start_addr = arm_cmse_mpu_region_get(start);
    d4fe:	4606      	mov	r6, r0
	uint32_t region_end_addr = arm_cmse_mpu_region_get(start + size - 1);
    d500:	1858      	adds	r0, r3, r1
    d502:	3801      	subs	r0, #1
    d504:	f001 fea8 	bl	f258 <arm_cmse_mpu_region_get>
	if (region_start_addr == region_end_addr) {
    d508:	4286      	cmp	r6, r0
    d50a:	4a19      	ldr	r2, [pc, #100]	; (d570 <arm_core_mpu_mark_areas_for_dynamic_regions+0xa4>)
    d50c:	d008      	beq.n	d520 <arm_core_mpu_mark_areas_for_dynamic_regions+0x54>
		dyn_reg_info[i].index =
    d50e:	2314      	movs	r3, #20
    d510:	435f      	muls	r7, r3
    d512:	f06f 0315 	mvn.w	r3, #21
    d516:	f849 3007 	str.w	r3, [r9, r7]
}
    d51a:	b003      	add	sp, #12
    d51c:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
					dyn_region_areas[i].size);

		if (dyn_reg_info[i].index == -EINVAL) {
    d520:	f116 0f16 	cmn.w	r6, #22
		dyn_reg_info[i].index =
    d524:	6026      	str	r6, [r4, #0]
		if (dyn_reg_info[i].index == -EINVAL) {
    d526:	d0f8      	beq.n	d51a <arm_core_mpu_mark_areas_for_dynamic_regions+0x4e>

			return -EINVAL;
		}

		if (dyn_reg_info[i].index >= static_regions_num) {
    d528:	7813      	ldrb	r3, [r2, #0]
    d52a:	42b3      	cmp	r3, r6
    d52c:	ddf5      	ble.n	d51a <arm_core_mpu_mark_areas_for_dynamic_regions+0x4e>
	attr->rbar = MPU->RBAR &
    d52e:	fb0b 9307 	mla	r3, fp, r7, r9
	MPU->RNR = index;
    d532:	60ae      	str	r6, [r5, #8]
	MPU->RNR = index;
    d534:	60ae      	str	r6, [r5, #8]
	attr->rbar = MPU->RBAR &
    d536:	68e8      	ldr	r0, [r5, #12]
    d538:	7b19      	ldrb	r1, [r3, #12]
    d53a:	f360 0104 	bfi	r1, r0, #0, #5
    d53e:	7319      	strb	r1, [r3, #12]
	attr->mair_idx = (MPU->RLAR & MPU_RLAR_AttrIndx_Msk) >>
    d540:	6929      	ldr	r1, [r5, #16]
    d542:	7b18      	ldrb	r0, [r3, #12]
    d544:	0849      	lsrs	r1, r1, #1
    d546:	f361 1047 	bfi	r0, r1, #5, #3
    d54a:	7318      	strb	r0, [r3, #12]
	region_conf->base = (MPU->RBAR & MPU_RBAR_BASE_Msk);
    d54c:	68eb      	ldr	r3, [r5, #12]
    d54e:	f023 031f 	bic.w	r3, r3, #31
    d552:	6063      	str	r3, [r4, #4]
	region_conf->attr.r_limit = MPU->RLAR & MPU_RLAR_LIMIT_Msk;
    d554:	692b      	ldr	r3, [r5, #16]
    d556:	f023 031f 	bic.w	r3, r3, #31
    d55a:	6123      	str	r3, [r4, #16]
	for (int i = 0; i < dyn_region_areas_num; i++) {
    d55c:	3701      	adds	r7, #1
    d55e:	3414      	adds	r4, #20
    d560:	f108 080c 	add.w	r8, r8, #12
    d564:	e7bc      	b.n	d4e0 <arm_core_mpu_mark_areas_for_dynamic_regions+0x14>
    d566:	bf00      	nop
    d568:	2001020c 	.word	0x2001020c
    d56c:	e000ed90 	.word	0xe000ed90
    d570:	20010289 	.word	0x20010289

0000d574 <__stdout_hook_install>:

static int (*_stdout_hook)(int) = _stdout_hook_default;

void __stdout_hook_install(int (*hook)(int))
{
	_stdout_hook = hook;
    d574:	4b01      	ldr	r3, [pc, #4]	; (d57c <__stdout_hook_install+0x8>)
    d576:	6018      	str	r0, [r3, #0]
}
    d578:	4770      	bx	lr
    d57a:	bf00      	nop
    d57c:	20010004 	.word	0x20010004

0000d580 <nrf_gpio_cfg_sense_set>:

NRF_STATIC_INLINE void nrf_gpio_cfg_sense_set(uint32_t             pin_number,
                                              nrf_gpio_pin_sense_t sense_config)
{
    NRF_GPIO_Type * reg = nrf_gpio_pin_port_decode(&pin_number);
    uint32_t cnf = reg->PIN_CNF[pin_number] & ~GPIO_PIN_CNF_SENSE_Msk;
    d580:	4b06      	ldr	r3, [pc, #24]	; (d59c <nrf_gpio_cfg_sense_set+0x1c>)
}

NRF_STATIC_INLINE uint32_t nrf_gpio_pin_port_number_extract(uint32_t * p_pin)
{
    uint32_t pin_number = *p_pin;
    *p_pin = pin_number & 0x1F;
    d582:	f000 001f 	and.w	r0, r0, #31
    d586:	eb03 0080 	add.w	r0, r3, r0, lsl #2
    uint32_t cnf = reg->PIN_CNF[pin_number] & ~GPIO_PIN_CNF_SENSE_Msk;
    d58a:	f8d0 3200 	ldr.w	r3, [r0, #512]	; 0x200
    d58e:	f423 3340 	bic.w	r3, r3, #196608	; 0x30000
    reg->PIN_CNF[pin_number] = cnf | (sense_config << GPIO_PIN_CNF_SENSE_Pos);
    d592:	ea43 4101 	orr.w	r1, r3, r1, lsl #16
    d596:	f8c0 1200 	str.w	r1, [r0, #512]	; 0x200
}
    d59a:	4770      	bx	lr
    d59c:	40842500 	.word	0x40842500

0000d5a0 <gpio_nrfx_init>:
}

#define GPIOTE_NODE DT_INST(0, nordic_nrf_gpiote)

static int gpio_nrfx_init(const struct device *port)
{
    d5a0:	b508      	push	{r3, lr}
	static bool gpio_initialized;

	if (!gpio_initialized) {
    d5a2:	4b09      	ldr	r3, [pc, #36]	; (d5c8 <gpio_nrfx_init+0x28>)
    d5a4:	781a      	ldrb	r2, [r3, #0]
    d5a6:	b96a      	cbnz	r2, d5c4 <gpio_nrfx_init+0x24>
		gpio_initialized = true;
    d5a8:	2101      	movs	r1, #1
		IRQ_CONNECT(DT_IRQN(GPIOTE_NODE), DT_IRQ(GPIOTE_NODE, priority),
    d5aa:	2031      	movs	r0, #49	; 0x31
		gpio_initialized = true;
    d5ac:	7019      	strb	r1, [r3, #0]
		IRQ_CONNECT(DT_IRQN(GPIOTE_NODE), DT_IRQ(GPIOTE_NODE, priority),
    d5ae:	2105      	movs	r1, #5
    d5b0:	f7ff fc2e 	bl	ce10 <z_arm_irq_priority_set>
			    gpiote_event_handler, NULL, 0);

		irq_enable(DT_IRQN(GPIOTE_NODE));
    d5b4:	2031      	movs	r0, #49	; 0x31
    d5b6:	f7ff fc0d 	bl	cdd4 <arch_irq_enable>
    return ((uint32_t)p_reg + event);
}

NRF_STATIC_INLINE void nrf_gpiote_int_enable(NRF_GPIOTE_Type * p_reg, uint32_t mask)
{
    p_reg->INTENSET = mask;
    d5ba:	f04f 4200 	mov.w	r2, #2147483648	; 0x80000000
    d5be:	4b03      	ldr	r3, [pc, #12]	; (d5cc <gpio_nrfx_init+0x2c>)
    d5c0:	f8c3 2304 	str.w	r2, [r3, #772]	; 0x304
		nrf_gpiote_int_enable(NRF_GPIOTE, NRF_GPIOTE_INT_PORT_MASK);
	}

	return 0;
}
    d5c4:	2000      	movs	r0, #0
    d5c6:	bd08      	pop	{r3, pc}
    d5c8:	2001028a 	.word	0x2001028a
    d5cc:	40031000 	.word	0x40031000

0000d5d0 <gpio_nrfx_config>:
	switch (flags & (GPIO_DS_LOW_MASK | GPIO_DS_HIGH_MASK |
    d5d0:	4b28      	ldr	r3, [pc, #160]	; (d674 <gpio_nrfx_config+0xa4>)
{
    d5d2:	b570      	push	{r4, r5, r6, lr}
	switch (flags & (GPIO_DS_LOW_MASK | GPIO_DS_HIGH_MASK |
    d5d4:	4013      	ands	r3, r2
    d5d6:	f5b3 1f80 	cmp.w	r3, #1048576	; 0x100000
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    d5da:	6846      	ldr	r6, [r0, #4]
	switch (flags & (GPIO_DS_LOW_MASK | GPIO_DS_HIGH_MASK |
    d5dc:	d03b      	beq.n	d656 <gpio_nrfx_config+0x86>
    d5de:	d807      	bhi.n	d5f0 <gpio_nrfx_config+0x20>
    d5e0:	2b02      	cmp	r3, #2
    d5e2:	d03a      	beq.n	d65a <gpio_nrfx_config+0x8a>
    d5e4:	2b06      	cmp	r3, #6
    d5e6:	d013      	beq.n	d610 <gpio_nrfx_config+0x40>
    d5e8:	b193      	cbz	r3, d610 <gpio_nrfx_config+0x40>
		return -EINVAL;
    d5ea:	f06f 0015 	mvn.w	r0, #21
    d5ee:	e031      	b.n	d654 <gpio_nrfx_config+0x84>
	switch (flags & (GPIO_DS_LOW_MASK | GPIO_DS_HIGH_MASK |
    d5f0:	f5b3 0f80 	cmp.w	r3, #4194304	; 0x400000
    d5f4:	d033      	beq.n	d65e <gpio_nrfx_config+0x8e>
    d5f6:	d804      	bhi.n	d602 <gpio_nrfx_config+0x32>
    d5f8:	481f      	ldr	r0, [pc, #124]	; (d678 <gpio_nrfx_config+0xa8>)
    d5fa:	4283      	cmp	r3, r0
    d5fc:	d1f5      	bne.n	d5ea <gpio_nrfx_config+0x1a>
		drive = NRF_GPIO_PIN_H0D1;
    d5fe:	2307      	movs	r3, #7
    d600:	e006      	b.n	d610 <gpio_nrfx_config+0x40>
	switch (flags & (GPIO_DS_LOW_MASK | GPIO_DS_HIGH_MASK |
    d602:	481e      	ldr	r0, [pc, #120]	; (d67c <gpio_nrfx_config+0xac>)
    d604:	4283      	cmp	r3, r0
    d606:	d02c      	beq.n	d662 <gpio_nrfx_config+0x92>
    d608:	f5b3 0fa0 	cmp.w	r3, #5242880	; 0x500000
    d60c:	d1ed      	bne.n	d5ea <gpio_nrfx_config+0x1a>
		drive = NRF_GPIO_PIN_H0H1;
    d60e:	2303      	movs	r3, #3
	if ((flags & GPIO_PULL_UP) != 0) {
    d610:	06d0      	lsls	r0, r2, #27
		pull = NRF_GPIO_PIN_NOPULL;
    d612:	bf54      	ite	pl
    d614:	f3c2 1540 	ubfxpl	r5, r2, #5, #1
		pull = NRF_GPIO_PIN_PULLUP;
    d618:	2503      	movmi	r5, #3
		: NRF_GPIO_PIN_INPUT_DISCONNECT;
    d61a:	f482 7480 	eor.w	r4, r2, #256	; 0x100
	if ((flags & GPIO_OUTPUT) != 0) {
    d61e:	f412 7f00 	tst.w	r2, #512	; 0x200
	dir = ((flags & GPIO_OUTPUT) != 0)
    d622:	f3c2 2040 	ubfx	r0, r2, #9, #1
		: NRF_GPIO_PIN_INPUT_DISCONNECT;
    d626:	f3c4 2400 	ubfx	r4, r4, #8, #1
	if ((flags & GPIO_OUTPUT) != 0) {
    d62a:	d006      	beq.n	d63a <gpio_nrfx_config+0x6a>
		if ((flags & GPIO_OUTPUT_INIT_HIGH) != 0) {
    d62c:	f412 6f00 	tst.w	r2, #2048	; 0x800
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    d630:	6876      	ldr	r6, [r6, #4]
		if ((flags & GPIO_OUTPUT_INIT_HIGH) != 0) {
    d632:	d018      	beq.n	d666 <gpio_nrfx_config+0x96>
			nrf_gpio_port_out_set(reg, BIT(pin));
    d634:	2201      	movs	r2, #1
    d636:	408a      	lsls	r2, r1
    p_reg->OUTSET = set_mask;
    d638:	60b2      	str	r2, [r6, #8]
                               | ((uint32_t)drive << GPIO_PIN_CNF_DRIVE_Pos)
    d63a:	ea40 0044 	orr.w	r0, r0, r4, lsl #1
    d63e:	ea40 2303 	orr.w	r3, r0, r3, lsl #8
	return 0;
    d642:	2000      	movs	r0, #0
    *p_pin = pin_number & 0x1F;
    d644:	f001 011f 	and.w	r1, r1, #31
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    d648:	4a0d      	ldr	r2, [pc, #52]	; (d680 <gpio_nrfx_config+0xb0>)
                               | ((uint32_t)drive << GPIO_PIN_CNF_DRIVE_Pos)
    d64a:	ea43 0385 	orr.w	r3, r3, r5, lsl #2
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    d64e:	3180      	adds	r1, #128	; 0x80
    d650:	f842 3021 	str.w	r3, [r2, r1, lsl #2]
}
    d654:	bd70      	pop	{r4, r5, r6, pc}
		drive = NRF_GPIO_PIN_H0S1;
    d656:	2301      	movs	r3, #1
    d658:	e7da      	b.n	d610 <gpio_nrfx_config+0x40>
		drive = NRF_GPIO_PIN_D0S1;
    d65a:	2304      	movs	r3, #4
    d65c:	e7d8      	b.n	d610 <gpio_nrfx_config+0x40>
		drive = NRF_GPIO_PIN_S0H1;
    d65e:	2302      	movs	r3, #2
    d660:	e7d6      	b.n	d610 <gpio_nrfx_config+0x40>
		drive = NRF_GPIO_PIN_D0H1;
    d662:	2305      	movs	r3, #5
    d664:	e7d4      	b.n	d610 <gpio_nrfx_config+0x40>
		} else if ((flags & GPIO_OUTPUT_INIT_LOW) != 0) {
    d666:	0552      	lsls	r2, r2, #21
			nrf_gpio_port_out_clear(reg, BIT(pin));
    d668:	bf42      	ittt	mi
    d66a:	2201      	movmi	r2, #1
    d66c:	408a      	lslmi	r2, r1
    p_reg->OUTCLR = clr_mask;
    d66e:	60f2      	strmi	r2, [r6, #12]
    d670:	e7e3      	b.n	d63a <gpio_nrfx_config+0x6a>
    d672:	bf00      	nop
    d674:	00f00006 	.word	0x00f00006
    d678:	00100006 	.word	0x00100006
    d67c:	00400002 	.word	0x00400002
    d680:	40842500 	.word	0x40842500

0000d684 <gpio_nrfx_pin_interrupt_configure>:
{
    d684:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    d686:	460d      	mov	r5, r1
	uint32_t abs_pin = NRF_GPIO_PIN_MAP(get_port_cfg(port)->port_num, pin);
    d688:	6841      	ldr	r1, [r0, #4]
    d68a:	f005 041f 	and.w	r4, r5, #31
    d68e:	7a09      	ldrb	r1, [r1, #8]
	if ((mode == GPIO_INT_MODE_EDGE) &&
    d690:	f5b2 3fa0 	cmp.w	r2, #81920	; 0x14000
	struct gpio_nrfx_data *data = get_port_data(port);
    d694:	68c7      	ldr	r7, [r0, #12]
	if ((mode == GPIO_INT_MODE_EDGE) &&
    d696:	ea44 1441 	orr.w	r4, r4, r1, lsl #5
    d69a:	d10a      	bne.n	d6b2 <gpio_nrfx_pin_interrupt_configure+0x2e>
    return (nrf_gpio_pin_dir_t)((reg->PIN_CNF[pin_number] &
    d69c:	4866      	ldr	r0, [pc, #408]	; (d838 <gpio_nrfx_pin_interrupt_configure+0x1b4>)
    *p_pin = pin_number & 0x1F;
    d69e:	f004 011f 	and.w	r1, r4, #31
    return (nrf_gpio_pin_dir_t)((reg->PIN_CNF[pin_number] &
    d6a2:	3180      	adds	r1, #128	; 0x80
    d6a4:	f850 1021 	ldr.w	r1, [r0, r1, lsl #2]
    d6a8:	07c8      	lsls	r0, r1, #31
    d6aa:	d507      	bpl.n	d6bc <gpio_nrfx_pin_interrupt_configure+0x38>
		return -ENOTSUP;
    d6ac:	f06f 0022 	mvn.w	r0, #34	; 0x22
    d6b0:	e0a1      	b.n	d7f6 <gpio_nrfx_pin_interrupt_configure+0x172>
	WRITE_BIT(data->pin_int_en, pin, mode != GPIO_INT_MODE_DISABLED);
    d6b2:	f5b2 5f00 	cmp.w	r2, #8192	; 0x2000
    d6b6:	68f9      	ldr	r1, [r7, #12]
    d6b8:	f000 809e 	beq.w	d7f8 <gpio_nrfx_pin_interrupt_configure+0x174>
    d6bc:	2101      	movs	r1, #1
    d6be:	68f8      	ldr	r0, [r7, #12]
    d6c0:	40a9      	lsls	r1, r5
    d6c2:	4301      	orrs	r1, r0
    d6c4:	60f9      	str	r1, [r7, #12]
	WRITE_BIT(data->trig_edge, pin, mode == GPIO_INT_MODE_EDGE);
    d6c6:	2101      	movs	r1, #1
    d6c8:	6978      	ldr	r0, [r7, #20]
    d6ca:	40a9      	lsls	r1, r5
    d6cc:	f5b2 3fa0 	cmp.w	r2, #81920	; 0x14000
    d6d0:	69ba      	ldr	r2, [r7, #24]
    d6d2:	bf0c      	ite	eq
    d6d4:	4308      	orreq	r0, r1
    d6d6:	4388      	bicne	r0, r1
	WRITE_BIT(data->double_edge, pin, trig == GPIO_INT_TRIG_BOTH);
    d6d8:	f5b3 2fc0 	cmp.w	r3, #393216	; 0x60000
    d6dc:	bf0c      	ite	eq
    d6de:	430a      	orreq	r2, r1
    d6e0:	438a      	bicne	r2, r1
	WRITE_BIT(data->int_active_level, pin, trig == GPIO_INT_TRIG_HIGH);
    d6e2:	f5b3 2f80 	cmp.w	r3, #262144	; 0x40000
	for (size_t i = 0; i < GPIOTE_CH_NUM; i++) {
    d6e6:	f04f 0300 	mov.w	r3, #0
	WRITE_BIT(data->double_edge, pin, trig == GPIO_INT_TRIG_BOTH);
    d6ea:	61ba      	str	r2, [r7, #24]
    d6ec:	693a      	ldr	r2, [r7, #16]
    p_reg->INTENCLR = mask;
}

NRF_STATIC_INLINE uint32_t nrf_gpiote_int_enable_check(NRF_GPIOTE_Type const * p_reg, uint32_t mask)
{
    return p_reg->INTENSET & mask;
    d6ee:	4e53      	ldr	r6, [pc, #332]	; (d83c <gpio_nrfx_pin_interrupt_configure+0x1b8>)
	WRITE_BIT(data->int_active_level, pin, trig == GPIO_INT_TRIG_HIGH);
    d6f0:	bf0c      	ite	eq
    d6f2:	4311      	orreq	r1, r2
    d6f4:	ea22 0101 	bicne.w	r1, r2, r1
	WRITE_BIT(data->trig_edge, pin, mode == GPIO_INT_MODE_EDGE);
    d6f8:	6178      	str	r0, [r7, #20]
	WRITE_BIT(data->int_active_level, pin, trig == GPIO_INT_TRIG_HIGH);
    d6fa:	6139      	str	r1, [r7, #16]
    d6fc:	f8d6 2304 	ldr.w	r2, [r6, #772]	; 0x304
    d700:	b2d2      	uxtb	r2, r2
                        ((polarity << GPIOTE_CONFIG_POLARITY_Pos) & GPIOTE_CONFIG_POLARITY_Msk);
}

NRF_STATIC_INLINE uint32_t nrf_gpiote_event_pin_get(NRF_GPIOTE_Type const * p_reg, uint32_t idx)
{
    return ((p_reg->CONFIG[idx] & GPIOTE_CONFIG_PORT_PIN_Msk) >> GPIOTE_CONFIG_PSEL_Pos);
    d702:	f503 71a2 	add.w	r1, r3, #324	; 0x144
    d706:	f856 1021 	ldr.w	r1, [r6, r1, lsl #2]
    d70a:	f3c1 2104 	ubfx	r1, r1, #8, #5
		if ((nrf_gpiote_event_pin_get(NRF_GPIOTE, i) == abs_pin)
    d70e:	428c      	cmp	r4, r1
    d710:	d177      	bne.n	d802 <gpio_nrfx_pin_interrupt_configure+0x17e>
		    && (intenset & BIT(i))) {
    d712:	fa22 f103 	lsr.w	r1, r2, r3
    d716:	07c9      	lsls	r1, r1, #31
    d718:	d573      	bpl.n	d802 <gpio_nrfx_pin_interrupt_configure+0x17e>
			(void)atomic_and(mask, ~BIT(i));
    d71a:	2201      	movs	r2, #1
    d71c:	409a      	lsls	r2, r3
    d71e:	43d0      	mvns	r0, r2
	return __atomic_fetch_and(target, value, __ATOMIC_SEQ_CST);
    d720:	4947      	ldr	r1, [pc, #284]	; (d840 <gpio_nrfx_pin_interrupt_configure+0x1bc>)
    d722:	e8d1 cfef 	ldaex	ip, [r1]
    d726:	ea0c 0c00 	and.w	ip, ip, r0
    d72a:	e8c1 cfee 	stlex	lr, ip, [r1]
    d72e:	f1be 0f00 	cmp.w	lr, #0
    d732:	d1f6      	bne.n	d722 <gpio_nrfx_pin_interrupt_configure+0x9e>
   p_reg->CONFIG[idx] &= ~GPIOTE_CONFIG_MODE_Event;
    d734:	009b      	lsls	r3, r3, #2
    d736:	f103 4380 	add.w	r3, r3, #1073741824	; 0x40000000
    d73a:	f503 3344 	add.w	r3, r3, #200704	; 0x31000
    d73e:	f8d3 1510 	ldr.w	r1, [r3, #1296]	; 0x510
    d742:	f021 0101 	bic.w	r1, r1, #1
    d746:	f8c3 1510 	str.w	r1, [r3, #1296]	; 0x510
    p_reg->INTENCLR = mask;
    d74a:	f8c6 2308 	str.w	r2, [r6, #776]	; 0x308
	nrf_gpio_cfg_sense_set(abs_pin, NRF_GPIO_PIN_NOSENSE);
    d74e:	4620      	mov	r0, r4
    d750:	2100      	movs	r1, #0
    d752:	f7ff ff15 	bl	d580 <nrf_gpio_cfg_sense_set>
	if (data->pin_int_en & BIT(pin)) {
    d756:	68f8      	ldr	r0, [r7, #12]
    d758:	40e8      	lsrs	r0, r5
    d75a:	f010 0001 	ands.w	r0, r0, #1
    d75e:	d04a      	beq.n	d7f6 <gpio_nrfx_pin_interrupt_configure+0x172>
		if (data->trig_edge & BIT(pin)) {
    d760:	6978      	ldr	r0, [r7, #20]
    d762:	40e8      	lsrs	r0, r5
    d764:	f010 0201 	ands.w	r2, r0, #1
    d768:	d058      	beq.n	d81c <gpio_nrfx_pin_interrupt_configure+0x198>
			if (data->double_edge & BIT(pin)) {
    d76a:	69bb      	ldr	r3, [r7, #24]
    d76c:	40eb      	lsrs	r3, r5
    d76e:	07db      	lsls	r3, r3, #31
    d770:	d44c      	bmi.n	d80c <gpio_nrfx_pin_interrupt_configure+0x188>
			} else if ((data->int_active_level & BIT(pin)) != 0U) {
    d772:	693b      	ldr	r3, [r7, #16]
    d774:	fa23 f505 	lsr.w	r5, r3, r5
				pol = NRF_GPIOTE_POLARITY_HITOLO;
    d778:	f015 0f01 	tst.w	r5, #1
    d77c:	bf14      	ite	ne
    d77e:	2701      	movne	r7, #1
    d780:	2702      	moveq	r7, #2
    d782:	2300      	movs	r3, #0
		atomic_val_t prev = atomic_or(mask, BIT(channel));
    d784:	2501      	movs	r5, #1
	return __atomic_fetch_or(target, value, __ATOMIC_SEQ_CST);
    d786:	4a2e      	ldr	r2, [pc, #184]	; (d840 <gpio_nrfx_pin_interrupt_configure+0x1bc>)
    d788:	fa05 f103 	lsl.w	r1, r5, r3
    d78c:	e8d2 0fef 	ldaex	r0, [r2]
    d790:	ea40 0c01 	orr.w	ip, r0, r1
    d794:	e8c2 cfee 	stlex	lr, ip, [r2]
    d798:	f1be 0f00 	cmp.w	lr, #0
    d79c:	d1f6      	bne.n	d78c <gpio_nrfx_pin_interrupt_configure+0x108>
		if ((prev & BIT(channel)) == 0) {
    d79e:	40d8      	lsrs	r0, r3
    d7a0:	f010 0001 	ands.w	r0, r0, #1
    d7a4:	d134      	bne.n	d810 <gpio_nrfx_pin_interrupt_configure+0x18c>
  p_reg->CONFIG[idx] &= ~(GPIOTE_CONFIG_PORT_PIN_Msk | GPIOTE_CONFIG_POLARITY_Msk);
    d7a6:	009a      	lsls	r2, r3, #2
    d7a8:	f102 4280 	add.w	r2, r2, #1073741824	; 0x40000000
    d7ac:	f502 3244 	add.w	r2, r2, #200704	; 0x31000
    d7b0:	f8d2 5510 	ldr.w	r5, [r2, #1296]	; 0x510
			nrf_gpiote_event_t evt =
    d7b4:	3340      	adds	r3, #64	; 0x40
    d7b6:	f425 3547 	bic.w	r5, r5, #203776	; 0x31c00
    d7ba:	f425 7540 	bic.w	r5, r5, #768	; 0x300
    d7be:	f8c2 5510 	str.w	r5, [r2, #1296]	; 0x510
  p_reg->CONFIG[idx] |= ((pin << GPIOTE_CONFIG_PSEL_Pos) & GPIOTE_CONFIG_PORT_PIN_Msk) |
    d7c2:	0224      	lsls	r4, r4, #8
    d7c4:	009b      	lsls	r3, r3, #2
    d7c6:	f8d2 5510 	ldr.w	r5, [r2, #1296]	; 0x510
    d7ca:	f404 54f8 	and.w	r4, r4, #7936	; 0x1f00
    return ((uint32_t)p_reg + event);
    d7ce:	b29b      	uxth	r3, r3
  p_reg->CONFIG[idx] |= ((pin << GPIOTE_CONFIG_PSEL_Pos) & GPIOTE_CONFIG_PORT_PIN_Msk) |
    d7d0:	ea44 4407 	orr.w	r4, r4, r7, lsl #16
    return ((uint32_t)p_reg + event);
    d7d4:	f103 4380 	add.w	r3, r3, #1073741824	; 0x40000000
    d7d8:	f503 3344 	add.w	r3, r3, #200704	; 0x31000
  p_reg->CONFIG[idx] |= ((pin << GPIOTE_CONFIG_PSEL_Pos) & GPIOTE_CONFIG_PORT_PIN_Msk) |
    d7dc:	432c      	orrs	r4, r5
    d7de:	f8c2 4510 	str.w	r4, [r2, #1296]	; 0x510
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    d7e2:	6018      	str	r0, [r3, #0]
    d7e4:	681b      	ldr	r3, [r3, #0]
   p_reg->CONFIG[idx] |= GPIOTE_CONFIG_MODE_Event;
    d7e6:	f8d2 3510 	ldr.w	r3, [r2, #1296]	; 0x510
    d7ea:	f043 0301 	orr.w	r3, r3, #1
    d7ee:	f8c2 3510 	str.w	r3, [r2, #1296]	; 0x510
    p_reg->INTENSET = mask;
    d7f2:	f8c6 1304 	str.w	r1, [r6, #772]	; 0x304
}
    d7f6:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	WRITE_BIT(data->pin_int_en, pin, mode != GPIO_INT_MODE_DISABLED);
    d7f8:	2001      	movs	r0, #1
    d7fa:	40a8      	lsls	r0, r5
    d7fc:	ea21 0100 	bic.w	r1, r1, r0
    d800:	e760      	b.n	d6c4 <gpio_nrfx_pin_interrupt_configure+0x40>
	for (size_t i = 0; i < GPIOTE_CH_NUM; i++) {
    d802:	3301      	adds	r3, #1
    d804:	2b08      	cmp	r3, #8
    d806:	f47f af7c 	bne.w	d702 <gpio_nrfx_pin_interrupt_configure+0x7e>
    d80a:	e7a0      	b.n	d74e <gpio_nrfx_pin_interrupt_configure+0xca>
				pol = NRF_GPIOTE_POLARITY_TOGGLE;
    d80c:	2703      	movs	r7, #3
    d80e:	e7b8      	b.n	d782 <gpio_nrfx_pin_interrupt_configure+0xfe>
    d810:	3301      	adds	r3, #1
	for (uint8_t channel = 0; channel < GPIOTE_CH_NUM; ++channel) {
    d812:	2b08      	cmp	r3, #8
    d814:	d1b8      	bne.n	d788 <gpio_nrfx_pin_interrupt_configure+0x104>
	return -ENODEV;
    d816:	f06f 0012 	mvn.w	r0, #18
    d81a:	e7ec      	b.n	d7f6 <gpio_nrfx_pin_interrupt_configure+0x172>
	if ((BIT(pin) & data->int_active_level) != 0U) {
    d81c:	693b      	ldr	r3, [r7, #16]
			nrf_gpio_cfg_sense_set(abs_pin, sense);
    d81e:	4620      	mov	r0, r4
	if ((BIT(pin) & data->int_active_level) != 0U) {
    d820:	fa23 f505 	lsr.w	r5, r3, r5
		return NRF_GPIO_PIN_SENSE_HIGH;
    d824:	f015 0f01 	tst.w	r5, #1
			nrf_gpio_cfg_sense_set(abs_pin, sense);
    d828:	bf0c      	ite	eq
    d82a:	2103      	moveq	r1, #3
    d82c:	2102      	movne	r1, #2
    d82e:	f7ff fea7 	bl	d580 <nrf_gpio_cfg_sense_set>
	int res = 0;
    d832:	4610      	mov	r0, r2
    d834:	e7df      	b.n	d7f6 <gpio_nrfx_pin_interrupt_configure+0x172>
    d836:	bf00      	nop
    d838:	40842500 	.word	0x40842500
    d83c:	40031000 	.word	0x40031000
    d840:	2001023c 	.word	0x2001023c

0000d844 <gpiote_event_handler>:
{
    d844:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    d848:	4d3a      	ldr	r5, [pc, #232]	; (d934 <gpiote_event_handler+0xf0>)
    d84a:	682e      	ldr	r6, [r5, #0]
	if (port_event) {
    d84c:	2e00      	cmp	r6, #0
    d84e:	d04c      	beq.n	d8ea <gpiote_event_handler+0xa6>
	uint32_t bit = 1U << pin;
    d850:	2701      	movs	r7, #1
	uint32_t pin = 0U;
    d852:	f04f 0800 	mov.w	r8, #0
	uint32_t out = data->pin_int_en;
    d856:	4b38      	ldr	r3, [pc, #224]	; (d938 <gpiote_event_handler+0xf4>)
    d858:	68da      	ldr	r2, [r3, #12]
	out &= ~data->trig_edge & ~data->double_edge;
    d85a:	e9d3 1005 	ldrd	r1, r0, [r3, #20]
    d85e:	4301      	orrs	r1, r0
    d860:	ea22 0201 	bic.w	r2, r2, r1
    return p_reg->IN;
    d864:	4935      	ldr	r1, [pc, #212]	; (d93c <gpiote_event_handler+0xf8>)
	uint32_t pin_states = ~(port_in ^ data->int_active_level);
    d866:	691b      	ldr	r3, [r3, #16]
    d868:	690c      	ldr	r4, [r1, #16]
    d86a:	405c      	eors	r4, r3
	uint32_t out = pin_states & level_pins;
    d86c:	ea22 0404 	bic.w	r4, r2, r4
	while (level_pins) {
    d870:	bb72      	cbnz	r2, d8d0 <gpiote_event_handler+0x8c>
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    d872:	602a      	str	r2, [r5, #0]
    d874:	682b      	ldr	r3, [r5, #0]
	uint32_t fired_triggers[GPIO_COUNT] = {0};
    d876:	2300      	movs	r3, #0
		if (nrf_gpiote_int_enable_check(NRF_GPIOTE, BIT(i)) &&
    d878:	2501      	movs	r5, #1
    d87a:	461f      	mov	r7, r3
    return p_reg->INTENSET & mask;
    d87c:	4830      	ldr	r0, [pc, #192]	; (d940 <gpiote_event_handler+0xfc>)
    d87e:	4931      	ldr	r1, [pc, #196]	; (d944 <gpiote_event_handler+0x100>)
    d880:	f8d0 2304 	ldr.w	r2, [r0, #772]	; 0x304
    d884:	fa05 fc03 	lsl.w	ip, r5, r3
    d888:	ea1c 0f02 	tst.w	ip, r2
    d88c:	d00f      	beq.n	d8ae <gpiote_event_handler+0x6a>
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    d88e:	f851 2023 	ldr.w	r2, [r1, r3, lsl #2]
    d892:	b162      	cbz	r2, d8ae <gpiote_event_handler+0x6a>
    return ((p_reg->CONFIG[idx] & GPIOTE_CONFIG_PORT_PIN_Msk) >> GPIOTE_CONFIG_PSEL_Pos);
    d894:	f503 72a2 	add.w	r2, r3, #324	; 0x144
    d898:	f850 2022 	ldr.w	r2, [r0, r2, lsl #2]
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    d89c:	f841 7023 	str.w	r7, [r1, r3, lsl #2]
    return ((p_reg->CONFIG[idx] & GPIOTE_CONFIG_PORT_PIN_Msk) >> GPIOTE_CONFIG_PSEL_Pos);
    d8a0:	f3c2 2204 	ubfx	r2, r2, #8, #5
			fired_triggers[abs_pin / 32U] |= BIT(abs_pin % 32);
    d8a4:	fa05 f202 	lsl.w	r2, r5, r2
    d8a8:	4314      	orrs	r4, r2
    d8aa:	f851 2023 	ldr.w	r2, [r1, r3, lsl #2]
	for (size_t i = 0; i < GPIOTE_CH_NUM; i++) {
    d8ae:	3301      	adds	r3, #1
    d8b0:	2b08      	cmp	r3, #8
    d8b2:	d1e5      	bne.n	d880 <gpiote_event_handler+0x3c>
	if (fired_triggers[0]) {
    d8b4:	b9dc      	cbnz	r4, d8ee <gpiote_event_handler+0xaa>
	if (port_event) {
    d8b6:	b14e      	cbz	r6, d8cc <gpiote_event_handler+0x88>
	uint32_t bit = 1U << pin;
    d8b8:	2501      	movs	r5, #1
	uint32_t pin = 0U;
    d8ba:	2600      	movs	r6, #0
	uint32_t out = data->pin_int_en;
    d8bc:	4c1e      	ldr	r4, [pc, #120]	; (d938 <gpiote_event_handler+0xf4>)
    d8be:	68e2      	ldr	r2, [r4, #12]
	out &= ~data->trig_edge & ~data->double_edge;
    d8c0:	e9d4 1005 	ldrd	r1, r0, [r4, #20]
    d8c4:	4301      	orrs	r1, r0
    d8c6:	ea22 0201 	bic.w	r2, r2, r1
	while (level_pins) {
    d8ca:	bb0a      	cbnz	r2, d910 <gpiote_event_handler+0xcc>
}
    d8cc:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
		if (level_pins & bit) {
    d8d0:	423a      	tst	r2, r7
    d8d2:	d006      	beq.n	d8e2 <gpiote_event_handler+0x9e>
			nrf_gpio_cfg_sense_set(abs_pin, NRF_GPIO_PIN_NOSENSE);
    d8d4:	2100      	movs	r1, #0
    d8d6:	f008 001f 	and.w	r0, r8, #31
    d8da:	f7ff fe51 	bl	d580 <nrf_gpio_cfg_sense_set>
			level_pins &= ~bit;
    d8de:	ea22 0207 	bic.w	r2, r2, r7
		++pin;
    d8e2:	f108 0801 	add.w	r8, r8, #1
		bit <<= 1;
    d8e6:	007f      	lsls	r7, r7, #1
    d8e8:	e7c2      	b.n	d870 <gpiote_event_handler+0x2c>
	uint32_t fired_triggers[GPIO_COUNT] = {0};
    d8ea:	4634      	mov	r4, r6
    d8ec:	e7c3      	b.n	d876 <gpiote_event_handler+0x32>
					const struct device *port,
					uint32_t pins)
{
	struct gpio_callback *cb, *tmp;

	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(list, cb, tmp, node) {
    d8ee:	4b12      	ldr	r3, [pc, #72]	; (d938 <gpiote_event_handler+0xf4>)
    d8f0:	6859      	ldr	r1, [r3, #4]
    d8f2:	2900      	cmp	r1, #0
    d8f4:	d0df      	beq.n	d8b6 <gpiote_event_handler+0x72>
Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
    d8f6:	680d      	ldr	r5, [r1, #0]
		if (cb->pin_mask & pins) {
			__ASSERT(cb->handler, "No callback handler!");
			cb->handler(port, cb, cb->pin_mask & pins);
    d8f8:	4f13      	ldr	r7, [pc, #76]	; (d948 <gpiote_event_handler+0x104>)
		if (cb->pin_mask & pins) {
    d8fa:	688a      	ldr	r2, [r1, #8]
    d8fc:	4022      	ands	r2, r4
    d8fe:	d002      	beq.n	d906 <gpiote_event_handler+0xc2>
			cb->handler(port, cb, cb->pin_mask & pins);
    d900:	684b      	ldr	r3, [r1, #4]
    d902:	4638      	mov	r0, r7
    d904:	4798      	blx	r3
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(list, cb, tmp, node) {
    d906:	2d00      	cmp	r5, #0
    d908:	d0d5      	beq.n	d8b6 <gpiote_event_handler+0x72>
    d90a:	4629      	mov	r1, r5
    d90c:	682d      	ldr	r5, [r5, #0]
    d90e:	e7f4      	b.n	d8fa <gpiote_event_handler+0xb6>
		if (level_pins & bit) {
    d910:	4215      	tst	r5, r2
    d912:	d00c      	beq.n	d92e <gpiote_event_handler+0xea>
	if ((BIT(pin) & data->int_active_level) != 0U) {
    d914:	6923      	ldr	r3, [r4, #16]
			nrf_gpio_cfg_sense_set(abs_pin, sense);
    d916:	f006 001f 	and.w	r0, r6, #31
	if ((BIT(pin) & data->int_active_level) != 0U) {
    d91a:	40f3      	lsrs	r3, r6
		return NRF_GPIO_PIN_SENSE_HIGH;
    d91c:	f013 0f01 	tst.w	r3, #1
			nrf_gpio_cfg_sense_set(abs_pin, sense);
    d920:	bf0c      	ite	eq
    d922:	2103      	moveq	r1, #3
    d924:	2102      	movne	r1, #2
    d926:	f7ff fe2b 	bl	d580 <nrf_gpio_cfg_sense_set>
			level_pins &= ~bit;
    d92a:	ea22 0205 	bic.w	r2, r2, r5
		++pin;
    d92e:	3601      	adds	r6, #1
		bit <<= 1;
    d930:	006d      	lsls	r5, r5, #1
    d932:	e7ca      	b.n	d8ca <gpiote_event_handler+0x86>
    d934:	4003117c 	.word	0x4003117c
    d938:	20010220 	.word	0x20010220
    d93c:	40842500 	.word	0x40842500
    d940:	40031000 	.word	0x40031000
    d944:	40031100 	.word	0x40031100
    d948:	2001007c 	.word	0x2001007c

0000d94c <uarte_nrfx_configure>:
	return 0;
}

static int uarte_nrfx_configure(const struct device *dev,
				const struct uart_config *cfg)
{
    d94c:	b5f0      	push	{r4, r5, r6, r7, lr}
	nrf_uarte_config_t uarte_cfg;

#if defined(UARTE_CONFIG_STOP_Msk)
	switch (cfg->stop_bits) {
    d94e:	794b      	ldrb	r3, [r1, #5]
    d950:	2b01      	cmp	r3, #1
    d952:	d027      	beq.n	d9a4 <uarte_nrfx_configure+0x58>
    d954:	2b03      	cmp	r3, #3
    d956:	d122      	bne.n	d99e <uarte_nrfx_configure+0x52>
	case UART_CFG_STOP_BITS_1:
		uarte_cfg.stop = NRF_UARTE_STOP_ONE;
		break;
	case UART_CFG_STOP_BITS_2:
		uarte_cfg.stop = NRF_UARTE_STOP_TWO;
    d958:	2610      	movs	r6, #16
	if (cfg->stop_bits != UART_CFG_STOP_BITS_1) {
		return -ENOTSUP;
	}
#endif

	if (cfg->data_bits != UART_CFG_DATA_BITS_8) {
    d95a:	798b      	ldrb	r3, [r1, #6]
    d95c:	2b03      	cmp	r3, #3
    d95e:	d11e      	bne.n	d99e <uarte_nrfx_configure+0x52>
		return -ENOTSUP;
	}

	switch (cfg->flow_ctrl) {
    d960:	79cc      	ldrb	r4, [r1, #7]
    d962:	b124      	cbz	r4, d96e <uarte_nrfx_configure+0x22>
    d964:	2c01      	cmp	r4, #1
    d966:	d11a      	bne.n	d99e <uarte_nrfx_configure+0x52>
	case UART_CFG_FLOW_CTRL_NONE:
		uarte_cfg.hwfc = NRF_UARTE_HWFC_DISABLED;
		break;
	case UART_CFG_FLOW_CTRL_RTS_CTS:
		if (get_dev_config(dev)->rts_cts_pins_set) {
    d968:	6843      	ldr	r3, [r0, #4]
    d96a:	791b      	ldrb	r3, [r3, #4]
    d96c:	b1bb      	cbz	r3, d99e <uarte_nrfx_configure+0x52>
	}

#if defined(UARTE_CONFIG_PARITYTYPE_Msk)
	uarte_cfg.paritytype = NRF_UARTE_PARITYTYPE_EVEN;
#endif
	switch (cfg->parity) {
    d96e:	790a      	ldrb	r2, [r1, #4]
    d970:	b112      	cbz	r2, d978 <uarte_nrfx_configure+0x2c>
    d972:	2a02      	cmp	r2, #2
    d974:	d113      	bne.n	d99e <uarte_nrfx_configure+0x52>
	case UART_CFG_PARITY_NONE:
		uarte_cfg.parity = NRF_UARTE_PARITY_EXCLUDED;
		break;
	case UART_CFG_PARITY_EVEN:
		uarte_cfg.parity = NRF_UARTE_PARITY_INCLUDED;
    d976:	220e      	movs	r2, #14
	switch (baudrate) {
    d978:	f647 2712 	movw	r7, #31250	; 0x7a12
#endif
	default:
		return -ENOTSUP;
	}

	if (baudrate_set(dev, cfg->baudrate) != 0) {
    d97c:	680b      	ldr	r3, [r1, #0]
	return config->uarte_regs;
    d97e:	6845      	ldr	r5, [r0, #4]
	switch (baudrate) {
    d980:	42bb      	cmp	r3, r7
	return config->uarte_regs;
    d982:	682d      	ldr	r5, [r5, #0]
	switch (baudrate) {
    d984:	d063      	beq.n	da4e <uarte_nrfx_configure+0x102>
    d986:	d829      	bhi.n	d9dc <uarte_nrfx_configure+0x90>
    d988:	f5b3 5f96 	cmp.w	r3, #4800	; 0x12c0
    d98c:	d062      	beq.n	da54 <uarte_nrfx_configure+0x108>
    d98e:	d814      	bhi.n	d9ba <uarte_nrfx_configure+0x6e>
    d990:	f5b3 7f16 	cmp.w	r3, #600	; 0x258
    d994:	d060      	beq.n	da58 <uarte_nrfx_configure+0x10c>
    d996:	d807      	bhi.n	d9a8 <uarte_nrfx_configure+0x5c>
    d998:	f5b3 7f96 	cmp.w	r3, #300	; 0x12c
    d99c:	d05f      	beq.n	da5e <uarte_nrfx_configure+0x112>
		return -ENOTSUP;
    d99e:	f06f 0022 	mvn.w	r0, #34	; 0x22
    d9a2:	e053      	b.n	da4c <uarte_nrfx_configure+0x100>
		uarte_cfg.stop = NRF_UARTE_STOP_ONE;
    d9a4:	2600      	movs	r6, #0
    d9a6:	e7d8      	b.n	d95a <uarte_nrfx_configure+0xe>
	switch (baudrate) {
    d9a8:	f5b3 6f96 	cmp.w	r3, #1200	; 0x4b0
    d9ac:	d05a      	beq.n	da64 <uarte_nrfx_configure+0x118>
    d9ae:	f5b3 6f16 	cmp.w	r3, #2400	; 0x960
    d9b2:	d1f4      	bne.n	d99e <uarte_nrfx_configure+0x52>
		nrf_baudrate = NRF_UARTE_BAUDRATE_2400;
    d9b4:	f44f 231d 	mov.w	r3, #643072	; 0x9d000
    d9b8:	e03c      	b.n	da34 <uarte_nrfx_configure+0xe8>
	switch (baudrate) {
    d9ba:	f5b3 5f61 	cmp.w	r3, #14400	; 0x3840
    d9be:	d054      	beq.n	da6a <uarte_nrfx_configure+0x11e>
    d9c0:	d804      	bhi.n	d9cc <uarte_nrfx_configure+0x80>
    d9c2:	f5b3 5f16 	cmp.w	r3, #9600	; 0x2580
    d9c6:	d1ea      	bne.n	d99e <uarte_nrfx_configure+0x52>
		nrf_baudrate = NRF_UARTE_BAUDRATE_9600;
    d9c8:	4b33      	ldr	r3, [pc, #204]	; (da98 <uarte_nrfx_configure+0x14c>)
    d9ca:	e033      	b.n	da34 <uarte_nrfx_configure+0xe8>
	switch (baudrate) {
    d9cc:	f5b3 4f96 	cmp.w	r3, #19200	; 0x4b00
    d9d0:	d04d      	beq.n	da6e <uarte_nrfx_configure+0x122>
    d9d2:	f5b3 4fe1 	cmp.w	r3, #28800	; 0x7080
    d9d6:	d1e2      	bne.n	d99e <uarte_nrfx_configure+0x52>
		nrf_baudrate = NRF_UARTE_BAUDRATE_28800;
    d9d8:	4b30      	ldr	r3, [pc, #192]	; (da9c <uarte_nrfx_configure+0x150>)
    d9da:	e02b      	b.n	da34 <uarte_nrfx_configure+0xe8>
	switch (baudrate) {
    d9dc:	f5b3 3fe1 	cmp.w	r3, #115200	; 0x1c200
    d9e0:	d047      	beq.n	da72 <uarte_nrfx_configure+0x126>
    d9e2:	d812      	bhi.n	da0a <uarte_nrfx_configure+0xbe>
    d9e4:	f64d 27c0 	movw	r7, #56000	; 0xdac0
    d9e8:	42bb      	cmp	r3, r7
    d9ea:	d045      	beq.n	da78 <uarte_nrfx_configure+0x12c>
    d9ec:	d805      	bhi.n	d9fa <uarte_nrfx_configure+0xae>
    d9ee:	f5b3 4f16 	cmp.w	r3, #38400	; 0x9600
    d9f2:	d1d4      	bne.n	d99e <uarte_nrfx_configure+0x52>
		nrf_baudrate = NRF_UARTE_BAUDRATE_38400;
    d9f4:	f44f 031d 	mov.w	r3, #10289152	; 0x9d0000
    d9f8:	e01c      	b.n	da34 <uarte_nrfx_configure+0xe8>
	switch (baudrate) {
    d9fa:	f5b3 4f61 	cmp.w	r3, #57600	; 0xe100
    d9fe:	d03e      	beq.n	da7e <uarte_nrfx_configure+0x132>
    da00:	f5b3 3f96 	cmp.w	r3, #76800	; 0x12c00
    da04:	d1cb      	bne.n	d99e <uarte_nrfx_configure+0x52>
		nrf_baudrate = NRF_UARTE_BAUDRATE_76800;
    da06:	4b26      	ldr	r3, [pc, #152]	; (daa0 <uarte_nrfx_configure+0x154>)
    da08:	e014      	b.n	da34 <uarte_nrfx_configure+0xe8>
	switch (baudrate) {
    da0a:	f5b3 2fe1 	cmp.w	r3, #460800	; 0x70800
    da0e:	d039      	beq.n	da84 <uarte_nrfx_configure+0x138>
    da10:	d808      	bhi.n	da24 <uarte_nrfx_configure+0xd8>
    da12:	f5b3 3f61 	cmp.w	r3, #230400	; 0x38400
    da16:	d038      	beq.n	da8a <uarte_nrfx_configure+0x13e>
    da18:	4f22      	ldr	r7, [pc, #136]	; (daa4 <uarte_nrfx_configure+0x158>)
    da1a:	42bb      	cmp	r3, r7
    da1c:	d1bf      	bne.n	d99e <uarte_nrfx_configure+0x52>
		nrf_baudrate = NRF_UARTE_BAUDRATE_250000;
    da1e:	f04f 6380 	mov.w	r3, #67108864	; 0x4000000
    da22:	e007      	b.n	da34 <uarte_nrfx_configure+0xe8>
	switch (baudrate) {
    da24:	f5b3 2f61 	cmp.w	r3, #921600	; 0xe1000
    da28:	d032      	beq.n	da90 <uarte_nrfx_configure+0x144>
    da2a:	4f1f      	ldr	r7, [pc, #124]	; (daa8 <uarte_nrfx_configure+0x15c>)
    da2c:	42bb      	cmp	r3, r7
    da2e:	d1b6      	bne.n	d99e <uarte_nrfx_configure+0x52>
		nrf_baudrate = NRF_UARTE_BAUDRATE_1000000;
    da30:	f04f 5380 	mov.w	r3, #268435456	; 0x10000000
                    | (uint32_t)p_cfg->hwfc;
}

NRF_STATIC_INLINE void nrf_uarte_baudrate_set(NRF_UARTE_Type * p_reg, nrf_uarte_baudrate_t baudrate)
{
    p_reg->BAUDRATE = baudrate;
    da34:	f8c5 3524 	str.w	r3, [r5, #1316]	; 0x524
		return -ENOTSUP;
	}

	nrf_uarte_configure(get_uarte_instance(dev), &uarte_cfg);

	get_dev_data(dev)->uart_config = *cfg;
    da38:	68c3      	ldr	r3, [r0, #12]
                    | (uint32_t)p_cfg->hwfc;
    da3a:	4334      	orrs	r4, r6
    da3c:	4322      	orrs	r2, r4
    da3e:	3304      	adds	r3, #4
    da40:	c903      	ldmia	r1, {r0, r1}
    p_reg->CONFIG = (uint32_t)p_cfg->parity
    da42:	f8c5 256c 	str.w	r2, [r5, #1388]	; 0x56c
    da46:	e883 0003 	stmia.w	r3, {r0, r1}

	return 0;
    da4a:	2000      	movs	r0, #0
}
    da4c:	bdf0      	pop	{r4, r5, r6, r7, pc}
		nrf_baudrate = NRF_UARTE_BAUDRATE_31250;
    da4e:	f44f 0300 	mov.w	r3, #8388608	; 0x800000
    da52:	e7ef      	b.n	da34 <uarte_nrfx_configure+0xe8>
		nrf_baudrate = NRF_UARTE_BAUDRATE_4800;
    da54:	4b15      	ldr	r3, [pc, #84]	; (daac <uarte_nrfx_configure+0x160>)
    da56:	e7ed      	b.n	da34 <uarte_nrfx_configure+0xe8>
		nrf_baudrate = 0x00027000;
    da58:	f44f 331c 	mov.w	r3, #159744	; 0x27000
    da5c:	e7ea      	b.n	da34 <uarte_nrfx_configure+0xe8>
		nrf_baudrate = 0x00014000;
    da5e:	f44f 33a0 	mov.w	r3, #81920	; 0x14000
    da62:	e7e7      	b.n	da34 <uarte_nrfx_configure+0xe8>
		nrf_baudrate = NRF_UARTE_BAUDRATE_1200;
    da64:	f44f 239e 	mov.w	r3, #323584	; 0x4f000
    da68:	e7e4      	b.n	da34 <uarte_nrfx_configure+0xe8>
		nrf_baudrate = NRF_UARTE_BAUDRATE_14400;
    da6a:	4b11      	ldr	r3, [pc, #68]	; (dab0 <uarte_nrfx_configure+0x164>)
    da6c:	e7e2      	b.n	da34 <uarte_nrfx_configure+0xe8>
		nrf_baudrate = NRF_UARTE_BAUDRATE_19200;
    da6e:	4b11      	ldr	r3, [pc, #68]	; (dab4 <uarte_nrfx_configure+0x168>)
    da70:	e7e0      	b.n	da34 <uarte_nrfx_configure+0xe8>
		nrf_baudrate = NRF_UARTE_BAUDRATE_115200;
    da72:	f04f 73eb 	mov.w	r3, #30801920	; 0x1d60000
    da76:	e7dd      	b.n	da34 <uarte_nrfx_configure+0xe8>
		nrf_baudrate = NRF_UARTE_BAUDRATE_56000;
    da78:	f44f 0365 	mov.w	r3, #15007744	; 0xe50000
    da7c:	e7da      	b.n	da34 <uarte_nrfx_configure+0xe8>
		nrf_baudrate = NRF_UARTE_BAUDRATE_57600;
    da7e:	f44f 036b 	mov.w	r3, #15400960	; 0xeb0000
    da82:	e7d7      	b.n	da34 <uarte_nrfx_configure+0xe8>
		nrf_baudrate = NRF_UARTE_BAUDRATE_460800;
    da84:	f04f 63e8 	mov.w	r3, #121634816	; 0x7400000
    da88:	e7d4      	b.n	da34 <uarte_nrfx_configure+0xe8>
		nrf_baudrate = NRF_UARTE_BAUDRATE_230400;
    da8a:	f04f 736c 	mov.w	r3, #61865984	; 0x3b00000
    da8e:	e7d1      	b.n	da34 <uarte_nrfx_configure+0xe8>
		nrf_baudrate = NRF_UARTE_BAUDRATE_921600;
    da90:	f04f 6370 	mov.w	r3, #251658240	; 0xf000000
    da94:	e7ce      	b.n	da34 <uarte_nrfx_configure+0xe8>
    da96:	bf00      	nop
    da98:	00275000 	.word	0x00275000
    da9c:	0075c000 	.word	0x0075c000
    daa0:	013a9000 	.word	0x013a9000
    daa4:	0003d090 	.word	0x0003d090
    daa8:	000f4240 	.word	0x000f4240
    daac:	0013b000 	.word	0x0013b000
    dab0:	003af000 	.word	0x003af000
    dab4:	004ea000 	.word	0x004ea000

0000dab8 <uarte_instance_init.isra.2>:
	.irq_update		= uarte_nrfx_irq_update,
	.irq_callback_set	= uarte_nrfx_irq_callback_set,
#endif /* UARTE_INTERRUPT_DRIVEN */
};

static int uarte_instance_init(const struct device *dev,
    dab8:	b5f8      	push	{r3, r4, r5, r6, r7, lr}

	nrf_uarte_disable(uarte);

	data->dev = dev;

	nrf_gpio_pin_write(config->pseltxd, 1);
    daba:	680f      	ldr	r7, [r1, #0]
static int uarte_instance_init(const struct device *dev,
    dabc:	460d      	mov	r5, r1
    nrf_gpio_port_out_set(reg, 1UL << pin_number);
    dabe:	2101      	movs	r1, #1
    p_reg->ENABLE = UARTE_ENABLE_ENABLE_Disabled;
    dac0:	f04f 0c00 	mov.w	ip, #0
	return config->uarte_regs;
    dac4:	6843      	ldr	r3, [r0, #4]
	struct uarte_nrfx_data *data = get_dev_data(dev);
    dac6:	68c6      	ldr	r6, [r0, #12]
	return config->uarte_regs;
    dac8:	681c      	ldr	r4, [r3, #0]
    *p_pin = pin_number & 0x1F;
    daca:	f007 021f 	and.w	r2, r7, #31
    p_reg->OUTSET = set_mask;
    dace:	4b25      	ldr	r3, [pc, #148]	; (db64 <uarte_instance_init.isra.2+0xac>)
    nrf_gpio_port_out_set(reg, 1UL << pin_number);
    dad0:	4091      	lsls	r1, r2
    dad2:	f8c4 c500 	str.w	ip, [r4, #1280]	; 0x500
	data->dev = dev;
    dad6:	6030      	str	r0, [r6, #0]
    p_reg->OUTSET = set_mask;
    dad8:	6099      	str	r1, [r3, #8]
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    dada:	2103      	movs	r1, #3
    dadc:	3280      	adds	r2, #128	; 0x80
    dade:	f843 1022 	str.w	r1, [r3, r2, lsl #2]
	nrf_gpio_cfg_output(config->pseltxd);

	if (config->pselrxd !=  NRF_UARTE_PSEL_DISCONNECTED) {
    dae2:	686a      	ldr	r2, [r5, #4]
    dae4:	1c51      	adds	r1, r2, #1
    *p_pin = pin_number & 0x1F;
    dae6:	bf1e      	ittt	ne
    dae8:	f002 011f 	andne.w	r1, r2, #31
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    daec:	3180      	addne	r1, #128	; 0x80
    daee:	f843 c021 	strne.w	ip, [r3, r1, lsl #2]
		nrf_gpio_cfg_input(config->pselrxd, NRF_GPIO_PIN_NOPULL);
	}

	nrf_uarte_txrx_pins_set(uarte, config->pseltxd, config->pselrxd);

	if (config->pselcts != NRF_UARTE_PSEL_DISCONNECTED) {
    daf2:	68a9      	ldr	r1, [r5, #8]
    p_reg->PSEL.TXD = pseltxd;
    daf4:	f8c4 750c 	str.w	r7, [r4, #1292]	; 0x50c
    daf8:	1c4f      	adds	r7, r1, #1
    dafa:	bf18      	it	ne
    dafc:	2700      	movne	r7, #0
    p_reg->PSEL.RXD = pselrxd;
    dafe:	f8c4 2514 	str.w	r2, [r4, #1300]	; 0x514
    *p_pin = pin_number & 0x1F;
    db02:	bf1e      	ittt	ne
    db04:	f001 021f 	andne.w	r2, r1, #31
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    db08:	3280      	addne	r2, #128	; 0x80
    db0a:	f843 7022 	strne.w	r7, [r3, r2, lsl #2]
		nrf_gpio_cfg_input(config->pselcts, NRF_GPIO_PIN_NOPULL);
	}

	if (config->pselrts != NRF_UARTE_PSEL_DISCONNECTED) {
    db0e:	68ef      	ldr	r7, [r5, #12]
    db10:	1c7a      	adds	r2, r7, #1
    db12:	d00c      	beq.n	db2e <uarte_instance_init.isra.2+0x76>
    nrf_gpio_port_out_set(reg, 1UL << pin_number);
    db14:	f04f 0c01 	mov.w	ip, #1
    *p_pin = pin_number & 0x1F;
    db18:	f007 021f 	and.w	r2, r7, #31
    nrf_gpio_port_out_set(reg, 1UL << pin_number);
    db1c:	fa0c fc02 	lsl.w	ip, ip, r2
    p_reg->OUTSET = set_mask;
    db20:	f8c3 c008 	str.w	ip, [r3, #8]
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    db24:	f04f 0c03 	mov.w	ip, #3
    db28:	3280      	adds	r2, #128	; 0x80
    db2a:	f843 c022 	str.w	ip, [r3, r2, lsl #2]
    p_reg->PSEL.RTS = pselrts;
    db2e:	f8c4 7508 	str.w	r7, [r4, #1288]	; 0x508
    p_reg->PSEL.CTS = pselcts;
    db32:	f8c4 1510 	str.w	r1, [r4, #1296]	; 0x510
		nrf_gpio_cfg_output(config->pselrts);
	}

	nrf_uarte_hwfc_pins_set(uarte, config->pselrts, config->pselcts);

	err = uarte_nrfx_configure(dev, &get_dev_data(dev)->uart_config);
    db36:	68c1      	ldr	r1, [r0, #12]
    db38:	3104      	adds	r1, #4
    db3a:	f7ff ff07 	bl	d94c <uarte_nrfx_configure>
	if (err) {
    db3e:	b980      	cbnz	r0, db62 <uarte_instance_init.isra.2+0xaa>
    p_reg->ENABLE = UARTE_ENABLE_ENABLE_Enabled;
    db40:	2308      	movs	r3, #8
    db42:	f8c4 3500 	str.w	r3, [r4, #1280]	; 0x500
	}
#endif
	/* Enable receiver and transmitter */
	nrf_uarte_enable(uarte);

	if (config->pselrxd != NRF_UARTE_PSEL_DISCONNECTED) {
    db46:	686b      	ldr	r3, [r5, #4]
    db48:	3301      	adds	r3, #1
    db4a:	d00a      	beq.n	db62 <uarte_instance_init.isra.2+0xaa>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    db4c:	f8c4 0110 	str.w	r0, [r4, #272]	; 0x110
    db50:	f8d4 3110 	ldr.w	r3, [r4, #272]	; 0x110
NRF_STATIC_INLINE void nrf_uarte_rx_buffer_set(NRF_UARTE_Type * p_reg,
                                               uint8_t *        p_buffer,
                                               size_t           length)
{
    p_reg->RXD.PTR    = (uint32_t)p_buffer;
    p_reg->RXD.MAXCNT = length;
    db54:	2301      	movs	r3, #1
		nrf_uarte_event_clear(uarte, NRF_UARTE_EVENT_ENDRX);

		nrf_uarte_rx_buffer_set(uarte, &data->rx_data, 1);
    db56:	3610      	adds	r6, #16
    p_reg->RXD.PTR    = (uint32_t)p_buffer;
    db58:	f8c4 6534 	str.w	r6, [r4, #1332]	; 0x534
    p_reg->RXD.MAXCNT = length;
    db5c:	f8c4 3538 	str.w	r3, [r4, #1336]	; 0x538
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    db60:	6023      	str	r3, [r4, #0]
		/* switch off transmitter to save an energy */
		nrf_uarte_task_trigger(uarte, NRF_UARTE_TASK_STOPTX);
	}
#endif
	return 0;
}
    db62:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    db64:	40842500 	.word	0x40842500

0000db68 <uarte_0_init>:
				.tx_buffer = uarte##idx##_tx_buffer,	       \
				.tx_buff_size = sizeof(uarte##idx##_tx_buffer),\
			};))

#ifdef CONFIG_UART_0_NRF_UARTE
UART_NRF_UARTE_DEVICE(0);
    db68:	b530      	push	{r4, r5, lr}
    db6a:	b085      	sub	sp, #20
    db6c:	4605      	mov	r5, r0
    db6e:	466c      	mov	r4, sp
    db70:	4b04      	ldr	r3, [pc, #16]	; (db84 <uarte_0_init+0x1c>)
    db72:	cb0f      	ldmia	r3, {r0, r1, r2, r3}
    db74:	e884 000f 	stmia.w	r4, {r0, r1, r2, r3}
    db78:	4621      	mov	r1, r4
    db7a:	4628      	mov	r0, r5
    db7c:	f7ff ff9c 	bl	dab8 <uarte_instance_init.isra.2>
    db80:	b005      	add	sp, #20
    db82:	bd30      	pop	{r4, r5, pc}
    db84:	0000f960 	.word	0x0000f960

0000db88 <uarte_1_init>:
#endif

#ifdef CONFIG_UART_1_NRF_UARTE
UART_NRF_UARTE_DEVICE(1);
    db88:	b530      	push	{r4, r5, lr}
    db8a:	b085      	sub	sp, #20
    db8c:	4605      	mov	r5, r0
    db8e:	466c      	mov	r4, sp
    db90:	4b04      	ldr	r3, [pc, #16]	; (dba4 <uarte_1_init+0x1c>)
    db92:	cb0f      	ldmia	r3, {r0, r1, r2, r3}
    db94:	e884 000f 	stmia.w	r4, {r0, r1, r2, r3}
    db98:	4621      	mov	r1, r4
    db9a:	4628      	mov	r0, r5
    db9c:	f7ff ff8c 	bl	dab8 <uarte_instance_init.isra.2>
    dba0:	b005      	add	sp, #20
    dba2:	bd30      	pop	{r4, r5, pc}
    dba4:	0000f970 	.word	0x0000f970

0000dba8 <check_ext_api_requests>:
	}
};
#endif

static int check_ext_api_requests(const struct device *dev)
{
    dba8:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
	(void)dev;

	const struct fw_info_ext_api_request *ext_api_req =
			skip_ext_apis(&m_firmware_info);

	for (uint32_t i = 0; i < m_firmware_info.ext_api_request_num; i++) {
    dbac:	2500      	movs	r5, #0
			skip_ext_apis(&m_firmware_info);
    dbae:	4c21      	ldr	r4, [pc, #132]	; (dc34 <check_ext_api_requests+0x8c>)
 */
static inline const struct fw_info_ext_api *fw_info_ext_api_check(
							uint32_t ext_api_addr)
{
	const struct fw_info_ext_api *ext_api;
	const uint32_t ext_api_magic[] = {EXT_API_MAGIC};
    dbb0:	4e21      	ldr	r6, [pc, #132]	; (dc38 <check_ext_api_requests+0x90>)
	for (uint32_t i = 0; i < m_firmware_info.ext_api_request_num; i++) {
    dbb2:	f854 8c04 	ldr.w	r8, [r4, #-4]
			/* EXT_API hard requirement not met. */
			printk("ERROR: Cannot fulfill EXT_API request.\r\n");
			k_panic();
		} else {
			/* EXT_API soft requirement not met. */
			printk("WARNING: Optional EXT_API request not "
    dbb6:	f8df 9088 	ldr.w	r9, [pc, #136]	; dc40 <check_ext_api_requests+0x98>
{
    dbba:	b085      	sub	sp, #20
	for (uint32_t i = 0; i < m_firmware_info.ext_api_request_num; i++) {
    dbbc:	45a8      	cmp	r8, r5
    dbbe:	d803      	bhi.n	dbc8 <check_ext_api_requests+0x20>
		}
		ADVANCE_EXT_API_REQ(ext_api_req);
	}

	return 0;
}
    dbc0:	2000      	movs	r0, #0
    dbc2:	b005      	add	sp, #20
    dbc4:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
		if (fw_info_ext_api_check((uint32_t)*(ext_api_req->ext_api))
    dbc8:	6a63      	ldr	r3, [r4, #36]	; 0x24
    dbca:	e896 0007 	ldmia.w	r6, {r0, r1, r2}
    dbce:	681f      	ldr	r7, [r3, #0]
    dbd0:	ab01      	add	r3, sp, #4
    dbd2:	e883 0007 	stmia.w	r3, {r0, r1, r2}

	ext_api = (const struct fw_info_ext_api *)(ext_api_addr);
	if (memcmp(ext_api->magic, ext_api_magic, CONFIG_FW_INFO_MAGIC_LEN)
    dbd6:	220c      	movs	r2, #12
    dbd8:	4619      	mov	r1, r3
    dbda:	4638      	mov	r0, r7
    dbdc:	f001 fb51 	bl	f282 <memcmp>
    dbe0:	b990      	cbnz	r0, dc08 <check_ext_api_requests+0x60>
    dbe2:	b18f      	cbz	r7, dc08 <check_ext_api_requests+0x60>
			&& ext_api_satisfies_req(*(ext_api_req->ext_api),
    dbe4:	6a63      	ldr	r3, [r4, #36]	; 0x24
	const uint32_t req_id = ext_api_req->request.ext_api_id;
    dbe6:	6921      	ldr	r1, [r4, #16]
			&& ext_api_satisfies_req(*(ext_api_req->ext_api),
    dbe8:	681b      	ldr	r3, [r3, #0]
	return ((ext_api->ext_api_id == req_id)
    dbea:	691a      	ldr	r2, [r3, #16]
		&& ((ext_api->ext_api_flags & req_flags) == req_flags));
    dbec:	4291      	cmp	r1, r2
    dbee:	d10b      	bne.n	dc08 <check_ext_api_requests+0x60>
		&&  (ext_api->ext_api_version >= req_min_version)
    dbf0:	699a      	ldr	r2, [r3, #24]
	const uint32_t req_min_version = ext_api_req->request.ext_api_version;
    dbf2:	69a1      	ldr	r1, [r4, #24]
		&&  (ext_api->ext_api_version >= req_min_version)
    dbf4:	4291      	cmp	r1, r2
    dbf6:	d807      	bhi.n	dc08 <check_ext_api_requests+0x60>
	const uint32_t req_max_version = ext_api_req->ext_api_max_version;
    dbf8:	69e1      	ldr	r1, [r4, #28]
		&&  (ext_api->ext_api_version <  req_max_version)
    dbfa:	4291      	cmp	r1, r2
    dbfc:	d904      	bls.n	dc08 <check_ext_api_requests+0x60>
	const uint32_t req_flags = ext_api_req->request.ext_api_flags;
    dbfe:	6962      	ldr	r2, [r4, #20]
		&& ((ext_api->ext_api_flags & req_flags) == req_flags));
    dc00:	695b      	ldr	r3, [r3, #20]
    dc02:	ea32 0303 	bics.w	r3, r2, r3
    dc06:	d00a      	beq.n	dc1e <check_ext_api_requests+0x76>
		} else if (ext_api_req->required) {
    dc08:	6a27      	ldr	r7, [r4, #32]
    dc0a:	b167      	cbz	r7, dc26 <check_ext_api_requests+0x7e>
			printk("ERROR: Cannot fulfill EXT_API request.\r\n");
    dc0c:	480b      	ldr	r0, [pc, #44]	; (dc3c <check_ext_api_requests+0x94>)
    dc0e:	f001 f8b3 	bl	ed78 <printk>
			k_panic();
    dc12:	4040      	eors	r0, r0
    dc14:	f380 8811 	msr	BASEPRI, r0
    dc18:	f04f 0004 	mov.w	r0, #4
    dc1c:	df02      	svc	2
		ADVANCE_EXT_API_REQ(ext_api_req);
    dc1e:	68e3      	ldr	r3, [r4, #12]
	for (uint32_t i = 0; i < m_firmware_info.ext_api_request_num; i++) {
    dc20:	3501      	adds	r5, #1
		ADVANCE_EXT_API_REQ(ext_api_req);
    dc22:	441c      	add	r4, r3
    dc24:	e7ca      	b.n	dbbc <check_ext_api_requests+0x14>
			printk("WARNING: Optional EXT_API request not "
    dc26:	4648      	mov	r0, r9
    dc28:	f001 f8a6 	bl	ed78 <printk>
			*ext_api_req->ext_api = NULL;
    dc2c:	6a63      	ldr	r3, [r4, #36]	; 0x24
    dc2e:	601f      	str	r7, [r3, #0]
    dc30:	e7f5      	b.n	dc1e <check_ext_api_requests+0x76>
    dc32:	bf00      	nop
    dc34:	0000c23c 	.word	0x0000c23c
    dc38:	0000f980 	.word	0x0000f980
    dc3c:	0000fae7 	.word	0x0000fae7
    dc40:	0000fb10 	.word	0x0000fb10

0000dc44 <SystemInit>:
    static bool uicr_HFXOCNT_erased(void);
#endif

void SystemCoreClockUpdate(void)
{
    SystemCoreClock = __SYSTEM_CLOCK;
    dc44:	4b01      	ldr	r3, [pc, #4]	; (dc4c <SystemInit+0x8>)
    dc46:	4a02      	ldr	r2, [pc, #8]	; (dc50 <SystemInit+0xc>)
    dc48:	601a      	str	r2, [r3, #0]
      __DSB();
      __ISB();
    #endif
    
    SystemCoreClockUpdate();
}
    dc4a:	4770      	bx	lr
    dc4c:	20010030 	.word	0x20010030
    dc50:	03d09000 	.word	0x03d09000

0000dc54 <nrfx_clock_init>:
nrfx_err_t nrfx_clock_init(nrfx_clock_event_handler_t event_handler)
{
    NRFX_ASSERT(event_handler);

    nrfx_err_t err_code = NRFX_SUCCESS;
    if (m_clock_cb.module_initialized)
    dc54:	4b04      	ldr	r3, [pc, #16]	; (dc68 <nrfx_clock_init+0x14>)
    dc56:	791a      	ldrb	r2, [r3, #4]
    dc58:	b922      	cbnz	r2, dc64 <nrfx_clock_init+0x10>
    {
#if NRFX_CHECK(NRFX_CLOCK_CONFIG_LF_CAL_ENABLED)
        m_clock_cb.cal_state = CAL_STATE_IDLE;
#endif
        m_clock_cb.event_handler = event_handler;
        m_clock_cb.module_initialized = true;
    dc5a:	2201      	movs	r2, #1
        m_clock_cb.event_handler = event_handler;
    dc5c:	6018      	str	r0, [r3, #0]
        m_clock_cb.module_initialized = true;
    dc5e:	711a      	strb	r2, [r3, #4]
    nrfx_err_t err_code = NRFX_SUCCESS;
    dc60:	4802      	ldr	r0, [pc, #8]	; (dc6c <nrfx_clock_init+0x18>)
    dc62:	4770      	bx	lr
        err_code = NRFX_ERROR_ALREADY_INITIALIZED;
    dc64:	4802      	ldr	r0, [pc, #8]	; (dc70 <nrfx_clock_init+0x1c>)
#endif
    }

    NRFX_LOG_INFO("Function: %s, error code: %s.", __func__, NRFX_LOG_ERROR_STRING_GET(err_code));
    return err_code;
}
    dc66:	4770      	bx	lr
    dc68:	20010240 	.word	0x20010240
    dc6c:	0bad0000 	.word	0x0bad0000
    dc70:	0bad000c 	.word	0x0bad000c

0000dc74 <nrfx_clock_start>:
}

void nrfx_clock_start(nrf_clock_domain_t domain)
{
    NRFX_ASSERT(m_clock_cb.module_initialized);
    switch (domain)
    dc74:	b110      	cbz	r0, dc7c <nrfx_clock_start+0x8>
    dc76:	2801      	cmp	r0, #1
    dc78:	d01e      	beq.n	dcb8 <nrfx_clock_start+0x44>
    dc7a:	4770      	bx	lr
                    (nrf_clock_lfclk_t)((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_SRC_Msk)
    dc7c:	4b13      	ldr	r3, [pc, #76]	; (dccc <nrfx_clock_start+0x58>)
    dc7e:	f8d3 2418 	ldr.w	r2, [r3, #1048]	; 0x418
            if ((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_STATE_Msk)
    dc82:	f8d3 1418 	ldr.w	r1, [r3, #1048]	; 0x418
    dc86:	f411 3f80 	tst.w	r1, #65536	; 0x10000
    dc8a:	4619      	mov	r1, r3
    dc8c:	d010      	beq.n	dcb0 <nrfx_clock_start+0x3c>
    {
        case NRF_CLOCK_DOMAIN_LFCLK:
#if NRFX_CHECK(NRFX_CLOCK_CONFIG_LFXO_TWO_STAGE_ENABLED)
            {
                nrf_clock_lfclk_t lfclksrc;
                if (nrf_clock_is_running(NRF_CLOCK, NRF_CLOCK_DOMAIN_LFCLK, &lfclksrc) &&
    dc8e:	f002 0203 	and.w	r2, r2, #3
    dc92:	2a02      	cmp	r2, #2
    dc94:	d10c      	bne.n	dcb0 <nrfx_clock_start+0x3c>
    p_reg->LFCLKSRC = (uint32_t)(source);
    dc96:	f8c3 2518 	str.w	r2, [r3, #1304]	; 0x518
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    dc9a:	2200      	movs	r2, #0
    dc9c:	4b0c      	ldr	r3, [pc, #48]	; (dcd0 <nrfx_clock_start+0x5c>)
    dc9e:	601a      	str	r2, [r3, #0]
    p_reg->INTENSET = mask;
    dca0:	2202      	movs	r2, #2
    dca2:	681b      	ldr	r3, [r3, #0]
    dca4:	4b09      	ldr	r3, [pc, #36]	; (dccc <nrfx_clock_start+0x58>)
    dca6:	f8c3 2304 	str.w	r2, [r3, #772]	; 0x304
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    dcaa:	2201      	movs	r2, #1
    dcac:	609a      	str	r2, [r3, #8]
    dcae:	4770      	bx	lr
    p_reg->LFCLKSRC = (uint32_t)(source);
    dcb0:	2301      	movs	r3, #1
    dcb2:	f8c1 3518 	str.w	r3, [r1, #1304]	; 0x518
    dcb6:	e7f0      	b.n	dc9a <nrfx_clock_start+0x26>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    dcb8:	2200      	movs	r2, #0
    dcba:	4b06      	ldr	r3, [pc, #24]	; (dcd4 <nrfx_clock_start+0x60>)
    dcbc:	601a      	str	r2, [r3, #0]
    dcbe:	681b      	ldr	r3, [r3, #0]
    p_reg->INTENSET = mask;
    dcc0:	4b02      	ldr	r3, [pc, #8]	; (dccc <nrfx_clock_start+0x58>)
    dcc2:	f8c3 0304 	str.w	r0, [r3, #772]	; 0x304
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    dcc6:	6018      	str	r0, [r3, #0]
#endif
        default:
            NRFX_ASSERT(0);
            break;
    }
}
    dcc8:	4770      	bx	lr
    dcca:	bf00      	nop
    dccc:	40005000 	.word	0x40005000
    dcd0:	40005104 	.word	0x40005104
    dcd4:	40005100 	.word	0x40005100

0000dcd8 <nrfx_clock_stop>:

void nrfx_clock_stop(nrf_clock_domain_t domain)
{
    dcd8:	b538      	push	{r3, r4, r5, lr}
    NRFX_ASSERT(m_clock_cb.module_initialized);
    switch (domain)
    dcda:	b110      	cbz	r0, dce2 <nrfx_clock_stop+0xa>
    dcdc:	2801      	cmp	r0, #1
    dcde:	d016      	beq.n	dd0e <nrfx_clock_stop+0x36>
    if (domain == NRF_CLOCK_DOMAIN_HFCLK)
    {
            m_clock_cb.hfclk_started = false;
    }
#endif
}
    dce0:	bd38      	pop	{r3, r4, r5, pc}
    p_reg->INTENCLR = mask;
    dce2:	2202      	movs	r2, #2
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    dce4:	2101      	movs	r1, #1
    dce6:	f242 7510 	movw	r5, #10000	; 0x2710
    p_reg->INTENCLR = mask;
    dcea:	4c16      	ldr	r4, [pc, #88]	; (dd44 <nrfx_clock_stop+0x6c>)
    dcec:	f8c4 2308 	str.w	r2, [r4, #776]	; 0x308
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    dcf0:	4a15      	ldr	r2, [pc, #84]	; (dd48 <nrfx_clock_stop+0x70>)
    dcf2:	6010      	str	r0, [r2, #0]
    dcf4:	6812      	ldr	r2, [r2, #0]
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    dcf6:	4a15      	ldr	r2, [pc, #84]	; (dd4c <nrfx_clock_stop+0x74>)
    dcf8:	6011      	str	r1, [r2, #0]
            if ((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_STATE_Msk)
    dcfa:	f8d4 3418 	ldr.w	r3, [r4, #1048]	; 0x418
    dcfe:	03db      	lsls	r3, r3, #15
    dd00:	d5ee      	bpl.n	dce0 <nrfx_clock_stop+0x8>
        NRFX_WAIT_FOR(!nrfx_clock_is_running(domain, NULL), 10000, 1, stopped);
    dd02:	2001      	movs	r0, #1
    dd04:	f001 fbd0 	bl	f4a8 <nrfx_busy_wait>
    dd08:	3d01      	subs	r5, #1
    dd0a:	d1f6      	bne.n	dcfa <nrfx_clock_stop+0x22>
    dd0c:	e7e8      	b.n	dce0 <nrfx_clock_stop+0x8>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    dd0e:	2200      	movs	r2, #0
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    dd10:	f242 7510 	movw	r5, #10000	; 0x2710
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    dd14:	4b0e      	ldr	r3, [pc, #56]	; (dd50 <nrfx_clock_stop+0x78>)
    p_reg->INTENCLR = mask;
    dd16:	4c0b      	ldr	r4, [pc, #44]	; (dd44 <nrfx_clock_stop+0x6c>)
    dd18:	f8c4 0308 	str.w	r0, [r4, #776]	; 0x308
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    dd1c:	601a      	str	r2, [r3, #0]
    dd1e:	681b      	ldr	r3, [r3, #0]
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    dd20:	4b0c      	ldr	r3, [pc, #48]	; (dd54 <nrfx_clock_stop+0x7c>)
    dd22:	6018      	str	r0, [r3, #0]
                    (nrf_clock_hfclk_t)((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_SRC_Msk)
    dd24:	f8d4 340c 	ldr.w	r3, [r4, #1036]	; 0x40c
            if ((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_STATE_Msk)
    dd28:	f8d4 240c 	ldr.w	r2, [r4, #1036]	; 0x40c
                    (nrf_clock_hfclk_t)((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_SRC_Msk)
    dd2c:	f003 0301 	and.w	r3, r3, #1
            if ((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_STATE_Msk)
    dd30:	03d2      	lsls	r2, r2, #15
    dd32:	d5d5      	bpl.n	dce0 <nrfx_clock_stop+0x8>
        NRFX_WAIT_FOR((!nrfx_clock_is_running(domain, &clk_src) ||
    dd34:	2b00      	cmp	r3, #0
    dd36:	d0d3      	beq.n	dce0 <nrfx_clock_stop+0x8>
    dd38:	2001      	movs	r0, #1
    dd3a:	f001 fbb5 	bl	f4a8 <nrfx_busy_wait>
    dd3e:	3d01      	subs	r5, #1
    dd40:	d1f0      	bne.n	dd24 <nrfx_clock_stop+0x4c>
    dd42:	e7cd      	b.n	dce0 <nrfx_clock_stop+0x8>
    dd44:	40005000 	.word	0x40005000
    dd48:	40005104 	.word	0x40005104
    dd4c:	4000500c 	.word	0x4000500c
    dd50:	40005100 	.word	0x40005100
    dd54:	40005004 	.word	0x40005004

0000dd58 <nrfx_power_clock_irq_handler>:
    return (bool)*((volatile uint32_t *)((uint8_t *)p_reg + event));
    dd58:	4b15      	ldr	r3, [pc, #84]	; (ddb0 <nrfx_power_clock_irq_handler+0x58>)
    }
}
#endif

void nrfx_clock_irq_handler(void)
{
    dd5a:	b510      	push	{r4, lr}
    dd5c:	681a      	ldr	r2, [r3, #0]
    if (nrf_clock_event_check(NRF_CLOCK, NRF_CLOCK_EVENT_HFCLKSTARTED))
    dd5e:	b14a      	cbz	r2, dd74 <nrfx_power_clock_irq_handler+0x1c>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    dd60:	2000      	movs	r0, #0
    p_reg->INTENCLR = mask;
    dd62:	2201      	movs	r2, #1
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    dd64:	6018      	str	r0, [r3, #0]
    dd66:	681b      	ldr	r3, [r3, #0]
    p_reg->INTENCLR = mask;
    dd68:	4b12      	ldr	r3, [pc, #72]	; (ddb4 <nrfx_power_clock_irq_handler+0x5c>)
    dd6a:	f8c3 2308 	str.w	r2, [r3, #776]	; 0x308
        {
            m_clock_cb.hfclk_started = true;
            m_clock_cb.event_handler(NRFX_CLOCK_EVT_HFCLK_STARTED);
        }
#else
        m_clock_cb.event_handler(NRFX_CLOCK_EVT_HFCLK_STARTED);
    dd6e:	4b12      	ldr	r3, [pc, #72]	; (ddb8 <nrfx_power_clock_irq_handler+0x60>)
    dd70:	681b      	ldr	r3, [r3, #0]
    dd72:	4798      	blx	r3
    return (bool)*((volatile uint32_t *)((uint8_t *)p_reg + event));
    dd74:	4b11      	ldr	r3, [pc, #68]	; (ddbc <nrfx_power_clock_irq_handler+0x64>)
    dd76:	681a      	ldr	r2, [r3, #0]
#endif
    }
    if (nrf_clock_event_check(NRF_CLOCK, NRF_CLOCK_EVENT_LFCLKSTARTED))
    dd78:	b182      	cbz	r2, dd9c <nrfx_power_clock_irq_handler+0x44>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    dd7a:	2200      	movs	r2, #0
    dd7c:	601a      	str	r2, [r3, #0]
    dd7e:	681b      	ldr	r3, [r3, #0]
                    (nrf_clock_lfclk_t)((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_SRC_Msk)
    dd80:	4b0c      	ldr	r3, [pc, #48]	; (ddb4 <nrfx_power_clock_irq_handler+0x5c>)
    dd82:	f8d3 2418 	ldr.w	r2, [r3, #1048]	; 0x418
            if ((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_STATE_Msk)
    dd86:	f8d3 1418 	ldr.w	r1, [r3, #1048]	; 0x418
        NRFX_LOG_DEBUG("Event: NRF_CLOCK_EVENT_LFCLKSTARTED");

#if NRFX_CHECK(NRFX_CLOCK_CONFIG_LFXO_TWO_STAGE_ENABLED)
        nrf_clock_lfclk_t lfclksrc;
        (void)nrf_clock_is_running(NRF_CLOCK, NRF_CLOCK_DOMAIN_LFCLK, &lfclksrc);
        if (lfclksrc == NRF_CLOCK_LFCLK_RC)
    dd8a:	f002 0203 	and.w	r2, r2, #3
    dd8e:	2a01      	cmp	r2, #1
    dd90:	f04f 0102 	mov.w	r1, #2
    dd94:	d103      	bne.n	dd9e <nrfx_power_clock_irq_handler+0x46>
    p_reg->LFCLKSRC = (uint32_t)(source);
    dd96:	f8c3 1518 	str.w	r1, [r3, #1304]	; 0x518
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    dd9a:	609a      	str	r2, [r3, #8]
        nrf_clock_int_disable(NRF_CLOCK, NRF_CLOCK_INT_HF192M_STARTED_MASK);

        m_clock_cb.event_handler(NRFX_CLOCK_EVT_HFCLK192M_STARTED);
    }
#endif
}
    dd9c:	bd10      	pop	{r4, pc}
    p_reg->INTENCLR = mask;
    dd9e:	f8c3 1308 	str.w	r1, [r3, #776]	; 0x308
            m_clock_cb.event_handler(NRFX_CLOCK_EVT_LFCLK_STARTED);
    dda2:	4b05      	ldr	r3, [pc, #20]	; (ddb8 <nrfx_power_clock_irq_handler+0x60>)
    dda4:	2001      	movs	r0, #1
}
    dda6:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
            m_clock_cb.event_handler(NRFX_CLOCK_EVT_LFCLK_STARTED);
    ddaa:	681b      	ldr	r3, [r3, #0]
    ddac:	4718      	bx	r3
    ddae:	bf00      	nop
    ddb0:	40005100 	.word	0x40005100
    ddb4:	40005000 	.word	0x40005000
    ddb8:	20010240 	.word	0x20010240
    ddbc:	40005104 	.word	0x40005104

0000ddc0 <z_sys_init_run_level>:
 * off and the next one begins.
 *
 * @param level init level to run.
 */
void z_sys_init_run_level(int32_t level)
{
    ddc0:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
		/* End marker */
		__init_end,
	};
	const struct init_entry *entry;

	for (entry = levels[level]; entry < levels[level+1]; entry++) {
    ddc2:	4b10      	ldr	r3, [pc, #64]	; (de04 <z_sys_init_run_level+0x44>)
			/* Initialization failed.
			 * Set the init status bit so device is not declared ready.
			 */
			sys_bitfield_set_bit(
				(mem_addr_t) __device_init_status_start,
				(dev - __device_start));
    ddc4:	4f10      	ldr	r7, [pc, #64]	; (de08 <z_sys_init_run_level+0x48>)
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
    ddc6:	f853 5020 	ldr.w	r5, [r3, r0, lsl #2]
    ddca:	3001      	adds	r0, #1
    ddcc:	f853 6020 	ldr.w	r6, [r3, r0, lsl #2]
    ddd0:	42ae      	cmp	r6, r5
    ddd2:	d800      	bhi.n	ddd6 <z_sys_init_run_level+0x16>
		}
	}
}
    ddd4:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		if ((entry->init(dev) != 0) && (dev != NULL)) {
    ddd6:	e9d5 3400 	ldrd	r3, r4, [r5]
    ddda:	4620      	mov	r0, r4
    dddc:	4798      	blx	r3
    ddde:	b170      	cbz	r0, ddfe <z_sys_init_run_level+0x3e>
    dde0:	b16c      	cbz	r4, ddfe <z_sys_init_run_level+0x3e>

static ALWAYS_INLINE void sys_set_bit(mem_addr_t addr, unsigned int bit)
{
	uint32_t temp = *(volatile uint32_t *)addr;

	*(volatile uint32_t *)addr = temp | (1 << bit);
    dde2:	2301      	movs	r3, #1
				(dev - __device_start));
    dde4:	1be4      	subs	r4, r4, r7
    dde6:	1124      	asrs	r4, r4, #4
	void sys_bitfield_set_bit(mem_addr_t addr, unsigned int bit)
{
	/* Doing memory offsets in terms of 32-bit values to prevent
	 * alignment issues
	 */
	sys_set_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    dde8:	4a08      	ldr	r2, [pc, #32]	; (de0c <z_sys_init_run_level+0x4c>)
    ddea:	0961      	lsrs	r1, r4, #5
	uint32_t temp = *(volatile uint32_t *)addr;
    ddec:	f852 0021 	ldr.w	r0, [r2, r1, lsl #2]
	sys_set_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    ddf0:	f004 041f 	and.w	r4, r4, #31
	*(volatile uint32_t *)addr = temp | (1 << bit);
    ddf4:	fa03 f404 	lsl.w	r4, r3, r4
    ddf8:	4304      	orrs	r4, r0
    ddfa:	f842 4021 	str.w	r4, [r2, r1, lsl #2]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
    ddfe:	3508      	adds	r5, #8
    de00:	e7e6      	b.n	ddd0 <z_sys_init_run_level+0x10>
    de02:	bf00      	nop
    de04:	0000fa54 	.word	0x0000fa54
    de08:	2001003c 	.word	0x2001003c
    de0c:	2001008c 	.word	0x2001008c

0000de10 <z_device_ready>:

bool z_device_ready(const struct device *dev)
{
	/* Set bit indicates device failed initialization */
	return !(sys_bitfield_test_bit((mem_addr_t)__device_init_status_start,
					(dev - __device_start)));
    de10:	4b08      	ldr	r3, [pc, #32]	; (de34 <z_device_ready+0x24>)
    de12:	1ac0      	subs	r0, r0, r3
    de14:	1100      	asrs	r0, r0, #4
}

static ALWAYS_INLINE
	int sys_bitfield_test_bit(mem_addr_t addr, unsigned int bit)
{
	return sys_test_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    de16:	4b08      	ldr	r3, [pc, #32]	; (de38 <z_device_ready+0x28>)
    de18:	0942      	lsrs	r2, r0, #5
	uint32_t temp = *(volatile uint32_t *)addr;
    de1a:	f853 2022 	ldr.w	r2, [r3, r2, lsl #2]
	return temp & (1 << bit);
    de1e:	2301      	movs	r3, #1
	return sys_test_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    de20:	f000 001f 	and.w	r0, r0, #31
	return temp & (1 << bit);
    de24:	fa03 f000 	lsl.w	r0, r3, r0
	return !(sys_bitfield_test_bit((mem_addr_t)__device_init_status_start,
    de28:	4210      	tst	r0, r2
}
    de2a:	bf0c      	ite	eq
    de2c:	4618      	moveq	r0, r3
    de2e:	2000      	movne	r0, #0
    de30:	4770      	bx	lr
    de32:	bf00      	nop
    de34:	2001003c 	.word	0x2001003c
    de38:	2001008c 	.word	0x2001008c

0000de3c <z_impl_device_get_binding>:
	for (dev = __device_start; dev != __device_end; dev++) {
    de3c:	4911      	ldr	r1, [pc, #68]	; (de84 <z_impl_device_get_binding+0x48>)
{
    de3e:	b570      	push	{r4, r5, r6, lr}
    de40:	4605      	mov	r5, r0
    de42:	460e      	mov	r6, r1
	for (dev = __device_start; dev != __device_end; dev++) {
    de44:	4c10      	ldr	r4, [pc, #64]	; (de88 <z_impl_device_get_binding+0x4c>)
    de46:	428c      	cmp	r4, r1
    de48:	d104      	bne.n	de54 <z_impl_device_get_binding+0x18>
	for (dev = __device_start; dev != __device_end; dev++) {
    de4a:	4c0f      	ldr	r4, [pc, #60]	; (de88 <z_impl_device_get_binding+0x4c>)
    de4c:	42b4      	cmp	r4, r6
    de4e:	d10a      	bne.n	de66 <z_impl_device_get_binding+0x2a>
	return NULL;
    de50:	2400      	movs	r4, #0
    de52:	e014      	b.n	de7e <z_impl_device_get_binding+0x42>
		if (z_device_ready(dev) && (dev->name == name)) {
    de54:	4620      	mov	r0, r4
    de56:	f7ff ffdb 	bl	de10 <z_device_ready>
    de5a:	b110      	cbz	r0, de62 <z_impl_device_get_binding+0x26>
    de5c:	6823      	ldr	r3, [r4, #0]
    de5e:	42ab      	cmp	r3, r5
    de60:	d00d      	beq.n	de7e <z_impl_device_get_binding+0x42>
	for (dev = __device_start; dev != __device_end; dev++) {
    de62:	3410      	adds	r4, #16
    de64:	e7ef      	b.n	de46 <z_impl_device_get_binding+0xa>
		if (z_device_ready(dev) && (strcmp(name, dev->name) == 0)) {
    de66:	4620      	mov	r0, r4
    de68:	f7ff ffd2 	bl	de10 <z_device_ready>
    de6c:	b908      	cbnz	r0, de72 <z_impl_device_get_binding+0x36>
	for (dev = __device_start; dev != __device_end; dev++) {
    de6e:	3410      	adds	r4, #16
    de70:	e7ec      	b.n	de4c <z_impl_device_get_binding+0x10>
		if (z_device_ready(dev) && (strcmp(name, dev->name) == 0)) {
    de72:	6821      	ldr	r1, [r4, #0]
    de74:	4628      	mov	r0, r5
    de76:	f001 f9f8 	bl	f26a <strcmp>
    de7a:	2800      	cmp	r0, #0
    de7c:	d1f7      	bne.n	de6e <z_impl_device_get_binding+0x32>
}
    de7e:	4620      	mov	r0, r4
    de80:	bd70      	pop	{r4, r5, r6, pc}
    de82:	bf00      	nop
    de84:	2001008c 	.word	0x2001008c
    de88:	2001003c 	.word	0x2001003c

0000de8c <idle>:
#else
#define IDLE_YIELD_IF_COOP() do { } while (false)
#endif

void idle(void *unused1, void *unused2, void *unused3)
{
    de8c:	b508      	push	{r3, lr}
	_kernel.idle = ticks;
    de8e:	4d0b      	ldr	r5, [pc, #44]	; (debc <idle+0x30>)
    de90:	f04f 0220 	mov.w	r2, #32
    de94:	f3ef 8311 	mrs	r3, BASEPRI
    de98:	f382 8811 	msr	BASEPRI, r2
    de9c:	f3bf 8f6f 	isb	sy
	int32_t ticks = z_get_next_timeout_expiry();
    dea0:	f001 fbf0 	bl	f684 <z_get_next_timeout_expiry>
	z_set_timeout_expiry((ticks < IDLE_THRESH) ? 1 : ticks, true);
    dea4:	2101      	movs	r1, #1
	int32_t ticks = z_get_next_timeout_expiry();
    dea6:	4604      	mov	r4, r0
	z_set_timeout_expiry((ticks < IDLE_THRESH) ? 1 : ticks, true);
    dea8:	2802      	cmp	r0, #2
    deaa:	bfd8      	it	le
    deac:	4608      	movle	r0, r1
    deae:	f001 fbf9 	bl	f6a4 <z_set_timeout_expiry>
	_kernel.idle = ticks;
    deb2:	622c      	str	r4, [r5, #32]
	arch_cpu_idle();
    deb4:	f7ff f85e 	bl	cf74 <arch_cpu_idle>
    deb8:	e7ea      	b.n	de90 <idle+0x4>
    deba:	bf00      	nop
    debc:	20010248 	.word	0x20010248

0000dec0 <z_bss_zero>:
 *
 * @return N/A
 */
void z_bss_zero(void)
{
	(void)memset(__bss_start, 0, __bss_end - __bss_start);
    dec0:	4802      	ldr	r0, [pc, #8]	; (decc <z_bss_zero+0xc>)
    dec2:	4a03      	ldr	r2, [pc, #12]	; (ded0 <z_bss_zero+0x10>)
    dec4:	2100      	movs	r1, #0
    dec6:	1a12      	subs	r2, r2, r0
    dec8:	f001 ba15 	b.w	f2f6 <memset>
    decc:	20010090 	.word	0x20010090
    ded0:	2001028c 	.word	0x2001028c

0000ded4 <z_data_copy>:
 * This routine copies the data section from ROM to RAM.
 *
 * @return N/A
 */
void z_data_copy(void)
{
    ded4:	b508      	push	{r3, lr}
	(void)memcpy(&__data_ram_start, &__data_rom_start,
		 __data_ram_end - __data_ram_start);
    ded6:	4806      	ldr	r0, [pc, #24]	; (def0 <z_data_copy+0x1c>)
	(void)memcpy(&__data_ram_start, &__data_rom_start,
    ded8:	4a06      	ldr	r2, [pc, #24]	; (def4 <z_data_copy+0x20>)
    deda:	4907      	ldr	r1, [pc, #28]	; (def8 <z_data_copy+0x24>)
    dedc:	1a12      	subs	r2, r2, r0
    dede:	f001 f9e0 	bl	f2a2 <memcpy>
#else
	(void)memcpy(&_app_smem_start, &_app_smem_rom_start,
		 _app_smem_end - _app_smem_start);
#endif /* CONFIG_STACK_CANARIES */
#endif /* CONFIG_USERSPACE */
}
    dee2:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	(void)memcpy(&_ramfunc_ram_start, &_ramfunc_rom_start,
    dee6:	4a05      	ldr	r2, [pc, #20]	; (defc <z_data_copy+0x28>)
    dee8:	4905      	ldr	r1, [pc, #20]	; (df00 <z_data_copy+0x2c>)
    deea:	4806      	ldr	r0, [pc, #24]	; (df04 <z_data_copy+0x30>)
    deec:	f001 b9d9 	b.w	f2a2 <memcpy>
    def0:	20010000 	.word	0x20010000
    def4:	20010090 	.word	0x20010090
    def8:	0000fb80 	.word	0x0000fb80
    defc:	00000000 	.word	0x00000000
    df00:	0000fb80 	.word	0x0000fb80
    df04:	20010000 	.word	0x20010000

0000df08 <bg_thread_main>:
	static const unsigned int boot_delay = CONFIG_BOOT_DELAY;
#else
	static const unsigned int boot_delay;
#endif

	z_sys_post_kernel = true;
    df08:	2201      	movs	r2, #1
{
    df0a:	b508      	push	{r3, lr}
	z_sys_post_kernel = true;
    df0c:	4b0b      	ldr	r3, [pc, #44]	; (df3c <bg_thread_main+0x34>)

	z_sys_init_run_level(_SYS_INIT_LEVEL_POST_KERNEL);
    df0e:	2002      	movs	r0, #2
	z_sys_post_kernel = true;
    df10:	701a      	strb	r2, [r3, #0]
	z_sys_init_run_level(_SYS_INIT_LEVEL_POST_KERNEL);
    df12:	f7ff ff55 	bl	ddc0 <z_sys_init_run_level>
		k_busy_wait(CONFIG_BOOT_DELAY * USEC_PER_MSEC);
	}

#if defined(CONFIG_BOOT_BANNER)
#ifdef BUILD_VERSION
	printk("*** Booting Zephyr OS build %s %s ***\n",
    df16:	4a0a      	ldr	r2, [pc, #40]	; (df40 <bg_thread_main+0x38>)
    df18:	490a      	ldr	r1, [pc, #40]	; (df44 <bg_thread_main+0x3c>)
    df1a:	480b      	ldr	r0, [pc, #44]	; (df48 <bg_thread_main+0x40>)
    df1c:	f000 ff2c 	bl	ed78 <printk>
	__do_global_ctors_aux();
	__do_init_array_aux();
#endif

	/* Final init level before app starts */
	z_sys_init_run_level(_SYS_INIT_LEVEL_APPLICATION);
    df20:	2003      	movs	r0, #3
    df22:	f7ff ff4d 	bl	ddc0 <z_sys_init_run_level>

	z_init_static_threads();
    df26:	f000 fc23 	bl	e770 <z_init_static_threads>
	z_timestamp_main = k_cycle_get_32();
#endif

	extern void main(void);

	main();
    df2a:	f7fe fb35 	bl	c598 <main>

	/* Mark nonessenrial since main() has no more work to do */
	z_main_thread.base.user_options &= ~K_ESSENTIAL;
    df2e:	4a07      	ldr	r2, [pc, #28]	; (df4c <bg_thread_main+0x44>)
    df30:	7b13      	ldrb	r3, [r2, #12]
    df32:	f023 0301 	bic.w	r3, r3, #1
    df36:	7313      	strb	r3, [r2, #12]

#ifdef CONFIG_COVERAGE_DUMP
	/* Dump coverage data once the main() has exited. */
	gcov_coverage_dump();
#endif
} /* LCOV_EXCL_LINE ... because we just dumped final coverage data */
    df38:	bd08      	pop	{r3, pc}
    df3a:	bf00      	nop
    df3c:	2001028b 	.word	0x2001028b
    df40:	0000fb42 	.word	0x0000fb42
    df44:	0000fb43 	.word	0x0000fb43
    df48:	0000fb4f 	.word	0x0000fb4f
    df4c:	20010110 	.word	0x20010110

0000df50 <z_cstart>:
 * cleared/zeroed.
 *
 * @return Does not return
 */
FUNC_NORETURN void z_cstart(void)
{
    df50:	e92d 4880 	stmdb	sp!, {r7, fp, lr}
 * @return N/A
 */
static ALWAYS_INLINE void z_arm_interrupt_stack_setup(void)
{
	uint32_t msp =
		(uint32_t)(Z_KERNEL_STACK_BUFFER(z_interrupt_stacks[0])) +
    df54:	4b34      	ldr	r3, [pc, #208]	; (e028 <z_cstart+0xd8>)
    df56:	b0a7      	sub	sp, #156	; 0x9c
	uint32_t msp =
    df58:	f503 6900 	add.w	r9, r3, #2048	; 0x800
  __ASM volatile ("MSR msp, %0" : : "r" (topOfMainStack) : );
    df5c:	f389 8808 	msr	MSP, r9
  __ASM volatile ("MSR msplim, %0" : : "r" (MainStackPtrLimit));
    df60:	f383 880a 	msr	MSPLIM, r3
    SCB->SHPR[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    df64:	2400      	movs	r4, #0
    df66:	23e0      	movs	r3, #224	; 0xe0
    df68:	4d30      	ldr	r5, [pc, #192]	; (e02c <z_cstart+0xdc>)
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    df6a:	f04f 0b01 	mov.w	fp, #1
    df6e:	f885 3022 	strb.w	r3, [r5, #34]	; 0x22
    df72:	77ec      	strb	r4, [r5, #31]
    df74:	762c      	strb	r4, [r5, #24]
    df76:	766c      	strb	r4, [r5, #25]
    df78:	76ac      	strb	r4, [r5, #26]
#if defined(CONFIG_ARM_SECURE_FIRMWARE)
	NVIC_SetPriority(SecureFault_IRQn, _EXC_FAULT_PRIO);
#endif /* CONFIG_ARM_SECURE_FIRMWARE */

	/* Enable Usage, Mem, & Bus Faults */
	SCB->SHCSR |= SCB_SHCSR_USGFAULTENA_Msk | SCB_SHCSR_MEMFAULTENA_Msk |
    df7a:	6a6b      	ldr	r3, [r5, #36]	; 0x24
	_kernel.ready_q.cache = &z_main_thread;
    df7c:	4e2c      	ldr	r6, [pc, #176]	; (e030 <z_cstart+0xe0>)
    df7e:	f443 23e0 	orr.w	r3, r3, #458752	; 0x70000
    df82:	626b      	str	r3, [r5, #36]	; 0x24

static ALWAYS_INLINE void arch_kernel_init(void)
{
	z_arm_interrupt_stack_setup();
	z_arm_exc_setup();
	z_arm_fault_init();
    df84:	f7ff f92e 	bl	d1e4 <z_arm_fault_init>
	z_arm_cpu_idle_init();
    df88:	f7fe ffee 	bl	cf68 <z_arm_cpu_idle_init>
static ALWAYS_INLINE void z_arm_clear_faults(void)
{
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	/* Reset all faults */
	SCB->CFSR = SCB_CFSR_USGFAULTSR_Msk |
    df8c:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
    df90:	62ab      	str	r3, [r5, #40]	; 0x28
		    SCB_CFSR_MEMFAULTSR_Msk |
		    SCB_CFSR_BUSFAULTSR_Msk;

	/* Clear all Hard Faults - HFSR is write-one-to-clear */
	SCB->HFSR = 0xffffffff;
    df92:	62eb      	str	r3, [r5, #44]	; 0x2c
{
	dummy_thread->base.thread_state = _THREAD_DUMMY;
#ifdef CONFIG_SCHED_CPU_MASK
	dummy_thread->base.cpu_mask = -1;
#endif
	dummy_thread->base.user_options = K_ESSENTIAL;
    df94:	f240 1301 	movw	r3, #257	; 0x101
#endif
#ifdef CONFIG_USERSPACE
	dummy_thread->mem_domain_info.mem_domain = &k_mem_domain_default;
#endif

	_current_cpu->current = dummy_thread;
    df98:	4d26      	ldr	r5, [pc, #152]	; (e034 <z_cstart+0xe4>)
	dummy_thread->base.user_options = K_ESSENTIAL;
    df9a:	f8ad 3024 	strh.w	r3, [sp, #36]	; 0x24
	_current_cpu->current = dummy_thread;
    df9e:	ab06      	add	r3, sp, #24
    dfa0:	60ab      	str	r3, [r5, #8]

	z_dummy_thread_init(&dummy_thread);
#endif

	/* perform basic hardware initialization */
	z_sys_init_run_level(_SYS_INIT_LEVEL_PRE_KERNEL_1);
    dfa2:	4620      	mov	r0, r4
	dummy_thread->stack_info.size = 0U;
    dfa4:	e9cd 4420 	strd	r4, r4, [sp, #128]	; 0x80
    dfa8:	f7ff ff0a 	bl	ddc0 <z_sys_init_run_level>
	z_sys_init_run_level(_SYS_INIT_LEVEL_PRE_KERNEL_2);
    dfac:	2001      	movs	r0, #1
    dfae:	f7ff ff07 	bl	ddc0 <z_sys_init_run_level>
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    dfb2:	f8df 8098 	ldr.w	r8, [pc, #152]	; e04c <z_cstart+0xfc>
	z_sched_init();
    dfb6:	f000 fae5 	bl	e584 <z_sched_init>
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    dfba:	4b1f      	ldr	r3, [pc, #124]	; (e038 <z_cstart+0xe8>)
	_kernel.ready_q.cache = &z_main_thread;
    dfbc:	626e      	str	r6, [r5, #36]	; 0x24
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    dfbe:	f44f 6280 	mov.w	r2, #1024	; 0x400
    dfc2:	491e      	ldr	r1, [pc, #120]	; (e03c <z_cstart+0xec>)
    dfc4:	9305      	str	r3, [sp, #20]
    dfc6:	e9cd 4b03 	strd	r4, fp, [sp, #12]
    dfca:	4643      	mov	r3, r8
    dfcc:	e9cd 4401 	strd	r4, r4, [sp, #4]
    dfd0:	9400      	str	r4, [sp, #0]
    dfd2:	4630      	mov	r0, r6
    dfd4:	f000 fb9e 	bl	e714 <z_setup_new_thread>
	sys_trace_thread_resume(thread);
}

static inline void z_mark_thread_as_started(struct k_thread *thread)
{
	thread->base.thread_state &= ~_THREAD_PRESTART;
    dfd8:	7b73      	ldrb	r3, [r6, #13]
    dfda:	4682      	mov	sl, r0
    dfdc:	f023 0304 	bic.w	r3, r3, #4
	z_ready_thread(&z_main_thread);
    dfe0:	4630      	mov	r0, r6
    dfe2:	7373      	strb	r3, [r6, #13]
    dfe4:	f001 fab3 	bl	f54e <z_ready_thread>
	z_setup_new_thread(thread, stack,
    dfe8:	230f      	movs	r3, #15
    dfea:	4f15      	ldr	r7, [pc, #84]	; (e040 <z_cstart+0xf0>)
    dfec:	e9cd 4302 	strd	r4, r3, [sp, #8]
    dff0:	f44f 72a0 	mov.w	r2, #320	; 0x140
    dff4:	4b13      	ldr	r3, [pc, #76]	; (e044 <z_cstart+0xf4>)
    dff6:	4914      	ldr	r1, [pc, #80]	; (e048 <z_cstart+0xf8>)
    dff8:	e9cd b404 	strd	fp, r4, [sp, #16]
    dffc:	e9cd 4400 	strd	r4, r4, [sp]
    e000:	4638      	mov	r0, r7
    e002:	f000 fb87 	bl	e714 <z_setup_new_thread>
    e006:	7b7b      	ldrb	r3, [r7, #13]
		_kernel.cpus[i].idle_thread = &z_idle_threads[i];
    e008:	60ef      	str	r7, [r5, #12]
    e00a:	f023 0304 	bic.w	r3, r3, #4
    e00e:	737b      	strb	r3, [r7, #13]
 * @return N/A
 */

static inline void sys_dlist_init(sys_dlist_t *list)
{
	list->head = (sys_dnode_t *)list;
    e010:	f105 0318 	add.w	r3, r5, #24
		_kernel.cpus[i].id = i;
    e014:	752c      	strb	r4, [r5, #20]
		_kernel.cpus[i].irq_stack =
    e016:	f8c5 9004 	str.w	r9, [r5, #4]
	list->tail = (sys_dnode_t *)list;
    e01a:	e9c5 3306 	strd	r3, r3, [r5, #24]
	arch_switch_to_main_thread(&z_main_thread, stack_ptr, bg_thread_main);
    e01e:	4642      	mov	r2, r8
    e020:	4651      	mov	r1, sl
    e022:	4630      	mov	r0, r6
    e024:	f7fe ff28 	bl	ce78 <arch_switch_to_main_thread>
	CODE_UNREACHABLE; /* LCOV_EXCL_LINE */
    e028:	200107d0 	.word	0x200107d0
    e02c:	e000ed00 	.word	0xe000ed00
    e030:	20010110 	.word	0x20010110
    e034:	20010248 	.word	0x20010248
    e038:	0000fb76 	.word	0x0000fb76
    e03c:	20010290 	.word	0x20010290
    e040:	20010090 	.word	0x20010090
    e044:	0000de8d 	.word	0x0000de8d
    e048:	20010690 	.word	0x20010690
    e04c:	0000df09 	.word	0x0000df09

0000e050 <z_reset_time_slice>:
 */
static struct k_thread *pending_current;
#endif

void z_reset_time_slice(void)
{
    e050:	b510      	push	{r4, lr}
	/* Add the elapsed time since the last announced tick to the
	 * slice count, as we'll see those "expired" ticks arrive in a
	 * FUTURE z_time_slice() call.
	 */
	if (slice_time != 0) {
    e052:	4c08      	ldr	r4, [pc, #32]	; (e074 <z_reset_time_slice+0x24>)
    e054:	6823      	ldr	r3, [r4, #0]
    e056:	b15b      	cbz	r3, e070 <z_reset_time_slice+0x20>
		_current_cpu->slice_ticks = slice_time + z_clock_elapsed();
    e058:	f7fe fe88 	bl	cd6c <z_clock_elapsed>
    e05c:	6823      	ldr	r3, [r4, #0]
    e05e:	4a06      	ldr	r2, [pc, #24]	; (e078 <z_reset_time_slice+0x28>)
    e060:	4418      	add	r0, r3
    e062:	6110      	str	r0, [r2, #16]
		z_set_timeout_expiry(slice_time, false);
    e064:	2100      	movs	r1, #0
	}
}
    e066:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		z_set_timeout_expiry(slice_time, false);
    e06a:	4618      	mov	r0, r3
    e06c:	f001 bb1a 	b.w	f6a4 <z_set_timeout_expiry>
}
    e070:	bd10      	pop	{r4, pc}
    e072:	bf00      	nop
    e074:	20010280 	.word	0x20010280
    e078:	20010248 	.word	0x20010248

0000e07c <k_sched_time_slice_set>:

void k_sched_time_slice_set(int32_t slice, int prio)
{
    e07c:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    e07e:	460d      	mov	r5, r1
    e080:	f04f 0320 	mov.w	r3, #32
    e084:	f3ef 8411 	mrs	r4, BASEPRI
    e088:	f383 8811 	msr	BASEPRI, r3
    e08c:	f3bf 8f6f 	isb	sy
		} else {
			return t * (to_hz / from_hz);
		}
	} else {
		if (result32) {
			return (uint32_t)((t * to_hz + off) / from_hz);
    e090:	f44f 4100 	mov.w	r1, #32768	; 0x8000
    e094:	f240 36e7 	movw	r6, #999	; 0x3e7
    e098:	2700      	movs	r7, #0
	LOCKED(&sched_spinlock) {
		_current_cpu->slice_ticks = 0;
    e09a:	2200      	movs	r2, #0
    e09c:	fbe1 6700 	umlal	r6, r7, r1, r0
    e0a0:	4b09      	ldr	r3, [pc, #36]	; (e0c8 <k_sched_time_slice_set+0x4c>)
    e0a2:	4630      	mov	r0, r6
    e0a4:	611a      	str	r2, [r3, #16]
    e0a6:	4639      	mov	r1, r7
    e0a8:	f44f 727a 	mov.w	r2, #1000	; 0x3e8
    e0ac:	2300      	movs	r3, #0
    e0ae:	f7fe f8c5 	bl	c23c <__aeabi_uldivmod>
		slice_time = k_ms_to_ticks_ceil32(slice);
    e0b2:	4b06      	ldr	r3, [pc, #24]	; (e0cc <k_sched_time_slice_set+0x50>)
    e0b4:	6018      	str	r0, [r3, #0]
		slice_max_prio = prio;
    e0b6:	4b06      	ldr	r3, [pc, #24]	; (e0d0 <k_sched_time_slice_set+0x54>)
    e0b8:	601d      	str	r5, [r3, #0]
		z_reset_time_slice();
    e0ba:	f7ff ffc9 	bl	e050 <z_reset_time_slice>
	__asm__ volatile(
    e0be:	f384 8811 	msr	BASEPRI, r4
    e0c2:	f3bf 8f6f 	isb	sy
	}
}
    e0c6:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    e0c8:	20010248 	.word	0x20010248
    e0cc:	20010280 	.word	0x20010280
    e0d0:	2001027c 	.word	0x2001027c

0000e0d4 <z_reschedule>:
{
#ifdef CONFIG_SMP
	_current_cpu->swap_ok = 0;
#endif

	return arch_irq_unlocked(key) && !arch_is_in_isr();
    e0d4:	b949      	cbnz	r1, e0ea <z_reschedule+0x16>
  __ASM volatile ("MRS %0, ipsr" : "=r" (result) );
    e0d6:	f3ef 8005 	mrs	r0, IPSR
    e0da:	b930      	cbnz	r0, e0ea <z_reschedule+0x16>
	return _kernel.ready_q.cache;
    e0dc:	4b05      	ldr	r3, [pc, #20]	; (e0f4 <z_reschedule+0x20>)
#endif
}

void z_reschedule(struct k_spinlock *lock, k_spinlock_key_t key)
{
	if (resched(key.key) && need_swap()) {
    e0de:	6a5a      	ldr	r2, [r3, #36]	; 0x24
    e0e0:	689b      	ldr	r3, [r3, #8]
    e0e2:	429a      	cmp	r2, r3
    e0e4:	d001      	beq.n	e0ea <z_reschedule+0x16>
	ret = arch_swap(key);
    e0e6:	f7fe be5b 	b.w	cda0 <arch_swap>
    e0ea:	f381 8811 	msr	BASEPRI, r1
    e0ee:	f3bf 8f6f 	isb	sy
		z_swap(lock, key);
	} else {
		k_spin_unlock(lock, key);
	}
}
    e0f2:	4770      	bx	lr
    e0f4:	20010248 	.word	0x20010248

0000e0f8 <k_sched_lock>:
	__asm__ volatile(
    e0f8:	f04f 0320 	mov.w	r3, #32
    e0fc:	f3ef 8111 	mrs	r1, BASEPRI
    e100:	f383 8811 	msr	BASEPRI, r3
    e104:	f3bf 8f6f 	isb	sy
{
#ifdef CONFIG_PREEMPT_ENABLED
	__ASSERT(!arch_is_in_isr(), "");
	__ASSERT(_current->base.sched_locked != 1, "");

	--_current->base.sched_locked;
    e108:	4b04      	ldr	r3, [pc, #16]	; (e11c <k_sched_lock+0x24>)
    e10a:	689a      	ldr	r2, [r3, #8]
    e10c:	7bd3      	ldrb	r3, [r2, #15]
    e10e:	3b01      	subs	r3, #1
    e110:	73d3      	strb	r3, [r2, #15]
	__asm__ volatile(
    e112:	f381 8811 	msr	BASEPRI, r1
    e116:	f3bf 8f6f 	isb	sy
void k_sched_lock(void)
{
	LOCKED(&sched_spinlock) {
		z_sched_lock();
	}
}
    e11a:	4770      	bx	lr
    e11c:	20010248 	.word	0x20010248

0000e120 <z_priq_dumb_remove>:
}

void z_priq_dumb_remove(sys_dlist_t *pq, struct k_thread *thread)
{
#if defined(CONFIG_SWAP_NONATOMIC) && defined(CONFIG_SCHED_DUMB)
	if (pq == &_kernel.ready_q.runq && thread == _current &&
    e120:	4b09      	ldr	r3, [pc, #36]	; (e148 <z_priq_dumb_remove+0x28>)
    e122:	f103 0228 	add.w	r2, r3, #40	; 0x28
    e126:	4282      	cmp	r2, r0
    e128:	d105      	bne.n	e136 <z_priq_dumb_remove+0x16>
    e12a:	689b      	ldr	r3, [r3, #8]
    e12c:	428b      	cmp	r3, r1
    e12e:	d102      	bne.n	e136 <z_priq_dumb_remove+0x16>
    e130:	7b4b      	ldrb	r3, [r1, #13]
    e132:	06db      	lsls	r3, r3, #27
    e134:	d106      	bne.n	e144 <z_priq_dumb_remove+0x24>
 * @return N/A
 */

static inline void sys_dlist_remove(sys_dnode_t *node)
{
	node->prev->next = node->next;
    e136:	e9d1 3200 	ldrd	r3, r2, [r1]
    e13a:	6013      	str	r3, [r2, #0]
	node->next->prev = node->prev;
    e13c:	605a      	str	r2, [r3, #4]
	node->next = NULL;
    e13e:	2300      	movs	r3, #0
	node->prev = NULL;
    e140:	e9c1 3300 	strd	r3, r3, [r1]
#endif

	__ASSERT_NO_MSG(!z_is_idle_thread_object(thread));

	sys_dlist_remove(&thread->base.qnode_dlist);
}
    e144:	4770      	bx	lr
    e146:	bf00      	nop
    e148:	20010248 	.word	0x20010248

0000e14c <update_cache>:
{
    e14c:	b570      	push	{r4, r5, r6, lr}
	struct k_thread *thread = _priq_run_best(&_kernel.ready_q.runq);
    e14e:	4c10      	ldr	r4, [pc, #64]	; (e190 <update_cache+0x44>)
{
    e150:	4606      	mov	r6, r0
	struct k_thread *thread = _priq_run_best(&_kernel.ready_q.runq);
    e152:	f104 0028 	add.w	r0, r4, #40	; 0x28
    e156:	f001 f9f4 	bl	f542 <z_priq_dumb_best>
    e15a:	4605      	mov	r5, r0
	if (_current->base.thread_state & _THREAD_ABORTING) {
    e15c:	68a3      	ldr	r3, [r4, #8]
    e15e:	7b59      	ldrb	r1, [r3, #13]
    e160:	0688      	lsls	r0, r1, #26
		_current->base.thread_state |= _THREAD_DEAD;
    e162:	bf44      	itt	mi
    e164:	f041 0108 	orrmi.w	r1, r1, #8
    e168:	7359      	strbmi	r1, [r3, #13]
	return thread ? thread : _current_cpu->idle_thread;
    e16a:	b905      	cbnz	r5, e16e <update_cache+0x22>
    e16c:	68e5      	ldr	r5, [r4, #12]
	if (preempt_ok != 0) {
    e16e:	b94e      	cbnz	r6, e184 <update_cache+0x38>
	if (z_is_thread_prevented_from_running(_current)) {
    e170:	7b5a      	ldrb	r2, [r3, #13]
    e172:	06d2      	lsls	r2, r2, #27
    e174:	d106      	bne.n	e184 <update_cache+0x38>
	if (IS_ENABLED(CONFIG_SWAP_NONATOMIC)
    e176:	69aa      	ldr	r2, [r5, #24]
    e178:	b922      	cbnz	r2, e184 <update_cache+0x38>
	if (is_preempt(_current) || is_metairq(thread)) {
    e17a:	89da      	ldrh	r2, [r3, #14]
    e17c:	2a7f      	cmp	r2, #127	; 0x7f
    e17e:	d901      	bls.n	e184 <update_cache+0x38>
		_kernel.ready_q.cache = _current;
    e180:	6263      	str	r3, [r4, #36]	; 0x24
}
    e182:	bd70      	pop	{r4, r5, r6, pc}
		if (thread != _current) {
    e184:	42ab      	cmp	r3, r5
    e186:	d001      	beq.n	e18c <update_cache+0x40>
			z_reset_time_slice();
    e188:	f7ff ff62 	bl	e050 <z_reset_time_slice>
		_kernel.ready_q.cache = thread;
    e18c:	6265      	str	r5, [r4, #36]	; 0x24
}
    e18e:	e7f8      	b.n	e182 <update_cache+0x36>
    e190:	20010248 	.word	0x20010248

0000e194 <k_sched_unlock>:
{
    e194:	b510      	push	{r4, lr}
	__asm__ volatile(
    e196:	f04f 0320 	mov.w	r3, #32
    e19a:	f3ef 8411 	mrs	r4, BASEPRI
    e19e:	f383 8811 	msr	BASEPRI, r3
    e1a2:	f3bf 8f6f 	isb	sy
		++_current->base.sched_locked;
    e1a6:	4b08      	ldr	r3, [pc, #32]	; (e1c8 <k_sched_unlock+0x34>)
		update_cache(0);
    e1a8:	2000      	movs	r0, #0
		++_current->base.sched_locked;
    e1aa:	689a      	ldr	r2, [r3, #8]
    e1ac:	7bd3      	ldrb	r3, [r2, #15]
    e1ae:	3301      	adds	r3, #1
    e1b0:	73d3      	strb	r3, [r2, #15]
		update_cache(0);
    e1b2:	f7ff ffcb 	bl	e14c <update_cache>
	__asm__ volatile(
    e1b6:	f384 8811 	msr	BASEPRI, r4
    e1ba:	f3bf 8f6f 	isb	sy
}
    e1be:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule_unlocked();
    e1c2:	f001 b9a7 	b.w	f514 <z_reschedule_unlocked>
    e1c6:	bf00      	nop
    e1c8:	20010248 	.word	0x20010248

0000e1cc <ready_thread>:
{
    e1cc:	b470      	push	{r4, r5, r6}
	return !((z_is_thread_prevented_from_running(thread)) != 0 ||
    e1ce:	7b43      	ldrb	r3, [r0, #13]
    e1d0:	06db      	lsls	r3, r3, #27
    e1d2:	d127      	bne.n	e224 <ready_thread+0x58>
	if (z_is_thread_ready(thread)) {
    e1d4:	6983      	ldr	r3, [r0, #24]
    e1d6:	bb2b      	cbnz	r3, e224 <ready_thread+0x58>
	return list->head == list;
    e1d8:	4a13      	ldr	r2, [pc, #76]	; (e228 <ready_thread+0x5c>)
	return sys_dlist_is_empty(list) ? NULL : list->head;
    e1da:	f102 0128 	add.w	r1, r2, #40	; 0x28
    e1de:	e9d2 340a 	ldrd	r3, r4, [r2, #40]	; 0x28
    e1e2:	428b      	cmp	r3, r1
    e1e4:	d018      	beq.n	e218 <ready_thread+0x4c>
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    e1e6:	b1bb      	cbz	r3, e218 <ready_thread+0x4c>
	if (thread_1->base.prio < thread_2->base.prio) {
    e1e8:	f990 500e 	ldrsb.w	r5, [r0, #14]
    e1ec:	f993 600e 	ldrsb.w	r6, [r3, #14]
    e1f0:	42ae      	cmp	r6, r5
    e1f2:	dd0c      	ble.n	e20e <ready_thread+0x42>
	node->prev = successor->prev;
    e1f4:	685a      	ldr	r2, [r3, #4]
	node->next = successor;
    e1f6:	e9c0 3200 	strd	r3, r2, [r0]
	successor->prev->next = node;
    e1fa:	6010      	str	r0, [r2, #0]
	successor->prev = node;
    e1fc:	6058      	str	r0, [r3, #4]
	thread->base.thread_state |= states;
    e1fe:	7b43      	ldrb	r3, [r0, #13]
    e200:	f063 037f 	orn	r3, r3, #127	; 0x7f
    e204:	7343      	strb	r3, [r0, #13]
}
    e206:	bc70      	pop	{r4, r5, r6}
		update_cache(0);
    e208:	2000      	movs	r0, #0
    e20a:	f7ff bf9f 	b.w	e14c <update_cache>
	return (node == list->tail) ? NULL : node->next;
    e20e:	429c      	cmp	r4, r3
    e210:	d002      	beq.n	e218 <ready_thread+0x4c>
    e212:	681b      	ldr	r3, [r3, #0]
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    e214:	2b00      	cmp	r3, #0
    e216:	d1e9      	bne.n	e1ec <ready_thread+0x20>
	node->prev = list->tail;
    e218:	e9c0 1400 	strd	r1, r4, [r0]
	list->tail->next = node;
    e21c:	6ad3      	ldr	r3, [r2, #44]	; 0x2c
    e21e:	6018      	str	r0, [r3, #0]
	list->tail = node;
    e220:	62d0      	str	r0, [r2, #44]	; 0x2c
    e222:	e7ec      	b.n	e1fe <ready_thread+0x32>
}
    e224:	bc70      	pop	{r4, r5, r6}
    e226:	4770      	bx	lr
    e228:	20010248 	.word	0x20010248

0000e22c <z_sched_start>:
{
    e22c:	b510      	push	{r4, lr}
	__asm__ volatile(
    e22e:	f04f 0320 	mov.w	r3, #32
    e232:	f3ef 8411 	mrs	r4, BASEPRI
    e236:	f383 8811 	msr	BASEPRI, r3
    e23a:	f3bf 8f6f 	isb	sy
	if (z_has_thread_started(thread)) {
    e23e:	7b43      	ldrb	r3, [r0, #13]
    e240:	0759      	lsls	r1, r3, #29
    e242:	d404      	bmi.n	e24e <z_sched_start+0x22>
	__asm__ volatile(
    e244:	f384 8811 	msr	BASEPRI, r4
    e248:	f3bf 8f6f 	isb	sy
}
    e24c:	bd10      	pop	{r4, pc}
	thread->base.thread_state &= ~_THREAD_PRESTART;
    e24e:	f023 0304 	bic.w	r3, r3, #4
    e252:	7343      	strb	r3, [r0, #13]
	ready_thread(thread);
    e254:	f7ff ffba 	bl	e1cc <ready_thread>
	z_reschedule(&sched_spinlock, key);
    e258:	4621      	mov	r1, r4
}
    e25a:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule(&sched_spinlock, key);
    e25e:	4801      	ldr	r0, [pc, #4]	; (e264 <z_sched_start+0x38>)
    e260:	f7ff bf38 	b.w	e0d4 <z_reschedule>
    e264:	2001028c 	.word	0x2001028c

0000e268 <move_thread_to_end_of_prio_q>:
{
    e268:	b570      	push	{r4, r5, r6, lr}
	if (z_is_thread_queued(thread)) {
    e26a:	f990 300d 	ldrsb.w	r3, [r0, #13]
{
    e26e:	4604      	mov	r4, r0
	if (z_is_thread_queued(thread)) {
    e270:	2b00      	cmp	r3, #0
    e272:	da03      	bge.n	e27c <move_thread_to_end_of_prio_q+0x14>
		_priq_run_remove(&_kernel.ready_q.runq, thread);
    e274:	4601      	mov	r1, r0
    e276:	4816      	ldr	r0, [pc, #88]	; (e2d0 <move_thread_to_end_of_prio_q+0x68>)
    e278:	f7ff ff52 	bl	e120 <z_priq_dumb_remove>
	return list->head == list;
    e27c:	4a15      	ldr	r2, [pc, #84]	; (e2d4 <move_thread_to_end_of_prio_q+0x6c>)
	return sys_dlist_is_empty(list) ? NULL : list->head;
    e27e:	f102 0128 	add.w	r1, r2, #40	; 0x28
    e282:	e9d2 300a 	ldrd	r3, r0, [r2, #40]	; 0x28
    e286:	428b      	cmp	r3, r1
    e288:	d01c      	beq.n	e2c4 <move_thread_to_end_of_prio_q+0x5c>
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    e28a:	b1db      	cbz	r3, e2c4 <move_thread_to_end_of_prio_q+0x5c>
	if (thread_1->base.prio < thread_2->base.prio) {
    e28c:	f994 500e 	ldrsb.w	r5, [r4, #14]
    e290:	f993 600e 	ldrsb.w	r6, [r3, #14]
    e294:	42ae      	cmp	r6, r5
    e296:	dd10      	ble.n	e2ba <move_thread_to_end_of_prio_q+0x52>
	node->prev = successor->prev;
    e298:	6859      	ldr	r1, [r3, #4]
	node->next = successor;
    e29a:	e9c4 3100 	strd	r3, r1, [r4]
	successor->prev->next = node;
    e29e:	600c      	str	r4, [r1, #0]
	successor->prev = node;
    e2a0:	605c      	str	r4, [r3, #4]
	thread->base.thread_state |= states;
    e2a2:	7b63      	ldrb	r3, [r4, #13]
	update_cache(thread == _current);
    e2a4:	6890      	ldr	r0, [r2, #8]
    e2a6:	f063 037f 	orn	r3, r3, #127	; 0x7f
    e2aa:	7363      	strb	r3, [r4, #13]
    e2ac:	1b03      	subs	r3, r0, r4
    e2ae:	4258      	negs	r0, r3
    e2b0:	4158      	adcs	r0, r3
}
    e2b2:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
	update_cache(thread == _current);
    e2b6:	f7ff bf49 	b.w	e14c <update_cache>
	return (node == list->tail) ? NULL : node->next;
    e2ba:	4298      	cmp	r0, r3
    e2bc:	d002      	beq.n	e2c4 <move_thread_to_end_of_prio_q+0x5c>
    e2be:	681b      	ldr	r3, [r3, #0]
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    e2c0:	2b00      	cmp	r3, #0
    e2c2:	d1e5      	bne.n	e290 <move_thread_to_end_of_prio_q+0x28>
	node->prev = list->tail;
    e2c4:	e9c4 1000 	strd	r1, r0, [r4]
	list->tail->next = node;
    e2c8:	6ad3      	ldr	r3, [r2, #44]	; 0x2c
    e2ca:	601c      	str	r4, [r3, #0]
	list->tail = node;
    e2cc:	62d4      	str	r4, [r2, #44]	; 0x2c
    e2ce:	e7e8      	b.n	e2a2 <move_thread_to_end_of_prio_q+0x3a>
    e2d0:	20010270 	.word	0x20010270
    e2d4:	20010248 	.word	0x20010248

0000e2d8 <z_time_slice>:
{
    e2d8:	b570      	push	{r4, r5, r6, lr}
	__asm__ volatile(
    e2da:	f04f 0320 	mov.w	r3, #32
    e2de:	f3ef 8411 	mrs	r4, BASEPRI
    e2e2:	f383 8811 	msr	BASEPRI, r3
    e2e6:	f3bf 8f6f 	isb	sy
	if (pending_current == _current) {
    e2ea:	4a17      	ldr	r2, [pc, #92]	; (e348 <z_time_slice+0x70>)
    e2ec:	4917      	ldr	r1, [pc, #92]	; (e34c <z_time_slice+0x74>)
    e2ee:	6893      	ldr	r3, [r2, #8]
    e2f0:	680d      	ldr	r5, [r1, #0]
    e2f2:	42ab      	cmp	r3, r5
    e2f4:	4615      	mov	r5, r2
    e2f6:	d106      	bne.n	e306 <z_time_slice+0x2e>
			z_reset_time_slice();
    e2f8:	f7ff feaa 	bl	e050 <z_reset_time_slice>
	__asm__ volatile(
    e2fc:	f384 8811 	msr	BASEPRI, r4
    e300:	f3bf 8f6f 	isb	sy
}
    e304:	bd70      	pop	{r4, r5, r6, pc}
	pending_current = NULL;
    e306:	2600      	movs	r6, #0
    e308:	600e      	str	r6, [r1, #0]
	if (slice_time && sliceable(_current)) {
    e30a:	4911      	ldr	r1, [pc, #68]	; (e350 <z_time_slice+0x78>)
    e30c:	6809      	ldr	r1, [r1, #0]
    e30e:	b1c1      	cbz	r1, e342 <z_time_slice+0x6a>
		&& !z_is_idle_thread_object(thread);
    e310:	89d9      	ldrh	r1, [r3, #14]
    e312:	297f      	cmp	r1, #127	; 0x7f
    e314:	d815      	bhi.n	e342 <z_time_slice+0x6a>
		&& !z_is_thread_prevented_from_running(thread)
    e316:	7b59      	ldrb	r1, [r3, #13]
    e318:	06c9      	lsls	r1, r1, #27
    e31a:	d112      	bne.n	e342 <z_time_slice+0x6a>
		&& !z_is_prio_higher(thread->base.prio, slice_max_prio)
    e31c:	490d      	ldr	r1, [pc, #52]	; (e354 <z_time_slice+0x7c>)
    e31e:	f993 600e 	ldrsb.w	r6, [r3, #14]
    e322:	6809      	ldr	r1, [r1, #0]
    e324:	428e      	cmp	r6, r1
    e326:	db0c      	blt.n	e342 <z_time_slice+0x6a>
		&& !z_is_idle_thread_object(thread);
    e328:	490b      	ldr	r1, [pc, #44]	; (e358 <z_time_slice+0x80>)
    e32a:	428b      	cmp	r3, r1
    e32c:	d009      	beq.n	e342 <z_time_slice+0x6a>
		if (ticks >= _current_cpu->slice_ticks) {
    e32e:	6911      	ldr	r1, [r2, #16]
    e330:	4281      	cmp	r1, r0
    e332:	dc03      	bgt.n	e33c <z_time_slice+0x64>
			move_thread_to_end_of_prio_q(_current);
    e334:	4618      	mov	r0, r3
    e336:	f7ff ff97 	bl	e268 <move_thread_to_end_of_prio_q>
    e33a:	e7dd      	b.n	e2f8 <z_time_slice+0x20>
			_current_cpu->slice_ticks -= ticks;
    e33c:	1a09      	subs	r1, r1, r0
    e33e:	6111      	str	r1, [r2, #16]
    e340:	e7dc      	b.n	e2fc <z_time_slice+0x24>
		_current_cpu->slice_ticks = 0;
    e342:	2300      	movs	r3, #0
    e344:	612b      	str	r3, [r5, #16]
    e346:	e7d9      	b.n	e2fc <z_time_slice+0x24>
    e348:	20010248 	.word	0x20010248
    e34c:	20010278 	.word	0x20010278
    e350:	20010280 	.word	0x20010280
    e354:	2001027c 	.word	0x2001027c
    e358:	20010090 	.word	0x20010090

0000e35c <z_impl_k_thread_suspend>:
{
    e35c:	b570      	push	{r4, r5, r6, lr}
    e35e:	4604      	mov	r4, r0
	z_add_timeout(&th->base.timeout, z_thread_timeout, ticks);
}

static inline int z_abort_thread_timeout(struct k_thread *thread)
{
	return z_abort_timeout(&thread->base.timeout);
    e360:	3018      	adds	r0, #24
    e362:	f001 f979 	bl	f658 <z_abort_timeout>
	__asm__ volatile(
    e366:	f04f 0320 	mov.w	r3, #32
    e36a:	f3ef 8611 	mrs	r6, BASEPRI
    e36e:	f383 8811 	msr	BASEPRI, r3
    e372:	f3bf 8f6f 	isb	sy
		if (z_is_thread_queued(thread)) {
    e376:	f994 300d 	ldrsb.w	r3, [r4, #13]
    e37a:	2b00      	cmp	r3, #0
    e37c:	da07      	bge.n	e38e <z_impl_k_thread_suspend+0x32>
			_priq_run_remove(&_kernel.ready_q.runq, thread);
    e37e:	4621      	mov	r1, r4
    e380:	480e      	ldr	r0, [pc, #56]	; (e3bc <z_impl_k_thread_suspend+0x60>)
    e382:	f7ff fecd 	bl	e120 <z_priq_dumb_remove>
	thread->base.thread_state &= ~states;
    e386:	7b63      	ldrb	r3, [r4, #13]
    e388:	f003 037f 	and.w	r3, r3, #127	; 0x7f
    e38c:	7363      	strb	r3, [r4, #13]
		update_cache(thread == _current);
    e38e:	4d0c      	ldr	r5, [pc, #48]	; (e3c0 <z_impl_k_thread_suspend+0x64>)
	thread->base.thread_state |= _THREAD_SUSPENDED;
    e390:	7b63      	ldrb	r3, [r4, #13]
    e392:	68a8      	ldr	r0, [r5, #8]
    e394:	f043 0310 	orr.w	r3, r3, #16
    e398:	7363      	strb	r3, [r4, #13]
    e39a:	1b03      	subs	r3, r0, r4
    e39c:	4258      	negs	r0, r3
    e39e:	4158      	adcs	r0, r3
    e3a0:	f7ff fed4 	bl	e14c <update_cache>
	__asm__ volatile(
    e3a4:	f386 8811 	msr	BASEPRI, r6
    e3a8:	f3bf 8f6f 	isb	sy
	if (thread == _current) {
    e3ac:	68ab      	ldr	r3, [r5, #8]
    e3ae:	42a3      	cmp	r3, r4
    e3b0:	d103      	bne.n	e3ba <z_impl_k_thread_suspend+0x5e>
}
    e3b2:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
		z_reschedule_unlocked();
    e3b6:	f001 b8ad 	b.w	f514 <z_reschedule_unlocked>
}
    e3ba:	bd70      	pop	{r4, r5, r6, pc}
    e3bc:	20010270 	.word	0x20010270
    e3c0:	20010248 	.word	0x20010248

0000e3c4 <z_thread_single_abort>:
	if (thread->fn_abort != NULL) {
    e3c4:	6e03      	ldr	r3, [r0, #96]	; 0x60
{
    e3c6:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    e3ca:	4604      	mov	r4, r0
	if (thread->fn_abort != NULL) {
    e3cc:	b103      	cbz	r3, e3d0 <z_thread_single_abort+0xc>
		thread->fn_abort();
    e3ce:	4798      	blx	r3
    e3d0:	f104 0018 	add.w	r0, r4, #24
    e3d4:	f001 f940 	bl	f658 <z_abort_timeout>
	__asm__ volatile(
    e3d8:	f04f 0320 	mov.w	r3, #32
    e3dc:	f3ef 8611 	mrs	r6, BASEPRI
    e3e0:	f383 8811 	msr	BASEPRI, r3
    e3e4:	f3bf 8f6f 	isb	sy
	return !((z_is_thread_prevented_from_running(thread)) != 0 ||
    e3e8:	7b63      	ldrb	r3, [r4, #13]
    e3ea:	06d8      	lsls	r0, r3, #27
    e3ec:	d123      	bne.n	e436 <z_thread_single_abort+0x72>
		if (z_is_thread_ready(thread)) {
    e3ee:	69a2      	ldr	r2, [r4, #24]
    e3f0:	bb0a      	cbnz	r2, e436 <z_thread_single_abort+0x72>
			if (z_is_thread_queued(thread)) {
    e3f2:	0619      	lsls	r1, r3, #24
    e3f4:	d507      	bpl.n	e406 <z_thread_single_abort+0x42>
				_priq_run_remove(&_kernel.ready_q.runq,
    e3f6:	4621      	mov	r1, r4
    e3f8:	481e      	ldr	r0, [pc, #120]	; (e474 <z_thread_single_abort+0xb0>)
    e3fa:	f7ff fe91 	bl	e120 <z_priq_dumb_remove>
	thread->base.thread_state &= ~states;
    e3fe:	7b63      	ldrb	r3, [r4, #13]
    e400:	f003 037f 	and.w	r3, r3, #127	; 0x7f
    e404:	7363      	strb	r3, [r4, #13]
			update_cache(thread == _current);
    e406:	4b1c      	ldr	r3, [pc, #112]	; (e478 <z_thread_single_abort+0xb4>)
    e408:	6898      	ldr	r0, [r3, #8]
    e40a:	1b02      	subs	r2, r0, r4
    e40c:	4250      	negs	r0, r2
    e40e:	4150      	adcs	r0, r2
    e410:	f7ff fe9c 	bl	e14c <update_cache>
			waiter->base.pended_on = NULL;
    e414:	2700      	movs	r7, #0
		thread->base.thread_state |= mask;
    e416:	7b63      	ldrb	r3, [r4, #13]
	sys_dlist_init(&w->waitq);
}

static inline struct k_thread *z_waitq_head(_wait_q_t *w)
{
	return (struct k_thread *)sys_dlist_peek_head(&w->waitq);
    e418:	f104 0830 	add.w	r8, r4, #48	; 0x30
    e41c:	f043 0308 	orr.w	r3, r3, #8
    e420:	7363      	strb	r3, [r4, #13]
	return list->head == list;
    e422:	6b25      	ldr	r5, [r4, #48]	; 0x30
	return sys_dlist_is_empty(list) ? NULL : list->head;
    e424:	4545      	cmp	r5, r8
    e426:	d000      	beq.n	e42a <z_thread_single_abort+0x66>
		while ((waiter = z_waitq_head(&thread->base.join_waiters)) !=
    e428:	b995      	cbnz	r5, e450 <z_thread_single_abort+0x8c>
	__asm__ volatile(
    e42a:	f386 8811 	msr	BASEPRI, r6
    e42e:	f3bf 8f6f 	isb	sy
}
    e432:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
			if (z_is_thread_pending(thread)) {
    e436:	079b      	lsls	r3, r3, #30
    e438:	d5ec      	bpl.n	e414 <z_thread_single_abort+0x50>
				_priq_wait_remove(&pended_on(thread)->waitq,
    e43a:	4621      	mov	r1, r4
    e43c:	68a0      	ldr	r0, [r4, #8]
    e43e:	f7ff fe6f 	bl	e120 <z_priq_dumb_remove>
	thread->base.thread_state &= ~_THREAD_PENDING;
    e442:	7b63      	ldrb	r3, [r4, #13]
    e444:	f023 0302 	bic.w	r3, r3, #2
    e448:	7363      	strb	r3, [r4, #13]
				thread->base.pended_on = NULL;
    e44a:	2300      	movs	r3, #0
    e44c:	60a3      	str	r3, [r4, #8]
    e44e:	e7e1      	b.n	e414 <z_thread_single_abort+0x50>
    e450:	f105 0018 	add.w	r0, r5, #24
    e454:	f001 f900 	bl	f658 <z_abort_timeout>
			_priq_wait_remove(&pended_on(waiter)->waitq, waiter);
    e458:	68a8      	ldr	r0, [r5, #8]
    e45a:	4629      	mov	r1, r5
    e45c:	f7ff fe60 	bl	e120 <z_priq_dumb_remove>
    e460:	7b6b      	ldrb	r3, [r5, #13]
			waiter->base.pended_on = NULL;
    e462:	60af      	str	r7, [r5, #8]
    e464:	f023 0302 	bic.w	r3, r3, #2
    e468:	736b      	strb	r3, [r5, #13]
}

static ALWAYS_INLINE void
arch_thread_return_value_set(struct k_thread *thread, unsigned int value)
{
	thread->arch.swap_return_value = value;
    e46a:	67ef      	str	r7, [r5, #124]	; 0x7c
			ready_thread(waiter);
    e46c:	4628      	mov	r0, r5
    e46e:	f7ff fead 	bl	e1cc <ready_thread>
    e472:	e7d6      	b.n	e422 <z_thread_single_abort+0x5e>
    e474:	20010270 	.word	0x20010270
    e478:	20010248 	.word	0x20010248

0000e47c <unready_thread>:
{
    e47c:	b510      	push	{r4, lr}
	if (z_is_thread_queued(thread)) {
    e47e:	f990 300d 	ldrsb.w	r3, [r0, #13]
{
    e482:	4604      	mov	r4, r0
	if (z_is_thread_queued(thread)) {
    e484:	2b00      	cmp	r3, #0
    e486:	da07      	bge.n	e498 <unready_thread+0x1c>
		_priq_run_remove(&_kernel.ready_q.runq, thread);
    e488:	4601      	mov	r1, r0
    e48a:	4808      	ldr	r0, [pc, #32]	; (e4ac <unready_thread+0x30>)
    e48c:	f7ff fe48 	bl	e120 <z_priq_dumb_remove>
	thread->base.thread_state &= ~states;
    e490:	7b63      	ldrb	r3, [r4, #13]
    e492:	f003 037f 	and.w	r3, r3, #127	; 0x7f
    e496:	7363      	strb	r3, [r4, #13]
	update_cache(thread == _current);
    e498:	4b05      	ldr	r3, [pc, #20]	; (e4b0 <unready_thread+0x34>)
    e49a:	6898      	ldr	r0, [r3, #8]
    e49c:	1b03      	subs	r3, r0, r4
    e49e:	4258      	negs	r0, r3
    e4a0:	4158      	adcs	r0, r3
}
    e4a2:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	update_cache(thread == _current);
    e4a6:	f7ff be51 	b.w	e14c <update_cache>
    e4aa:	bf00      	nop
    e4ac:	20010270 	.word	0x20010270
    e4b0:	20010248 	.word	0x20010248

0000e4b4 <pend>:
{
    e4b4:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    e4b8:	4606      	mov	r6, r0
    e4ba:	4614      	mov	r4, r2
    e4bc:	461d      	mov	r5, r3
	__asm__ volatile(
    e4be:	f04f 0320 	mov.w	r3, #32
    e4c2:	f3ef 8711 	mrs	r7, BASEPRI
    e4c6:	f383 8811 	msr	BASEPRI, r3
    e4ca:	f3bf 8f6f 	isb	sy
		add_to_waitq_locked(thread, wait_q);
    e4ce:	f001 f86e 	bl	f5ae <add_to_waitq_locked>
	__asm__ volatile(
    e4d2:	f387 8811 	msr	BASEPRI, r7
    e4d6:	f3bf 8f6f 	isb	sy
	if (!K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    e4da:	1c6b      	adds	r3, r5, #1
    e4dc:	bf08      	it	eq
    e4de:	f1b4 3fff 	cmpeq.w	r4, #4294967295	; 0xffffffff
    e4e2:	d008      	beq.n	e4f6 <pend+0x42>
	z_add_timeout(&th->base.timeout, z_thread_timeout, ticks);
    e4e4:	4622      	mov	r2, r4
    e4e6:	462b      	mov	r3, r5
    e4e8:	f106 0018 	add.w	r0, r6, #24
    e4ec:	4903      	ldr	r1, [pc, #12]	; (e4fc <pend+0x48>)
}
    e4ee:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    e4f2:	f000 b9e7 	b.w	e8c4 <z_add_timeout>
    e4f6:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    e4fa:	bf00      	nop
    e4fc:	0000f56f 	.word	0x0000f56f

0000e500 <z_pend_curr>:
{
    e500:	b510      	push	{r4, lr}
    e502:	460c      	mov	r4, r1
	pending_current = _current;
    e504:	4b06      	ldr	r3, [pc, #24]	; (e520 <z_pend_curr+0x20>)
{
    e506:	4611      	mov	r1, r2
	pending_current = _current;
    e508:	6898      	ldr	r0, [r3, #8]
    e50a:	4b06      	ldr	r3, [pc, #24]	; (e524 <z_pend_curr+0x24>)
    e50c:	6018      	str	r0, [r3, #0]
	pend(_current, wait_q, timeout);
    e50e:	e9dd 2302 	ldrd	r2, r3, [sp, #8]
    e512:	f7ff ffcf 	bl	e4b4 <pend>
    e516:	4620      	mov	r0, r4
}
    e518:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
    e51c:	f7fe bc40 	b.w	cda0 <arch_swap>
    e520:	20010248 	.word	0x20010248
    e524:	20010278 	.word	0x20010278

0000e528 <z_tick_sleep.part.21>:
	z_impl_k_yield();
}
#include <syscalls/k_yield_mrsh.c>
#endif

static int32_t z_tick_sleep(int32_t ticks)
    e528:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    e52a:	4606      	mov	r6, r0
#else
	ticks += _TICK_ALIGN;
	timeout = (k_ticks_t) ticks;
#endif

	expected_wakeup_time = ticks + z_tick_get_32();
    e52c:	f001 f8d4 	bl	f6d8 <z_tick_get_32>
    e530:	1834      	adds	r4, r6, r0
	__asm__ volatile(
    e532:	f04f 0320 	mov.w	r3, #32
    e536:	f3ef 8711 	mrs	r7, BASEPRI
    e53a:	f383 8811 	msr	BASEPRI, r3
    e53e:	f3bf 8f6f 	isb	sy

	k_spinlock_key_t key = k_spin_lock(&sched_spinlock);

#if defined(CONFIG_TIMESLICING) && defined(CONFIG_SWAP_NONATOMIC)
	pending_current = _current;
    e542:	4d0d      	ldr	r5, [pc, #52]	; (e578 <z_tick_sleep.part.21+0x50>)
    e544:	4b0d      	ldr	r3, [pc, #52]	; (e57c <z_tick_sleep.part.21+0x54>)
    e546:	68a8      	ldr	r0, [r5, #8]
    e548:	6018      	str	r0, [r3, #0]
#endif
	unready_thread(_current);
    e54a:	f7ff ff97 	bl	e47c <unready_thread>
	z_add_thread_timeout(_current, timeout);
    e54e:	68a8      	ldr	r0, [r5, #8]
    e550:	490b      	ldr	r1, [pc, #44]	; (e580 <z_tick_sleep.part.21+0x58>)
    e552:	4632      	mov	r2, r6
    e554:	17f3      	asrs	r3, r6, #31
    e556:	3018      	adds	r0, #24
    e558:	f000 f9b4 	bl	e8c4 <z_add_timeout>
	z_mark_thread_as_suspended(_current);
    e55c:	68aa      	ldr	r2, [r5, #8]
    e55e:	4638      	mov	r0, r7
	thread->base.thread_state |= _THREAD_SUSPENDED;
    e560:	7b53      	ldrb	r3, [r2, #13]
    e562:	f043 0310 	orr.w	r3, r3, #16
    e566:	7353      	strb	r3, [r2, #13]
    e568:	f7fe fc1a 	bl	cda0 <arch_swap>

	(void)z_swap(&sched_spinlock, key);

	__ASSERT(!z_is_thread_state_set(_current, _THREAD_SUSPENDED), "");

	ticks = expected_wakeup_time - z_tick_get_32();
    e56c:	f001 f8b4 	bl	f6d8 <z_tick_get_32>
    e570:	1a20      	subs	r0, r4, r0
		return ticks;
	}
#endif

	return 0;
}
    e572:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
    e576:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    e578:	20010248 	.word	0x20010248
    e57c:	20010278 	.word	0x20010278
    e580:	0000f56f 	.word	0x0000f56f

0000e584 <z_sched_init>:
	k_sched_time_slice_set(CONFIG_TIMESLICE_SIZE,
    e584:	2100      	movs	r1, #0
	list->head = (sys_dnode_t *)list;
    e586:	4b04      	ldr	r3, [pc, #16]	; (e598 <z_sched_init+0x14>)
    e588:	4608      	mov	r0, r1
    e58a:	f103 0228 	add.w	r2, r3, #40	; 0x28
	list->tail = (sys_dnode_t *)list;
    e58e:	e9c3 220a 	strd	r2, r2, [r3, #40]	; 0x28
    e592:	f7ff bd73 	b.w	e07c <k_sched_time_slice_set>
    e596:	bf00      	nop
    e598:	20010248 	.word	0x20010248

0000e59c <z_impl_k_yield>:
{
    e59c:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	if (!z_is_idle_thread_object(_current)) {
    e59e:	4c23      	ldr	r4, [pc, #140]	; (e62c <z_impl_k_yield+0x90>)
    e5a0:	4b23      	ldr	r3, [pc, #140]	; (e630 <z_impl_k_yield+0x94>)
    e5a2:	68a2      	ldr	r2, [r4, #8]
    e5a4:	429a      	cmp	r2, r3
    e5a6:	d029      	beq.n	e5fc <z_impl_k_yield+0x60>
    e5a8:	f04f 0320 	mov.w	r3, #32
    e5ac:	f3ef 8611 	mrs	r6, BASEPRI
    e5b0:	f383 8811 	msr	BASEPRI, r3
    e5b4:	f3bf 8f6f 	isb	sy
				_priq_run_remove(&_kernel.ready_q.runq,
    e5b8:	f104 0528 	add.w	r5, r4, #40	; 0x28
    e5bc:	68a1      	ldr	r1, [r4, #8]
    e5be:	4628      	mov	r0, r5
    e5c0:	f7ff fdae 	bl	e120 <z_priq_dumb_remove>
	return list->head == list;
    e5c4:	6aa2      	ldr	r2, [r4, #40]	; 0x28
			_priq_run_add(&_kernel.ready_q.runq, _current);
    e5c6:	68a3      	ldr	r3, [r4, #8]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    e5c8:	42aa      	cmp	r2, r5
    e5ca:	d028      	beq.n	e61e <z_impl_k_yield+0x82>
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    e5cc:	b33a      	cbz	r2, e61e <z_impl_k_yield+0x82>
    e5ce:	6ae0      	ldr	r0, [r4, #44]	; 0x2c
	if (thread_1->base.prio < thread_2->base.prio) {
    e5d0:	f993 100e 	ldrsb.w	r1, [r3, #14]
    e5d4:	f992 700e 	ldrsb.w	r7, [r2, #14]
    e5d8:	428f      	cmp	r7, r1
    e5da:	dd1b      	ble.n	e614 <z_impl_k_yield+0x78>
	node->prev = successor->prev;
    e5dc:	6851      	ldr	r1, [r2, #4]
	node->next = successor;
    e5de:	e9c3 2100 	strd	r2, r1, [r3]
	successor->prev->next = node;
    e5e2:	600b      	str	r3, [r1, #0]
	successor->prev = node;
    e5e4:	6053      	str	r3, [r2, #4]
	thread->base.thread_state |= states;
    e5e6:	7b5a      	ldrb	r2, [r3, #13]
			update_cache(1);
    e5e8:	2001      	movs	r0, #1
    e5ea:	f062 027f 	orn	r2, r2, #127	; 0x7f
    e5ee:	735a      	strb	r2, [r3, #13]
    e5f0:	f7ff fdac 	bl	e14c <update_cache>
	__asm__ volatile(
    e5f4:	f386 8811 	msr	BASEPRI, r6
    e5f8:	f3bf 8f6f 	isb	sy
	__asm__ volatile(
    e5fc:	f04f 0320 	mov.w	r3, #32
    e600:	f3ef 8011 	mrs	r0, BASEPRI
    e604:	f383 8811 	msr	BASEPRI, r3
    e608:	f3bf 8f6f 	isb	sy
}
    e60c:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
    e610:	f7fe bbc6 	b.w	cda0 <arch_swap>
	return (node == list->tail) ? NULL : node->next;
    e614:	4282      	cmp	r2, r0
    e616:	d002      	beq.n	e61e <z_impl_k_yield+0x82>
    e618:	6812      	ldr	r2, [r2, #0]
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    e61a:	2a00      	cmp	r2, #0
    e61c:	d1da      	bne.n	e5d4 <z_impl_k_yield+0x38>
	node->prev = list->tail;
    e61e:	6ae2      	ldr	r2, [r4, #44]	; 0x2c
	node->next = list;
    e620:	601d      	str	r5, [r3, #0]
	node->prev = list->tail;
    e622:	605a      	str	r2, [r3, #4]
	list->tail->next = node;
    e624:	6ae2      	ldr	r2, [r4, #44]	; 0x2c
    e626:	6013      	str	r3, [r2, #0]
	list->tail = node;
    e628:	62e3      	str	r3, [r4, #44]	; 0x2c
    e62a:	e7dc      	b.n	e5e6 <z_impl_k_yield+0x4a>
    e62c:	20010248 	.word	0x20010248
    e630:	20010090 	.word	0x20010090

0000e634 <z_impl_k_sleep>:
	k_ticks_t ticks;

	__ASSERT(!arch_is_in_isr(), "");
	sys_trace_void(SYS_TRACE_ID_SLEEP);

	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    e634:	3101      	adds	r1, #1
    e636:	bf08      	it	eq
    e638:	f1b0 3fff 	cmpeq.w	r0, #4294967295	; 0xffffffff
{
    e63c:	b510      	push	{r4, lr}
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    e63e:	d106      	bne.n	e64e <z_impl_k_sleep+0x1a>
		k_thread_suspend(_current);
    e640:	4b0b      	ldr	r3, [pc, #44]	; (e670 <z_impl_k_sleep+0x3c>)
    e642:	6898      	ldr	r0, [r3, #8]
	z_impl_k_thread_suspend(thread);
    e644:	f7ff fe8a 	bl	e35c <z_impl_k_thread_suspend>
		return (int32_t) K_TICKS_FOREVER;
    e648:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
#endif

	ticks = z_tick_sleep(ticks);
	sys_trace_end_call(SYS_TRACE_ID_SLEEP);
	return k_ticks_to_ms_floor64(ticks);
}
    e64c:	bd10      	pop	{r4, pc}
	ticks = z_tick_sleep(ticks);
    e64e:	4604      	mov	r4, r0
	if (ticks == 0) {
    e650:	b948      	cbnz	r0, e666 <z_impl_k_sleep+0x32>
	z_impl_k_yield();
    e652:	f7ff ffa3 	bl	e59c <z_impl_k_yield>
		} else {
			return (t * to_hz + off) / from_hz;
    e656:	f44f 707a 	mov.w	r0, #1000	; 0x3e8
    e65a:	fb84 3400 	smull	r3, r4, r4, r0
    e65e:	0bd8      	lsrs	r0, r3, #15
    e660:	ea40 4044 	orr.w	r0, r0, r4, lsl #17
	return k_ticks_to_ms_floor64(ticks);
    e664:	e7f2      	b.n	e64c <z_impl_k_sleep+0x18>
    e666:	f7ff ff5f 	bl	e528 <z_tick_sleep.part.21>
    e66a:	4604      	mov	r4, r0
    e66c:	e7f3      	b.n	e656 <z_impl_k_sleep+0x22>
    e66e:	bf00      	nop
    e670:	20010248 	.word	0x20010248

0000e674 <z_impl_k_current_get>:

#ifdef CONFIG_SMP
	arch_irq_unlock(k);
#endif
	return ret;
}
    e674:	4b01      	ldr	r3, [pc, #4]	; (e67c <z_impl_k_current_get+0x8>)
    e676:	6898      	ldr	r0, [r3, #8]
    e678:	4770      	bx	lr
    e67a:	bf00      	nop
    e67c:	20010248 	.word	0x20010248

0000e680 <z_impl_k_sem_give>:
	ARG_UNUSED(sem);
#endif
}

void z_impl_k_sem_give(struct k_sem *sem)
{
    e680:	b538      	push	{r3, r4, r5, lr}
    e682:	4604      	mov	r4, r0
    e684:	f04f 0320 	mov.w	r3, #32
    e688:	f3ef 8511 	mrs	r5, BASEPRI
    e68c:	f383 8811 	msr	BASEPRI, r3
    e690:	f3bf 8f6f 	isb	sy
	k_spinlock_key_t key = k_spin_lock(&lock);
	struct k_thread *thread;

	sys_trace_semaphore_give(sem);
	thread = z_unpend_first_thread(&sem->wait_q);
    e694:	f000 ffb3 	bl	f5fe <z_unpend_first_thread>

	if (thread != NULL) {
    e698:	b148      	cbz	r0, e6ae <z_impl_k_sem_give+0x2e>
    e69a:	2200      	movs	r2, #0
    e69c:	67c2      	str	r2, [r0, #124]	; 0x7c
		arch_thread_return_value_set(thread, 0);
		z_ready_thread(thread);
    e69e:	f000 ff56 	bl	f54e <z_ready_thread>
	} else {
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
		handle_poll_events(sem);
	}

	z_reschedule(&lock, key);
    e6a2:	4629      	mov	r1, r5
	sys_trace_end_call(SYS_TRACE_ID_SEMA_GIVE);
}
    e6a4:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
	z_reschedule(&lock, key);
    e6a8:	4804      	ldr	r0, [pc, #16]	; (e6bc <z_impl_k_sem_give+0x3c>)
    e6aa:	f7ff bd13 	b.w	e0d4 <z_reschedule>
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
    e6ae:	e9d4 3202 	ldrd	r3, r2, [r4, #8]
    e6b2:	429a      	cmp	r2, r3
    e6b4:	bf18      	it	ne
    e6b6:	3301      	addne	r3, #1
    e6b8:	60a3      	str	r3, [r4, #8]
		handle_poll_events(sem);
    e6ba:	e7f2      	b.n	e6a2 <z_impl_k_sem_give+0x22>
    e6bc:	2001028c 	.word	0x2001028c

0000e6c0 <z_impl_k_sem_take>:
}
#include <syscalls/k_sem_give_mrsh.c>
#endif

int z_impl_k_sem_take(struct k_sem *sem, k_timeout_t timeout)
{
    e6c0:	b537      	push	{r0, r1, r2, r4, r5, lr}
    e6c2:	4614      	mov	r4, r2
    e6c4:	461d      	mov	r5, r3
    e6c6:	f04f 0320 	mov.w	r3, #32
    e6ca:	f3ef 8111 	mrs	r1, BASEPRI
    e6ce:	f383 8811 	msr	BASEPRI, r3
    e6d2:	f3bf 8f6f 	isb	sy
		  K_TIMEOUT_EQ(timeout, K_NO_WAIT)), "");

	k_spinlock_key_t key = k_spin_lock(&lock);
	sys_trace_semaphore_take(sem);

	if (likely(sem->count > 0U)) {
    e6d6:	6883      	ldr	r3, [r0, #8]
    e6d8:	b143      	cbz	r3, e6ec <z_impl_k_sem_take+0x2c>
		sem->count--;
    e6da:	3b01      	subs	r3, #1
    e6dc:	6083      	str	r3, [r0, #8]
	__asm__ volatile(
    e6de:	f381 8811 	msr	BASEPRI, r1
    e6e2:	f3bf 8f6f 	isb	sy
		k_spin_unlock(&lock, key);
		ret = 0;
    e6e6:	2000      	movs	r0, #0
	ret = z_pend_curr(&lock, key, &sem->wait_q, timeout);

out:
	sys_trace_end_call(SYS_TRACE_ID_SEMA_TAKE);
	return ret;
}
    e6e8:	b003      	add	sp, #12
    e6ea:	bd30      	pop	{r4, r5, pc}
	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    e6ec:	ea54 0305 	orrs.w	r3, r4, r5
    e6f0:	d106      	bne.n	e700 <z_impl_k_sem_take+0x40>
    e6f2:	f381 8811 	msr	BASEPRI, r1
    e6f6:	f3bf 8f6f 	isb	sy
		ret = -EBUSY;
    e6fa:	f06f 000f 	mvn.w	r0, #15
		goto out;
    e6fe:	e7f3      	b.n	e6e8 <z_impl_k_sem_take+0x28>
	ret = z_pend_curr(&lock, key, &sem->wait_q, timeout);
    e700:	4602      	mov	r2, r0
    e702:	e9cd 4500 	strd	r4, r5, [sp]
    e706:	4802      	ldr	r0, [pc, #8]	; (e710 <z_impl_k_sem_take+0x50>)
    e708:	f7ff fefa 	bl	e500 <z_pend_curr>
	return ret;
    e70c:	e7ec      	b.n	e6e8 <z_impl_k_sem_take+0x28>
    e70e:	bf00      	nop
    e710:	2001028c 	.word	0x2001028c

0000e714 <z_setup_new_thread>:
char *z_setup_new_thread(struct k_thread *new_thread,
			 k_thread_stack_t *stack, size_t stack_size,
			 k_thread_entry_t entry,
			 void *p1, void *p2, void *p3,
			 int prio, uint32_t options, const char *name)
{
    e714:	b5f0      	push	{r4, r5, r6, r7, lr}
	sys_dlist_init(&w->waitq);
    e716:	f100 0530 	add.w	r5, r0, #48	; 0x30
    e71a:	b085      	sub	sp, #20
	list->tail = (sys_dnode_t *)list;
    e71c:	e9c0 550c 	strd	r5, r5, [r0, #48]	; 0x30
void z_init_thread_base(struct _thread_base *thread_base, int priority,
		       uint32_t initial_state, unsigned int options)
{
	/* k_q_node is initialized upon first insertion in a list */

	thread_base->user_options = (uint8_t)options;
    e720:	9d0e      	ldr	r5, [sp, #56]	; 0x38
{
    e722:	4604      	mov	r4, r0
	thread_base->user_options = (uint8_t)options;
    e724:	7305      	strb	r5, [r0, #12]
	thread_base->thread_state = (uint8_t)initial_state;
    e726:	2504      	movs	r5, #4
    e728:	7345      	strb	r5, [r0, #13]

	thread_base->prio = priority;
    e72a:	9d0d      	ldr	r5, [sp, #52]	; 0x34
		stack_obj_size = Z_KERNEL_STACK_SIZE_ADJUST(stack_size);
    e72c:	3207      	adds	r2, #7
	thread_base->prio = priority;
    e72e:	7385      	strb	r5, [r0, #14]

	thread_base->sched_locked = 0U;
    e730:	2500      	movs	r5, #0
		stack_obj_size = Z_KERNEL_STACK_SIZE_ADJUST(stack_size);
    e732:	f022 0207 	bic.w	r2, r2, #7
	new_thread->stack_info.size = stack_buf_size;
    e736:	e9c0 121a 	strd	r1, r2, [r0, #104]	; 0x68
	stack_ptr = (char *)stack + stack_obj_size;
    e73a:	188e      	adds	r6, r1, r2
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    e73c:	9a0c      	ldr	r2, [sp, #48]	; 0x30
	thread_base->sched_locked = 0U;
    e73e:	73c5      	strb	r5, [r0, #15]
	node->prev = NULL;
    e740:	e9c0 5506 	strd	r5, r5, [r0, #24]
	new_thread->stack_info.delta = delta;
    e744:	6705      	str	r5, [r0, #112]	; 0x70
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    e746:	9202      	str	r2, [sp, #8]
    e748:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
    e74a:	9201      	str	r2, [sp, #4]
    e74c:	9a0a      	ldr	r2, [sp, #40]	; 0x28
    e74e:	9200      	str	r2, [sp, #0]
    e750:	4632      	mov	r2, r6
    e752:	f7fe fb75 	bl	ce40 <arch_new_thread>
	if (!_current) {
    e756:	4b05      	ldr	r3, [pc, #20]	; (e76c <z_setup_new_thread+0x58>)
	new_thread->fn_abort = NULL;
    e758:	e9c4 5517 	strd	r5, r5, [r4, #92]	; 0x5c
	if (!_current) {
    e75c:	689b      	ldr	r3, [r3, #8]
    e75e:	b103      	cbz	r3, e762 <z_setup_new_thread+0x4e>
	new_thread->resource_pool = _current->resource_pool;
    e760:	6f5b      	ldr	r3, [r3, #116]	; 0x74
}
    e762:	4630      	mov	r0, r6
    e764:	6763      	str	r3, [r4, #116]	; 0x74
    e766:	b005      	add	sp, #20
    e768:	bdf0      	pop	{r4, r5, r6, r7, pc}
    e76a:	bf00      	nop
    e76c:	20010248 	.word	0x20010248

0000e770 <z_init_static_threads>:
{
    e770:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	_FOREACH_STATIC_THREAD(thread_data) {
    e774:	4e2a      	ldr	r6, [pc, #168]	; (e820 <z_init_static_threads+0xb0>)
    e776:	4d2b      	ldr	r5, [pc, #172]	; (e824 <z_init_static_threads+0xb4>)
    e778:	46b0      	mov	r8, r6
{
    e77a:	b086      	sub	sp, #24
	_FOREACH_STATIC_THREAD(thread_data) {
    e77c:	42b5      	cmp	r5, r6
    e77e:	f105 0430 	add.w	r4, r5, #48	; 0x30
    e782:	d310      	bcc.n	e7a6 <z_init_static_threads+0x36>
	k_sched_lock();
    e784:	f7ff fcb8 	bl	e0f8 <k_sched_lock>
    e788:	f44f 4900 	mov.w	r9, #32768	; 0x8000
    e78c:	f240 36e7 	movw	r6, #999	; 0x3e7
    e790:	2700      	movs	r7, #0
	_FOREACH_STATIC_THREAD(thread_data) {
    e792:	4c24      	ldr	r4, [pc, #144]	; (e824 <z_init_static_threads+0xb4>)
    e794:	f8df a090 	ldr.w	sl, [pc, #144]	; e828 <z_init_static_threads+0xb8>
    e798:	4544      	cmp	r4, r8
    e79a:	d321      	bcc.n	e7e0 <z_init_static_threads+0x70>
}
    e79c:	b006      	add	sp, #24
    e79e:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	k_sched_unlock();
    e7a2:	f7ff bcf7 	b.w	e194 <k_sched_unlock>
		z_setup_new_thread(
    e7a6:	f854 3c04 	ldr.w	r3, [r4, #-4]
    e7aa:	9305      	str	r3, [sp, #20]
    e7ac:	f854 3c10 	ldr.w	r3, [r4, #-16]
    e7b0:	9304      	str	r3, [sp, #16]
    e7b2:	f854 3c14 	ldr.w	r3, [r4, #-20]
    e7b6:	9303      	str	r3, [sp, #12]
    e7b8:	f854 3c18 	ldr.w	r3, [r4, #-24]
    e7bc:	9302      	str	r3, [sp, #8]
    e7be:	f854 3c1c 	ldr.w	r3, [r4, #-28]
    e7c2:	9301      	str	r3, [sp, #4]
    e7c4:	f854 3c20 	ldr.w	r3, [r4, #-32]
    e7c8:	9300      	str	r3, [sp, #0]
    e7ca:	e954 230a 	ldrd	r2, r3, [r4, #-40]	; 0x28
    e7ce:	e954 010c 	ldrd	r0, r1, [r4, #-48]	; 0x30
    e7d2:	f7ff ff9f 	bl	e714 <z_setup_new_thread>
		thread_data->init_thread->init_data = thread_data;
    e7d6:	f854 3c30 	ldr.w	r3, [r4, #-48]
    e7da:	65dd      	str	r5, [r3, #92]	; 0x5c
    e7dc:	4625      	mov	r5, r4
    e7de:	e7cd      	b.n	e77c <z_init_static_threads+0xc>
		if (thread_data->init_delay != K_TICKS_FOREVER) {
    e7e0:	6a63      	ldr	r3, [r4, #36]	; 0x24
    e7e2:	1c5a      	adds	r2, r3, #1
    e7e4:	d00d      	beq.n	e802 <z_init_static_threads+0x92>
    e7e6:	4630      	mov	r0, r6
    e7e8:	4639      	mov	r1, r7
					    K_MSEC(thread_data->init_delay));
    e7ea:	ea23 73e3 	bic.w	r3, r3, r3, asr #31
    e7ee:	fbc9 0103 	smlal	r0, r1, r9, r3
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
    e7f2:	42b9      	cmp	r1, r7
    e7f4:	bf08      	it	eq
    e7f6:	42b0      	cmpeq	r0, r6
			schedule_new_thread(thread_data->init_thread,
    e7f8:	6825      	ldr	r5, [r4, #0]
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
    e7fa:	d104      	bne.n	e806 <z_init_static_threads+0x96>
	z_sched_start(thread);
    e7fc:	4628      	mov	r0, r5
    e7fe:	f7ff fd15 	bl	e22c <z_sched_start>
	_FOREACH_STATIC_THREAD(thread_data) {
    e802:	3430      	adds	r4, #48	; 0x30
    e804:	e7c8      	b.n	e798 <z_init_static_threads+0x28>
    e806:	f44f 727a 	mov.w	r2, #1000	; 0x3e8
    e80a:	2300      	movs	r3, #0
    e80c:	f7fd fd16 	bl	c23c <__aeabi_uldivmod>
    e810:	4602      	mov	r2, r0
    e812:	460b      	mov	r3, r1
    e814:	f105 0018 	add.w	r0, r5, #24
    e818:	4651      	mov	r1, sl
    e81a:	f000 f853 	bl	e8c4 <z_add_timeout>
    e81e:	e7f0      	b.n	e802 <z_init_static_threads+0x92>
    e820:	20010090 	.word	0x20010090
    e824:	20010090 	.word	0x20010090
    e828:	0000f56f 	.word	0x0000f56f

0000e82c <elapsed>:
	sys_dlist_remove(&t->node);
}

static int32_t elapsed(void)
{
	return announce_remaining == 0 ? z_clock_elapsed() : 0;
    e82c:	4b03      	ldr	r3, [pc, #12]	; (e83c <elapsed+0x10>)
    e82e:	681b      	ldr	r3, [r3, #0]
    e830:	b90b      	cbnz	r3, e836 <elapsed+0xa>
    e832:	f7fe ba9b 	b.w	cd6c <z_clock_elapsed>
}
    e836:	2000      	movs	r0, #0
    e838:	4770      	bx	lr
    e83a:	bf00      	nop
    e83c:	20010284 	.word	0x20010284

0000e840 <remove_timeout>:
{
    e840:	b530      	push	{r4, r5, lr}
    e842:	6803      	ldr	r3, [r0, #0]
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    e844:	b168      	cbz	r0, e862 <remove_timeout+0x22>
    e846:	4a0a      	ldr	r2, [pc, #40]	; (e870 <remove_timeout+0x30>)
	return (node == list->tail) ? NULL : node->next;
    e848:	6852      	ldr	r2, [r2, #4]
    e84a:	4290      	cmp	r0, r2
    e84c:	d009      	beq.n	e862 <remove_timeout+0x22>
	if (next(t) != NULL) {
    e84e:	b143      	cbz	r3, e862 <remove_timeout+0x22>
		next(t)->dticks += t->dticks;
    e850:	e9d3 2104 	ldrd	r2, r1, [r3, #16]
    e854:	e9d0 4504 	ldrd	r4, r5, [r0, #16]
    e858:	1912      	adds	r2, r2, r4
    e85a:	eb45 0101 	adc.w	r1, r5, r1
    e85e:	e9c3 2104 	strd	r2, r1, [r3, #16]
	node->prev->next = node->next;
    e862:	6842      	ldr	r2, [r0, #4]
    e864:	6013      	str	r3, [r2, #0]
	node->next->prev = node->prev;
    e866:	605a      	str	r2, [r3, #4]
	node->next = NULL;
    e868:	2300      	movs	r3, #0
	node->prev = NULL;
    e86a:	e9c0 3300 	strd	r3, r3, [r0]
}
    e86e:	bd30      	pop	{r4, r5, pc}
    e870:	20010034 	.word	0x20010034

0000e874 <next_timeout>:

static int32_t next_timeout(void)
{
    e874:	b538      	push	{r3, r4, r5, lr}
	return list->head == list;
    e876:	4b11      	ldr	r3, [pc, #68]	; (e8bc <next_timeout+0x48>)
    e878:	681c      	ldr	r4, [r3, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    e87a:	429c      	cmp	r4, r3
    e87c:	bf08      	it	eq
    e87e:	2400      	moveq	r4, #0
	struct _timeout *to = first();
	int32_t ticks_elapsed = elapsed();
    e880:	f7ff ffd4 	bl	e82c <elapsed>
	int32_t ret = to == NULL ? MAX_WAIT
    e884:	b1b4      	cbz	r4, e8b4 <next_timeout+0x40>
		: MIN(MAX_WAIT, MAX(0, to->dticks - ticks_elapsed));
    e886:	e9d4 2304 	ldrd	r2, r3, [r4, #16]
    e88a:	1a14      	subs	r4, r2, r0
    e88c:	eb63 75e0 	sbc.w	r5, r3, r0, asr #31
	int32_t ret = to == NULL ? MAX_WAIT
    e890:	f1b4 4f00 	cmp.w	r4, #2147483648	; 0x80000000
    e894:	f175 0300 	sbcs.w	r3, r5, #0
    e898:	da0c      	bge.n	e8b4 <next_timeout+0x40>
		: MIN(MAX_WAIT, MAX(0, to->dticks - ticks_elapsed));
    e89a:	2c00      	cmp	r4, #0
    e89c:	f175 0300 	sbcs.w	r3, r5, #0
    e8a0:	4620      	mov	r0, r4
    e8a2:	da00      	bge.n	e8a6 <next_timeout+0x32>
    e8a4:	2000      	movs	r0, #0

#ifdef CONFIG_TIMESLICING
	if (_current_cpu->slice_ticks && _current_cpu->slice_ticks < ret) {
    e8a6:	4b06      	ldr	r3, [pc, #24]	; (e8c0 <next_timeout+0x4c>)
    e8a8:	691b      	ldr	r3, [r3, #16]
    e8aa:	b113      	cbz	r3, e8b2 <next_timeout+0x3e>
    e8ac:	4298      	cmp	r0, r3
    e8ae:	bfa8      	it	ge
    e8b0:	4618      	movge	r0, r3
		ret = _current_cpu->slice_ticks;
	}
#endif
	return ret;
}
    e8b2:	bd38      	pop	{r3, r4, r5, pc}
	int32_t ret = to == NULL ? MAX_WAIT
    e8b4:	f06f 4000 	mvn.w	r0, #2147483648	; 0x80000000
    e8b8:	e7f5      	b.n	e8a6 <next_timeout+0x32>
    e8ba:	bf00      	nop
    e8bc:	20010034 	.word	0x20010034
    e8c0:	20010248 	.word	0x20010248

0000e8c4 <z_add_timeout>:

void z_add_timeout(struct _timeout *to, _timeout_func_t fn,
		   k_timeout_t timeout)
{
    e8c4:	e92d 4ff7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, sl, fp, lr}
    e8c8:	9101      	str	r1, [sp, #4]
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    e8ca:	1c59      	adds	r1, r3, #1
    e8cc:	bf08      	it	eq
    e8ce:	f1b2 3fff 	cmpeq.w	r2, #4294967295	; 0xffffffff
{
    e8d2:	4682      	mov	sl, r0
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    e8d4:	d06e      	beq.n	e9b4 <z_add_timeout+0xf0>
	}

#ifdef CONFIG_LEGACY_TIMEOUT_API
	k_ticks_t ticks = timeout;
#else
	k_ticks_t ticks = timeout.ticks + 1;
    e8d6:	1c54      	adds	r4, r2, #1
    e8d8:	f143 0500 	adc.w	r5, r3, #0

	if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) && Z_TICK_ABS(ticks) >= 0) {
    e8dc:	f06f 0301 	mvn.w	r3, #1
    e8e0:	f04f 3bff 	mov.w	fp, #4294967295	; 0xffffffff
    e8e4:	ebb3 0804 	subs.w	r8, r3, r4
    e8e8:	eb6b 0905 	sbc.w	r9, fp, r5
    e8ec:	f1b8 0f00 	cmp.w	r8, #0
    e8f0:	f179 0300 	sbcs.w	r3, r9, #0
    e8f4:	db0f      	blt.n	e916 <z_add_timeout+0x52>
		ticks = Z_TICK_ABS(ticks) - (curr_tick + elapsed());
    e8f6:	f7ff ff99 	bl	e82c <elapsed>
    e8fa:	f06f 0301 	mvn.w	r3, #1
    e8fe:	4a34      	ldr	r2, [pc, #208]	; (e9d0 <z_add_timeout+0x10c>)
    e900:	e9d2 1c00 	ldrd	r1, ip, [r2]
    e904:	1a5b      	subs	r3, r3, r1
    e906:	eb6b 020c 	sbc.w	r2, fp, ip
    e90a:	1b1e      	subs	r6, r3, r4
    e90c:	eb62 0705 	sbc.w	r7, r2, r5
    e910:	1a34      	subs	r4, r6, r0
    e912:	eb67 75e0 	sbc.w	r5, r7, r0, asr #31
	}
#endif

	__ASSERT(!sys_dnode_is_linked(&to->node), "");
	to->fn = fn;
    e916:	9b01      	ldr	r3, [sp, #4]
    e918:	f8ca 3008 	str.w	r3, [sl, #8]
	__asm__ volatile(
    e91c:	f04f 0320 	mov.w	r3, #32
    e920:	f3ef 8611 	mrs	r6, BASEPRI
    e924:	f383 8811 	msr	BASEPRI, r3
    e928:	f3bf 8f6f 	isb	sy
	ticks = MAX(1, ticks);

	LOCKED(&timeout_lock) {
		struct _timeout *t;

		to->dticks = ticks + elapsed();
    e92c:	f7ff ff7e 	bl	e82c <elapsed>
	ticks = MAX(1, ticks);
    e930:	2c01      	cmp	r4, #1
    e932:	f175 0300 	sbcs.w	r3, r5, #0
    e936:	4621      	mov	r1, r4
    e938:	bfb8      	it	lt
    e93a:	2101      	movlt	r1, #1
    e93c:	462a      	mov	r2, r5
    e93e:	bfb8      	it	lt
    e940:	2200      	movlt	r2, #0
	return list->head == list;
    e942:	4b24      	ldr	r3, [pc, #144]	; (e9d4 <z_add_timeout+0x110>)
		to->dticks = ticks + elapsed();
    e944:	180c      	adds	r4, r1, r0
    e946:	eb42 75e0 	adc.w	r5, r2, r0, asr #31
    e94a:	681a      	ldr	r2, [r3, #0]
    e94c:	e9ca 4504 	strd	r4, r5, [sl, #16]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    e950:	429a      	cmp	r2, r3
    e952:	d001      	beq.n	e958 <z_add_timeout+0x94>
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    e954:	685f      	ldr	r7, [r3, #4]
		for (t = first(); t != NULL; t = next(t)) {
    e956:	b952      	cbnz	r2, e96e <z_add_timeout+0xaa>
	node->prev = list->tail;
    e958:	685a      	ldr	r2, [r3, #4]
	node->next = list;
    e95a:	f8ca 3000 	str.w	r3, [sl]
	node->prev = list->tail;
    e95e:	f8ca 2004 	str.w	r2, [sl, #4]
	list->tail->next = node;
    e962:	685a      	ldr	r2, [r3, #4]
    e964:	f8c2 a000 	str.w	sl, [r2]
	list->tail = node;
    e968:	f8c3 a004 	str.w	sl, [r3, #4]
    e96c:	e014      	b.n	e998 <z_add_timeout+0xd4>
			if (t->dticks > to->dticks) {
    e96e:	e9d2 8904 	ldrd	r8, r9, [r2, #16]
    e972:	e9da 4504 	ldrd	r4, r5, [sl, #16]
    e976:	4544      	cmp	r4, r8
    e978:	eb75 0109 	sbcs.w	r1, r5, r9
    e97c:	da1d      	bge.n	e9ba <z_add_timeout+0xf6>
				t->dticks -= to->dticks;
    e97e:	ebb8 0004 	subs.w	r0, r8, r4
    e982:	eb69 0105 	sbc.w	r1, r9, r5
    e986:	e9c2 0104 	strd	r0, r1, [r2, #16]
	node->prev = successor->prev;
    e98a:	6851      	ldr	r1, [r2, #4]
	node->next = successor;
    e98c:	e9ca 2100 	strd	r2, r1, [sl]
	successor->prev->next = node;
    e990:	f8c1 a000 	str.w	sl, [r1]
	successor->prev = node;
    e994:	f8c2 a004 	str.w	sl, [r2, #4]
	return list->head == list;
    e998:	681a      	ldr	r2, [r3, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    e99a:	429a      	cmp	r2, r3
    e99c:	d006      	beq.n	e9ac <z_add_timeout+0xe8>

		if (t == NULL) {
			sys_dlist_append(&timeout_list, &to->node);
		}

		if (to == first()) {
    e99e:	4592      	cmp	sl, r2
    e9a0:	d104      	bne.n	e9ac <z_add_timeout+0xe8>
			z_clock_set_timeout(next_timeout(), false);
    e9a2:	f7ff ff67 	bl	e874 <next_timeout>
    e9a6:	2100      	movs	r1, #0
    e9a8:	f7fe f97a 	bl	cca0 <z_clock_set_timeout>
	__asm__ volatile(
    e9ac:	f386 8811 	msr	BASEPRI, r6
    e9b0:	f3bf 8f6f 	isb	sy
		}
	}
}
    e9b4:	b003      	add	sp, #12
    e9b6:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
			to->dticks -= t->dticks;
    e9ba:	ebb4 0008 	subs.w	r0, r4, r8
    e9be:	eb65 0109 	sbc.w	r1, r5, r9
	return (node == list->tail) ? NULL : node->next;
    e9c2:	42ba      	cmp	r2, r7
    e9c4:	e9ca 0104 	strd	r0, r1, [sl, #16]
    e9c8:	d0c6      	beq.n	e958 <z_add_timeout+0x94>
    e9ca:	6812      	ldr	r2, [r2, #0]
    e9cc:	e7c3      	b.n	e956 <z_add_timeout+0x92>
    e9ce:	bf00      	nop
    e9d0:	20010190 	.word	0x20010190
    e9d4:	20010034 	.word	0x20010034

0000e9d8 <z_clock_announce>:
		}
	}
}

void z_clock_announce(int32_t ticks)
{
    e9d8:	e92d 4ff7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, sl, fp, lr}
    e9dc:	4604      	mov	r4, r0
#ifdef CONFIG_TIMESLICING
	z_time_slice(ticks);
    e9de:	f7ff fc7b 	bl	e2d8 <z_time_slice>
	__asm__ volatile(
    e9e2:	f04f 0320 	mov.w	r3, #32
    e9e6:	f3ef 8511 	mrs	r5, BASEPRI
    e9ea:	f383 8811 	msr	BASEPRI, r3
    e9ee:	f3bf 8f6f 	isb	sy
#endif

	k_spinlock_key_t key = k_spin_lock(&timeout_lock);

	announce_remaining = ticks;
    e9f2:	4b2c      	ldr	r3, [pc, #176]	; (eaa4 <CONFIG_SYS_PM_MIN_RESIDENCY_DEEP_SLEEP_1+0x44>)
    e9f4:	f8df 90b0 	ldr.w	r9, [pc, #176]	; eaa8 <CONFIG_SYS_PM_MIN_RESIDENCY_DEEP_SLEEP_1+0x48>
    e9f8:	4698      	mov	r8, r3
    e9fa:	46cb      	mov	fp, r9
	return list->head == list;
    e9fc:	f8df a0ac 	ldr.w	sl, [pc, #172]	; eaac <CONFIG_SYS_PM_MIN_RESIDENCY_DEEP_SLEEP_1+0x4c>
    ea00:	601c      	str	r4, [r3, #0]
    ea02:	f8d8 c000 	ldr.w	ip, [r8]
    ea06:	f8da 4000 	ldr.w	r4, [sl]
    ea0a:	4666      	mov	r6, ip
    ea0c:	e9d9 2300 	ldrd	r2, r3, [r9]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    ea10:	4554      	cmp	r4, sl
    ea12:	e9cd 2300 	strd	r2, r3, [sp]
    ea16:	ea4f 77e6 	mov.w	r7, r6, asr #31
    ea1a:	d00c      	beq.n	ea36 <z_clock_announce+0x5e>

	while (first() != NULL && first()->dticks <= announce_remaining) {
    ea1c:	b15c      	cbz	r4, ea36 <z_clock_announce+0x5e>
    ea1e:	e9d4 1204 	ldrd	r1, r2, [r4, #16]
    ea22:	458c      	cmp	ip, r1
    ea24:	eb77 0302 	sbcs.w	r3, r7, r2
    ea28:	da1b      	bge.n	ea62 <CONFIG_SYS_PM_MIN_RESIDENCY_DEEP_SLEEP_1+0x2>
		t->fn(t);
		key = k_spin_lock(&timeout_lock);
	}

	if (first() != NULL) {
		first()->dticks -= announce_remaining;
    ea2a:	ebb1 000c 	subs.w	r0, r1, ip
    ea2e:	eb62 0107 	sbc.w	r1, r2, r7
    ea32:	e9c4 0104 	strd	r0, r1, [r4, #16]
	}

	curr_tick += announce_remaining;
	announce_remaining = 0;
    ea36:	2400      	movs	r4, #0
	curr_tick += announce_remaining;
    ea38:	9b00      	ldr	r3, [sp, #0]
	announce_remaining = 0;
    ea3a:	f8c8 4000 	str.w	r4, [r8]
	curr_tick += announce_remaining;
    ea3e:	18f2      	adds	r2, r6, r3
    ea40:	9b01      	ldr	r3, [sp, #4]
    ea42:	eb47 0303 	adc.w	r3, r7, r3
    ea46:	e9cb 2300 	strd	r2, r3, [fp]

	z_clock_set_timeout(next_timeout(), false);
    ea4a:	f7ff ff13 	bl	e874 <next_timeout>
    ea4e:	4621      	mov	r1, r4
    ea50:	f7fe f926 	bl	cca0 <z_clock_set_timeout>
	__asm__ volatile(
    ea54:	f385 8811 	msr	BASEPRI, r5
    ea58:	f3bf 8f6f 	isb	sy

	k_spin_unlock(&timeout_lock, key);
}
    ea5c:	b003      	add	sp, #12
    ea5e:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
		t->dticks = 0;
    ea62:	2200      	movs	r2, #0
		curr_tick += dt;
    ea64:	e9dd 6700 	ldrd	r6, r7, [sp]
		t->dticks = 0;
    ea68:	2300      	movs	r3, #0
		curr_tick += dt;
    ea6a:	1876      	adds	r6, r6, r1
		announce_remaining -= dt;
    ea6c:	ebac 0001 	sub.w	r0, ip, r1
		curr_tick += dt;
    ea70:	eb47 77e1 	adc.w	r7, r7, r1, asr #31
		announce_remaining -= dt;
    ea74:	f8c8 0000 	str.w	r0, [r8]
		t->dticks = 0;
    ea78:	e9c4 2304 	strd	r2, r3, [r4, #16]
		remove_timeout(t);
    ea7c:	4620      	mov	r0, r4
		curr_tick += dt;
    ea7e:	e9c9 6700 	strd	r6, r7, [r9]
		remove_timeout(t);
    ea82:	f7ff fedd 	bl	e840 <remove_timeout>
    ea86:	f385 8811 	msr	BASEPRI, r5
    ea8a:	f3bf 8f6f 	isb	sy
		t->fn(t);
    ea8e:	68a3      	ldr	r3, [r4, #8]
    ea90:	4798      	blx	r3
	__asm__ volatile(
    ea92:	f04f 0320 	mov.w	r3, #32
    ea96:	f3ef 8511 	mrs	r5, BASEPRI
    ea9a:	f383 8811 	msr	BASEPRI, r3
    ea9e:	f3bf 8f6f 	isb	sy
#endif

#ifdef CONFIG_SPIN_VALIDATE
	z_spin_lock_set_owner(l);
#endif
	return k;
    eaa2:	e7ae      	b.n	ea02 <z_clock_announce+0x2a>
    eaa4:	20010284 	.word	0x20010284
    eaa8:	20010190 	.word	0x20010190
    eaac:	20010034 	.word	0x20010034

0000eab0 <z_tick_get>:

int64_t z_tick_get(void)
{
    eab0:	e92d 4818 	stmdb	sp!, {r3, r4, fp, lr}
    eab4:	f04f 0320 	mov.w	r3, #32
    eab8:	f3ef 8411 	mrs	r4, BASEPRI
    eabc:	f383 8811 	msr	BASEPRI, r3
    eac0:	f3bf 8f6f 	isb	sy
	uint64_t t = 0U;

	LOCKED(&timeout_lock) {
		t = curr_tick + z_clock_elapsed();
    eac4:	f7fe f952 	bl	cd6c <z_clock_elapsed>
    eac8:	4b07      	ldr	r3, [pc, #28]	; (eae8 <z_tick_get+0x38>)
    eaca:	e9d3 2300 	ldrd	r2, r3, [r3]
    eace:	eb12 0b00 	adds.w	fp, r2, r0
    ead2:	f143 0c00 	adc.w	ip, r3, #0
    ead6:	4658      	mov	r0, fp
    ead8:	4661      	mov	r1, ip
	__asm__ volatile(
    eada:	f384 8811 	msr	BASEPRI, r4
    eade:	f3bf 8f6f 	isb	sy
	}
	return t;
}
    eae2:	e8bd 8818 	ldmia.w	sp!, {r3, r4, fp, pc}
    eae6:	bf00      	nop
    eae8:	20010190 	.word	0x20010190

0000eaec <statics_init>:
	z_waitq_init(&h->wait_q);
	sys_heap_init(&h->heap, mem, bytes);
}

static int statics_init(const struct device *unused)
{
    eaec:	b538      	push	{r3, r4, r5, lr}
	ARG_UNUSED(unused);
	Z_STRUCT_SECTION_FOREACH(k_heap, h) {
    eaee:	4c06      	ldr	r4, [pc, #24]	; (eb08 <statics_init+0x1c>)
    eaf0:	4d06      	ldr	r5, [pc, #24]	; (eb0c <statics_init+0x20>)
    eaf2:	42ac      	cmp	r4, r5
    eaf4:	d301      	bcc.n	eafa <statics_init+0xe>
		k_heap_init(h, h->heap.init_mem, h->heap.init_bytes);
	}
	return 0;
}
    eaf6:	2000      	movs	r0, #0
    eaf8:	bd38      	pop	{r3, r4, r5, pc}
		k_heap_init(h, h->heap.init_mem, h->heap.init_bytes);
    eafa:	e9d4 1201 	ldrd	r1, r2, [r4, #4]
    eafe:	4620      	mov	r0, r4
    eb00:	f000 fdee 	bl	f6e0 <k_heap_init>
	Z_STRUCT_SECTION_FOREACH(k_heap, h) {
    eb04:	3414      	adds	r4, #20
    eb06:	e7f4      	b.n	eaf2 <statics_init+0x6>
    eb08:	20010090 	.word	0x20010090
    eb0c:	20010090 	.word	0x20010090

0000eb10 <sys_notify_validate>:

int sys_notify_validate(struct sys_notify *notify)
{
	int rv = 0;

	if (notify == NULL) {
    eb10:	b160      	cbz	r0, eb2c <sys_notify_validate+0x1c>
	uint32_t method = notify->flags >> SYS_NOTIFY_METHOD_POS;
    eb12:	6843      	ldr	r3, [r0, #4]
	return method & SYS_NOTIFY_METHOD_MASK;
    eb14:	f003 0303 	and.w	r3, r3, #3
		return -EINVAL;
	}

	/* Validate configuration based on mode */
	switch (sys_notify_get_method(notify)) {
    eb18:	2b01      	cmp	r3, #1
    eb1a:	d003      	beq.n	eb24 <sys_notify_validate+0x14>
    eb1c:	2b03      	cmp	r3, #3
    eb1e:	d105      	bne.n	eb2c <sys_notify_validate+0x1c>
	case SYS_NOTIFY_METHOD_SPINWAIT:
		break;
	case SYS_NOTIFY_METHOD_CALLBACK:
		if (notify->method.callback == NULL) {
    eb20:	6803      	ldr	r3, [r0, #0]
    eb22:	b11b      	cbz	r3, eb2c <sys_notify_validate+0x1c>
		break;
	}

	/* Clear the result here instead of in all callers. */
	if (rv == 0) {
		notify->result = 0;
    eb24:	2300      	movs	r3, #0
    eb26:	6083      	str	r3, [r0, #8]
    eb28:	4618      	mov	r0, r3
    eb2a:	4770      	bx	lr
		return -EINVAL;
    eb2c:	f06f 0015 	mvn.w	r0, #21
	}

	return rv;
}
    eb30:	4770      	bx	lr

0000eb32 <sys_notify_finalize>:
	uint32_t method = notify->flags >> SYS_NOTIFY_METHOD_POS;
    eb32:	6842      	ldr	r2, [r0, #4]

sys_notify_generic_callback sys_notify_finalize(struct sys_notify *notify,
						    int res)
{
    eb34:	4603      	mov	r3, r0
	return method & SYS_NOTIFY_METHOD_MASK;
    eb36:	f002 0203 	and.w	r2, r2, #3

	/* Store the result and capture secondary notification
	 * information.
	 */
	notify->result = res;
	switch (method) {
    eb3a:	2a03      	cmp	r2, #3
    eb3c:	f04f 0200 	mov.w	r2, #0
	notify->result = res;
    eb40:	6081      	str	r1, [r0, #8]
	case SYS_NOTIFY_METHOD_SPINWAIT:
		break;
	case SYS_NOTIFY_METHOD_CALLBACK:
		rv = notify->method.callback;
    eb42:	bf0c      	ite	eq
    eb44:	6800      	ldreq	r0, [r0, #0]
	sys_notify_generic_callback rv = 0;
    eb46:	4610      	movne	r0, r2
	/* Mark completion by clearing the flags field to the
	 * completed state, releasing any spin-waiters, then complete
	 * secondary notification.
	 */
	compiler_barrier();
	notify->flags = SYS_NOTIFY_METHOD_COMPLETED;
    eb48:	605a      	str	r2, [r3, #4]
	if (IS_ENABLED(CONFIG_POLL) && (sig != NULL)) {
		k_poll_signal_raise(sig, res);
	}

	return rv;
}
    eb4a:	4770      	bx	lr

0000eb4c <arch_printk_char_out>:
}
    eb4c:	2000      	movs	r0, #0
    eb4e:	4770      	bx	lr

0000eb50 <z_vprintk>:
{
    eb50:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
	char length_mod = 0;
    eb54:	2500      	movs	r5, #0
{
    eb56:	4606      	mov	r6, r0
    eb58:	460f      	mov	r7, r1
    eb5a:	461c      	mov	r4, r3
	int min_width = -1;
    eb5c:	f04f 39ff 	mov.w	r9, #4294967295	; 0xffffffff
	enum pad_type padding = PAD_NONE;
    eb60:	46a8      	mov	r8, r5
{
    eb62:	b087      	sub	sp, #28
    eb64:	f102 3bff 	add.w	fp, r2, #4294967295	; 0xffffffff
			might_format = 0;
    eb68:	f04f 0a00 	mov.w	sl, #0
					break;
    eb6c:	e007      	b.n	eb7e <z_vprintk+0x2e>
		if (!might_format) {
    eb6e:	f1ba 0f00 	cmp.w	sl, #0
    eb72:	d10b      	bne.n	eb8c <z_vprintk+0x3c>
			if (*fmt != '%') {
    eb74:	2825      	cmp	r0, #37	; 0x25
    eb76:	f000 80f0 	beq.w	ed5a <z_vprintk+0x20a>
				out((int)*fmt, ctx);
    eb7a:	4639      	mov	r1, r7
    eb7c:	47b0      	blx	r6
	while (*fmt) {
    eb7e:	f81b 0f01 	ldrb.w	r0, [fp, #1]!
    eb82:	2800      	cmp	r0, #0
    eb84:	d1f3      	bne.n	eb6e <z_vprintk+0x1e>
}
    eb86:	b007      	add	sp, #28
    eb88:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
			switch (*fmt) {
    eb8c:	2864      	cmp	r0, #100	; 0x64
    eb8e:	d06c      	beq.n	ec6a <z_vprintk+0x11a>
    eb90:	d81a      	bhi.n	ebc8 <z_vprintk+0x78>
    eb92:	2839      	cmp	r0, #57	; 0x39
    eb94:	d80a      	bhi.n	ebac <z_vprintk+0x5c>
    eb96:	2831      	cmp	r0, #49	; 0x31
    eb98:	d25e      	bcs.n	ec58 <z_vprintk+0x108>
    eb9a:	282d      	cmp	r0, #45	; 0x2d
    eb9c:	f000 80e4 	beq.w	ed68 <z_vprintk+0x218>
    eba0:	2830      	cmp	r0, #48	; 0x30
    eba2:	d04a      	beq.n	ec3a <z_vprintk+0xea>
    eba4:	2825      	cmp	r0, #37	; 0x25
    eba6:	d107      	bne.n	ebb8 <z_vprintk+0x68>
				out((int)'%', ctx);
    eba8:	4639      	mov	r1, r7
    ebaa:	e00b      	b.n	ebc4 <z_vprintk+0x74>
			switch (*fmt) {
    ebac:	2858      	cmp	r0, #88	; 0x58
    ebae:	f000 80a5 	beq.w	ecfc <z_vprintk+0x1ac>
    ebb2:	2863      	cmp	r0, #99	; 0x63
    ebb4:	f000 80cd 	beq.w	ed52 <z_vprintk+0x202>
					out((int)'%', ctx);
    ebb8:	4639      	mov	r1, r7
    ebba:	2025      	movs	r0, #37	; 0x25
    ebbc:	47b0      	blx	r6
					out((int)*fmt, ctx);
    ebbe:	4639      	mov	r1, r7
    ebc0:	f89b 0000 	ldrb.w	r0, [fp]
    ebc4:	47b0      	blx	r6
    ebc6:	e7cf      	b.n	eb68 <z_vprintk+0x18>
			switch (*fmt) {
    ebc8:	2870      	cmp	r0, #112	; 0x70
    ebca:	f000 808d 	beq.w	ece8 <z_vprintk+0x198>
    ebce:	d80d      	bhi.n	ebec <z_vprintk+0x9c>
    ebd0:	2869      	cmp	r0, #105	; 0x69
    ebd2:	d04a      	beq.n	ec6a <z_vprintk+0x11a>
    ebd4:	286c      	cmp	r0, #108	; 0x6c
    ebd6:	d103      	bne.n	ebe0 <z_vprintk+0x90>
				} else if (*fmt == 'l' && length_mod == 'l') {
    ebd8:	2d6c      	cmp	r5, #108	; 0x6c
    ebda:	d12a      	bne.n	ec32 <z_vprintk+0xe2>
					length_mod = 'L';
    ebdc:	254c      	movs	r5, #76	; 0x4c
    ebde:	e7ce      	b.n	eb7e <z_vprintk+0x2e>
			switch (*fmt) {
    ebe0:	2868      	cmp	r0, #104	; 0x68
    ebe2:	d1e9      	bne.n	ebb8 <z_vprintk+0x68>
				if (*fmt == 'h' && length_mod == 'h') {
    ebe4:	2d68      	cmp	r5, #104	; 0x68
    ebe6:	d124      	bne.n	ec32 <z_vprintk+0xe2>
					length_mod = 'H';
    ebe8:	2548      	movs	r5, #72	; 0x48
    ebea:	e7c8      	b.n	eb7e <z_vprintk+0x2e>
			switch (*fmt) {
    ebec:	2875      	cmp	r0, #117	; 0x75
    ebee:	d03c      	beq.n	ec6a <z_vprintk+0x11a>
    ebf0:	d81b      	bhi.n	ec2a <z_vprintk+0xda>
    ebf2:	2873      	cmp	r0, #115	; 0x73
    ebf4:	d1e0      	bne.n	ebb8 <z_vprintk+0x68>
				char *s = va_arg(ap, char *);
    ebf6:	f854 3b04 	ldr.w	r3, [r4], #4
				while (*s) {
    ebfa:	469a      	mov	sl, r3
    ebfc:	4652      	mov	r2, sl
    ebfe:	f81a 0b01 	ldrb.w	r0, [sl], #1
    ec02:	2800      	cmp	r0, #0
    ec04:	f040 80a0 	bne.w	ed48 <z_vprintk+0x1f8>
				if (padding == PAD_SPACE_AFTER) {
    ec08:	f1b8 0f03 	cmp.w	r8, #3
    ec0c:	f040 80b2 	bne.w	ed74 <z_vprintk+0x224>
					int remaining = min_width - (s - start);
    ec10:	eba2 0a03 	sub.w	sl, r2, r3
    ec14:	eba9 0a0a 	sub.w	sl, r9, sl
					while (remaining-- > 0) {
    ec18:	f1ba 0f00 	cmp.w	sl, #0
    ec1c:	dda4      	ble.n	eb68 <z_vprintk+0x18>
						out(' ', ctx);
    ec1e:	4639      	mov	r1, r7
    ec20:	2020      	movs	r0, #32
    ec22:	47b0      	blx	r6
    ec24:	f10a 3aff 	add.w	sl, sl, #4294967295	; 0xffffffff
    ec28:	e7f6      	b.n	ec18 <z_vprintk+0xc8>
			switch (*fmt) {
    ec2a:	2878      	cmp	r0, #120	; 0x78
    ec2c:	d066      	beq.n	ecfc <z_vprintk+0x1ac>
    ec2e:	287a      	cmp	r0, #122	; 0x7a
    ec30:	d1c2      	bne.n	ebb8 <z_vprintk+0x68>
				} else if (length_mod == 0) {
    ec32:	2d00      	cmp	r5, #0
    ec34:	d1c0      	bne.n	ebb8 <z_vprintk+0x68>
    ec36:	4605      	mov	r5, r0
    ec38:	e7a1      	b.n	eb7e <z_vprintk+0x2e>
				if (min_width < 0 && padding == PAD_NONE) {
    ec3a:	f1b9 0f00 	cmp.w	r9, #0
    ec3e:	da0e      	bge.n	ec5e <z_vprintk+0x10e>
    ec40:	f1b8 0f00 	cmp.w	r8, #0
    ec44:	f000 8093 	beq.w	ed6e <z_vprintk+0x21e>
					min_width = *fmt - '0';
    ec48:	f1a0 0930 	sub.w	r9, r0, #48	; 0x30
					padding = PAD_SPACE_BEFORE;
    ec4c:	f1b8 0f00 	cmp.w	r8, #0
    ec50:	bf08      	it	eq
    ec52:	f04f 0802 	moveq.w	r8, #2
    ec56:	e792      	b.n	eb7e <z_vprintk+0x2e>
				if (min_width < 0) {
    ec58:	f1b9 0f00 	cmp.w	r9, #0
    ec5c:	dbf4      	blt.n	ec48 <z_vprintk+0xf8>
					min_width = 10 * min_width + *fmt - '0';
    ec5e:	230a      	movs	r3, #10
    ec60:	fb03 0909 	mla	r9, r3, r9, r0
    ec64:	f1a9 0930 	sub.w	r9, r9, #48	; 0x30
    ec68:	e7f0      	b.n	ec4c <z_vprintk+0xfc>
				if (length_mod == 'z') {
    ec6a:	2d7a      	cmp	r5, #122	; 0x7a
    ec6c:	d106      	bne.n	ec7c <z_vprintk+0x12c>
					d = va_arg(ap, long);
    ec6e:	46a2      	mov	sl, r4
    ec70:	f85a 2b04 	ldr.w	r2, [sl], #4
    ec74:	17d3      	asrs	r3, r2, #31
				if (*fmt != 'u' && negative(d)) {
    ec76:	2875      	cmp	r0, #117	; 0x75
    ec78:	d125      	bne.n	ecc6 <z_vprintk+0x176>
    ec7a:	e00f      	b.n	ec9c <z_vprintk+0x14c>
				} else if (length_mod == 'l') {
    ec7c:	2d6c      	cmp	r5, #108	; 0x6c
    ec7e:	d0f6      	beq.n	ec6e <z_vprintk+0x11e>
				} else if (length_mod == 'L') {
    ec80:	2d4c      	cmp	r5, #76	; 0x4c
    ec82:	d105      	bne.n	ec90 <z_vprintk+0x140>
					long long lld = va_arg(ap, long long);
    ec84:	3407      	adds	r4, #7
    ec86:	f024 0a07 	bic.w	sl, r4, #7
					d = (printk_val_t) lld;
    ec8a:	e8fa 2302 	ldrd	r2, r3, [sl], #8
    ec8e:	e7f2      	b.n	ec76 <z_vprintk+0x126>
				} else if (*fmt == 'u') {
    ec90:	2875      	cmp	r0, #117	; 0x75
    ec92:	f104 0a04 	add.w	sl, r4, #4
					d = va_arg(ap, unsigned int);
    ec96:	6822      	ldr	r2, [r4, #0]
				} else if (*fmt == 'u') {
    ec98:	d114      	bne.n	ecc4 <z_vprintk+0x174>
					d = va_arg(ap, unsigned int);
    ec9a:	2300      	movs	r3, #0
	print_digits(out, ctx, num, 10, padding != PAD_SPACE_AFTER,
    ec9c:	f1b8 0103 	subs.w	r1, r8, #3
    eca0:	bf18      	it	ne
    eca2:	2101      	movne	r1, #1
    eca4:	f1b8 0f01 	cmp.w	r8, #1
    eca8:	bf0c      	ite	eq
    ecaa:	2030      	moveq	r0, #48	; 0x30
    ecac:	2020      	movne	r0, #32
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
    ecae:	9101      	str	r1, [sp, #4]
    ecb0:	210a      	movs	r1, #10
    ecb2:	e9cd 0902 	strd	r0, r9, [sp, #8]
    ecb6:	9100      	str	r1, [sp, #0]
    ecb8:	4630      	mov	r0, r6
    ecba:	4639      	mov	r1, r7
    ecbc:	f7fd fc92 	bl	c5e4 <print_digits.part.0>
    ecc0:	4654      	mov	r4, sl
    ecc2:	e751      	b.n	eb68 <z_vprintk+0x18>
					d = va_arg(ap, int);
    ecc4:	17d3      	asrs	r3, r2, #31
				if (*fmt != 'u' && negative(d)) {
    ecc6:	2a00      	cmp	r2, #0
    ecc8:	f173 0100 	sbcs.w	r1, r3, #0
    eccc:	dae6      	bge.n	ec9c <z_vprintk+0x14c>
					out((int)'-', ctx);
    ecce:	4639      	mov	r1, r7
    ecd0:	202d      	movs	r0, #45	; 0x2d
    ecd2:	e9cd 2304 	strd	r2, r3, [sp, #16]
    ecd6:	47b0      	blx	r6
					d = -d;
    ecd8:	e9dd 2304 	ldrd	r2, r3, [sp, #16]
    ecdc:	4252      	negs	r2, r2
    ecde:	eb63 0343 	sbc.w	r3, r3, r3, lsl #1
					min_width--;
    ece2:	f109 39ff 	add.w	r9, r9, #4294967295	; 0xffffffff
    ece6:	e7d9      	b.n	ec9c <z_vprintk+0x14c>
				out('0', ctx);
    ece8:	4639      	mov	r1, r7
    ecea:	2030      	movs	r0, #48	; 0x30
    ecec:	47b0      	blx	r6
				out('x', ctx);
    ecee:	4639      	mov	r1, r7
    ecf0:	2078      	movs	r0, #120	; 0x78
    ecf2:	47b0      	blx	r6
				min_width = sizeof(void *) * 2;
    ecf4:	f04f 0908 	mov.w	r9, #8
				padding = PAD_ZERO_BEFORE;
    ecf8:	f04f 0801 	mov.w	r8, #1
				if (*fmt == 'p') {
    ecfc:	f89b 3000 	ldrb.w	r3, [fp]
    ed00:	2b70      	cmp	r3, #112	; 0x70
    ed02:	d103      	bne.n	ed0c <z_vprintk+0x1bc>
					x = va_arg(ap, unsigned int);
    ed04:	f854 2b04 	ldr.w	r2, [r4], #4
    ed08:	2300      	movs	r3, #0
    ed0a:	e00a      	b.n	ed22 <z_vprintk+0x1d2>
				} else if (length_mod == 'l') {
    ed0c:	2d6c      	cmp	r5, #108	; 0x6c
    ed0e:	d0f9      	beq.n	ed04 <z_vprintk+0x1b4>
				} else if (length_mod == 'L') {
    ed10:	2d4c      	cmp	r5, #76	; 0x4c
    ed12:	d1f7      	bne.n	ed04 <z_vprintk+0x1b4>
					x = va_arg(ap, unsigned long long);
    ed14:	3407      	adds	r4, #7
    ed16:	f024 0307 	bic.w	r3, r4, #7
    ed1a:	461c      	mov	r4, r3
    ed1c:	685b      	ldr	r3, [r3, #4]
    ed1e:	f854 2b08 	ldr.w	r2, [r4], #8
	print_digits(out, ctx, num, 16, padding != PAD_SPACE_AFTER,
    ed22:	f1b8 0103 	subs.w	r1, r8, #3
    ed26:	bf18      	it	ne
    ed28:	2101      	movne	r1, #1
    ed2a:	f1b8 0f01 	cmp.w	r8, #1
    ed2e:	bf0c      	ite	eq
    ed30:	2030      	moveq	r0, #48	; 0x30
    ed32:	2020      	movne	r0, #32
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
    ed34:	9101      	str	r1, [sp, #4]
    ed36:	2110      	movs	r1, #16
    ed38:	e9cd 0902 	strd	r0, r9, [sp, #8]
    ed3c:	9100      	str	r1, [sp, #0]
    ed3e:	4630      	mov	r0, r6
    ed40:	4639      	mov	r1, r7
    ed42:	f7fd fc4f 	bl	c5e4 <print_digits.part.0>
    ed46:	e70f      	b.n	eb68 <z_vprintk+0x18>
					out((int)(*s++), ctx);
    ed48:	4639      	mov	r1, r7
    ed4a:	9304      	str	r3, [sp, #16]
    ed4c:	47b0      	blx	r6
    ed4e:	9b04      	ldr	r3, [sp, #16]
    ed50:	e754      	b.n	ebfc <z_vprintk+0xac>
				out(c, ctx);
    ed52:	4639      	mov	r1, r7
    ed54:	f854 0b04 	ldr.w	r0, [r4], #4
    ed58:	e734      	b.n	ebc4 <z_vprintk+0x74>
				length_mod = 0;
    ed5a:	4655      	mov	r5, sl
				padding = PAD_NONE;
    ed5c:	46d0      	mov	r8, sl
				min_width = -1;
    ed5e:	f04f 39ff 	mov.w	r9, #4294967295	; 0xffffffff
				might_format = 1;
    ed62:	f04f 0a01 	mov.w	sl, #1
    ed66:	e70a      	b.n	eb7e <z_vprintk+0x2e>
				padding = PAD_SPACE_AFTER;
    ed68:	f04f 0803 	mov.w	r8, #3
    ed6c:	e707      	b.n	eb7e <z_vprintk+0x2e>
					padding = PAD_ZERO_BEFORE;
    ed6e:	f04f 0801 	mov.w	r8, #1
    ed72:	e704      	b.n	eb7e <z_vprintk+0x2e>
			might_format = 0;
    ed74:	4682      	mov	sl, r0
    ed76:	e702      	b.n	eb7e <z_vprintk+0x2e>

0000ed78 <printk>:
 * @param fmt formatted string to output
 *
 * @return N/A
 */
void printk(const char *fmt, ...)
{
    ed78:	b40f      	push	{r0, r1, r2, r3}
    ed7a:	b507      	push	{r0, r1, r2, lr}
    ed7c:	a904      	add	r1, sp, #16
    ed7e:	f851 0b04 	ldr.w	r0, [r1], #4
	va_list ap;

	va_start(ap, fmt);
    ed82:	9101      	str	r1, [sp, #4]

	if (IS_ENABLED(CONFIG_LOG_PRINTK)) {
		log_printk(fmt, ap);
	} else {
		vprintk(fmt, ap);
    ed84:	f7fd fc7e 	bl	c684 <vprintk>
	}
	va_end(ap);
}
    ed88:	b003      	add	sp, #12
    ed8a:	f85d eb04 	ldr.w	lr, [sp], #4
    ed8e:	b004      	add	sp, #16
    ed90:	4770      	bx	lr

0000ed92 <process_recheck>:
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    ed92:	8b03      	ldrh	r3, [r0, #24]
	if ((state == ONOFF_STATE_OFF)
    ed94:	f013 0307 	ands.w	r3, r3, #7
    ed98:	d105      	bne.n	eda6 <process_recheck+0x14>
	    && !sys_slist_is_empty(&mgr->clients)) {
    ed9a:	6803      	ldr	r3, [r0, #0]
    ed9c:	2b00      	cmp	r3, #0
		evt = EVT_START;
    ed9e:	bf0c      	ite	eq
    eda0:	2000      	moveq	r0, #0
    eda2:	2003      	movne	r0, #3
    eda4:	4770      	bx	lr
	} else if ((state == ONOFF_STATE_ON)
    eda6:	2b02      	cmp	r3, #2
    eda8:	d105      	bne.n	edb6 <process_recheck+0x24>
		   && (mgr->refs == 0)) {
    edaa:	8b43      	ldrh	r3, [r0, #26]
    edac:	2b00      	cmp	r3, #0
		evt = EVT_STOP;
    edae:	bf14      	ite	ne
    edb0:	2000      	movne	r0, #0
    edb2:	2004      	moveq	r0, #4
    edb4:	4770      	bx	lr
	} else if ((state == ONOFF_STATE_ERROR)
    edb6:	2b01      	cmp	r3, #1
    edb8:	d105      	bne.n	edc6 <process_recheck+0x34>
		   && !sys_slist_is_empty(&mgr->clients)) {
    edba:	6803      	ldr	r3, [r0, #0]
    edbc:	2b00      	cmp	r3, #0
		evt = EVT_RESET;
    edbe:	bf0c      	ite	eq
    edc0:	2000      	moveq	r0, #0
    edc2:	2005      	movne	r0, #5
    edc4:	4770      	bx	lr
	int evt = EVT_NOP;
    edc6:	2000      	movs	r0, #0
}
    edc8:	4770      	bx	lr

0000edca <notify_one>:
{
    edca:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    edce:	460d      	mov	r5, r1
    edd0:	4607      	mov	r7, r0
		(onoff_client_callback)sys_notify_finalize(&cli->notify, res);
    edd2:	4619      	mov	r1, r3
    edd4:	1d28      	adds	r0, r5, #4
{
    edd6:	4690      	mov	r8, r2
    edd8:	461e      	mov	r6, r3
		(onoff_client_callback)sys_notify_finalize(&cli->notify, res);
    edda:	f7ff feaa 	bl	eb32 <sys_notify_finalize>
	if (cb) {
    edde:	4604      	mov	r4, r0
    ede0:	b138      	cbz	r0, edf2 <notify_one+0x28>
		cb(mgr, cli, state, res);
    ede2:	4633      	mov	r3, r6
    ede4:	4642      	mov	r2, r8
    ede6:	4629      	mov	r1, r5
    ede8:	4638      	mov	r0, r7
    edea:	46a4      	mov	ip, r4
}
    edec:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
		cb(mgr, cli, state, res);
    edf0:	4760      	bx	ip
}
    edf2:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

0000edf6 <transition_complete>:
{
    edf6:	b410      	push	{r4}
	__asm__ volatile(
    edf8:	f04f 0420 	mov.w	r4, #32
    edfc:	f3ef 8211 	mrs	r2, BASEPRI
    ee00:	f384 8811 	msr	BASEPRI, r4
    ee04:	f3bf 8f6f 	isb	sy
	mgr->last_res = res;
    ee08:	6141      	str	r1, [r0, #20]
}
    ee0a:	bc10      	pop	{r4}
	process_event(mgr, EVT_COMPLETE, key);
    ee0c:	2101      	movs	r1, #1
    ee0e:	f7fd bc47 	b.w	c6a0 <process_event>

0000ee12 <validate_args>:
{
    ee12:	b510      	push	{r4, lr}
    ee14:	460c      	mov	r4, r1
	if ((mgr == NULL) || (cli == NULL)) {
    ee16:	b140      	cbz	r0, ee2a <validate_args+0x18>
    ee18:	b139      	cbz	r1, ee2a <validate_args+0x18>
	int rv = sys_notify_validate(&cli->notify);
    ee1a:	1d08      	adds	r0, r1, #4
    ee1c:	f7ff fe78 	bl	eb10 <sys_notify_validate>
	if ((rv == 0)
    ee20:	b928      	cbnz	r0, ee2e <validate_args+0x1c>
	    && ((cli->notify.flags
    ee22:	68a3      	ldr	r3, [r4, #8]
    ee24:	f033 0303 	bics.w	r3, r3, #3
    ee28:	d001      	beq.n	ee2e <validate_args+0x1c>
		rv = -EINVAL;
    ee2a:	f06f 0015 	mvn.w	r0, #21
}
    ee2e:	bd10      	pop	{r4, pc}

0000ee30 <onoff_manager_init>:
{
    ee30:	b538      	push	{r3, r4, r5, lr}
    ee32:	460c      	mov	r4, r1
	if ((mgr == NULL)
    ee34:	4605      	mov	r5, r0
    ee36:	b158      	cbz	r0, ee50 <onoff_manager_init+0x20>
	    || (transitions == NULL)
    ee38:	b151      	cbz	r1, ee50 <onoff_manager_init+0x20>
	    || (transitions->start == NULL)
    ee3a:	680b      	ldr	r3, [r1, #0]
    ee3c:	b143      	cbz	r3, ee50 <onoff_manager_init+0x20>
	    || (transitions->stop == NULL)) {
    ee3e:	684b      	ldr	r3, [r1, #4]
    ee40:	b133      	cbz	r3, ee50 <onoff_manager_init+0x20>
	*mgr = (struct onoff_manager)ONOFF_MANAGER_INITIALIZER(transitions);
    ee42:	221c      	movs	r2, #28
    ee44:	2100      	movs	r1, #0
    ee46:	f000 fa56 	bl	f2f6 <memset>
	return 0;
    ee4a:	2000      	movs	r0, #0
	*mgr = (struct onoff_manager)ONOFF_MANAGER_INITIALIZER(transitions);
    ee4c:	612c      	str	r4, [r5, #16]
}
    ee4e:	bd38      	pop	{r3, r4, r5, pc}
		return -EINVAL;
    ee50:	f06f 0015 	mvn.w	r0, #21
    ee54:	e7fb      	b.n	ee4e <onoff_manager_init+0x1e>

0000ee56 <onoff_request>:

int onoff_request(struct onoff_manager *mgr,
		  struct onoff_client *cli)
{
    ee56:	b570      	push	{r4, r5, r6, lr}
    ee58:	4604      	mov	r4, r0
    ee5a:	460d      	mov	r5, r1
	bool add_client = false;        /* add client to pending list */
	bool start = false;             /* trigger a start transition */
	bool notify = false;            /* do client notification */
	int rv = validate_args(mgr, cli);
    ee5c:	f7ff ffd9 	bl	ee12 <validate_args>

	if (rv < 0) {
    ee60:	1e06      	subs	r6, r0, #0
    ee62:	db31      	blt.n	eec8 <onoff_request+0x72>
    ee64:	f04f 0320 	mov.w	r3, #32
    ee68:	f3ef 8111 	mrs	r1, BASEPRI
    ee6c:	f383 8811 	msr	BASEPRI, r3
    ee70:	f3bf 8f6f 	isb	sy

	k_spinlock_key_t key = k_spin_lock(&mgr->lock);
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;

	/* Reject if this would overflow the reference count. */
	if (mgr->refs == SERVICE_REFS_MAX) {
    ee74:	f64f 76ff 	movw	r6, #65535	; 0xffff
    ee78:	8b63      	ldrh	r3, [r4, #26]
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    ee7a:	8b20      	ldrh	r0, [r4, #24]
	if (mgr->refs == SERVICE_REFS_MAX) {
    ee7c:	42b3      	cmp	r3, r6
    ee7e:	f000 0207 	and.w	r2, r0, #7
    ee82:	d02e      	beq.n	eee2 <onoff_request+0x8c>
		rv = -EAGAIN;
		goto out;
	}

	rv = state;
	if (state == ONOFF_STATE_ON) {
    ee84:	2a02      	cmp	r2, #2
    ee86:	d10e      	bne.n	eea6 <onoff_request+0x50>
		/* Increment reference count, notify in exit */
		notify = true;
		mgr->refs += 1U;
    ee88:	3301      	adds	r3, #1
    ee8a:	8363      	strh	r3, [r4, #26]
	rv = state;
    ee8c:	4616      	mov	r6, r2
		notify = true;
    ee8e:	2301      	movs	r3, #1
	__asm__ volatile(
    ee90:	f381 8811 	msr	BASEPRI, r1
    ee94:	f3bf 8f6f 	isb	sy
	if (start) {
		process_event(mgr, EVT_RECHECK, key);
	} else {
		k_spin_unlock(&mgr->lock, key);

		if (notify) {
    ee98:	b1b3      	cbz	r3, eec8 <onoff_request+0x72>
			notify_one(mgr, cli, state, 0);
    ee9a:	2300      	movs	r3, #0
    ee9c:	4629      	mov	r1, r5
    ee9e:	4620      	mov	r0, r4
    eea0:	f7ff ff93 	bl	edca <notify_one>
    eea4:	e010      	b.n	eec8 <onoff_request+0x72>
	} else if ((state == ONOFF_STATE_OFF)
    eea6:	0783      	lsls	r3, r0, #30
    eea8:	d001      	beq.n	eeae <onoff_request+0x58>
		   || (state == ONOFF_STATE_TO_ON)) {
    eeaa:	2a06      	cmp	r2, #6
    eeac:	d10e      	bne.n	eecc <onoff_request+0x76>
	parent->next = child;
    eeae:	2300      	movs	r3, #0
    eeb0:	602b      	str	r3, [r5, #0]
Z_GENLIST_APPEND(slist, snode)
    eeb2:	6863      	ldr	r3, [r4, #4]
    eeb4:	b993      	cbnz	r3, eedc <onoff_request+0x86>
	list->head = node;
    eeb6:	e9c4 5500 	strd	r5, r5, [r4]
	if (start) {
    eeba:	4616      	mov	r6, r2
    eebc:	b962      	cbnz	r2, eed8 <onoff_request+0x82>
		process_event(mgr, EVT_RECHECK, key);
    eebe:	460a      	mov	r2, r1
    eec0:	4620      	mov	r0, r4
    eec2:	2102      	movs	r1, #2
    eec4:	f7fd fbec 	bl	c6a0 <process_event>
		}
	}

	return rv;
}
    eec8:	4630      	mov	r0, r6
    eeca:	bd70      	pop	{r4, r5, r6, pc}
		rv = -EIO;
    eecc:	2a05      	cmp	r2, #5
    eece:	bf0c      	ite	eq
    eed0:	f06f 0622 	mvneq.w	r6, #34	; 0x22
    eed4:	f06f 0604 	mvnne.w	r6, #4
    eed8:	2300      	movs	r3, #0
    eeda:	e7d9      	b.n	ee90 <onoff_request+0x3a>
	parent->next = child;
    eedc:	601d      	str	r5, [r3, #0]
	list->tail = node;
    eede:	6065      	str	r5, [r4, #4]
    eee0:	e7eb      	b.n	eeba <onoff_request+0x64>
		rv = -EAGAIN;
    eee2:	f06f 060a 	mvn.w	r6, #10
    eee6:	e7f7      	b.n	eed8 <onoff_request+0x82>

0000eee8 <z_thread_entry>:
 * This routine does not return, and is marked as such so the compiler won't
 * generate preamble code that is only used by functions that actually return.
 */
FUNC_NORETURN void z_thread_entry(k_thread_entry_t entry,
				 void *p1, void *p2, void *p3)
{
    eee8:	4604      	mov	r4, r0
    eeea:	b508      	push	{r3, lr}
    eeec:	4608      	mov	r0, r1
    eeee:	4611      	mov	r1, r2
	entry(p1, p2, p3);
    eef0:	461a      	mov	r2, r3
    eef2:	47a0      	blx	r4
	return z_impl_k_current_get();
    eef4:	f7ff fbbe 	bl	e674 <z_impl_k_current_get>
	z_impl_k_thread_abort(thread);
    eef8:	f7fe f99e 	bl	d238 <z_impl_k_thread_abort>

0000eefc <chunk_field>:
				 enum chunk_fields f)
{
	chunk_unit_t *buf = chunk_buf(h);
	void *cmem = &buf[c];

	if (big_heap(h)) {
    eefc:	6883      	ldr	r3, [r0, #8]
	void *cmem = &buf[c];
    eefe:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
	if (big_heap(h)) {
    ef02:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
		return ((uint32_t *)cmem)[f];
    ef06:	bf2c      	ite	cs
    ef08:	f851 0022 	ldrcs.w	r0, [r1, r2, lsl #2]
	} else {
		return ((uint16_t *)cmem)[f];
    ef0c:	f831 0012 	ldrhcc.w	r0, [r1, r2, lsl #1]
	}
}
    ef10:	4770      	bx	lr

0000ef12 <chunk_set>:
			     enum chunk_fields f, chunkid_t val)
{
	CHECK(c <= h->len);

	chunk_unit_t *buf = chunk_buf(h);
	void *cmem = &buf[c];
    ef12:	eb00 01c1 	add.w	r1, r0, r1, lsl #3

	if (big_heap(h)) {
    ef16:	6880      	ldr	r0, [r0, #8]
    ef18:	f5b0 4f00 	cmp.w	r0, #32768	; 0x8000
		CHECK(val == (uint32_t)val);
		((uint32_t *)cmem)[f] = val;
    ef1c:	bf2c      	ite	cs
    ef1e:	f841 3022 	strcs.w	r3, [r1, r2, lsl #2]
	} else {
		CHECK(val == (uint16_t)val);
		((uint16_t *)cmem)[f] = val;
    ef22:	f821 3012 	strhcc.w	r3, [r1, r2, lsl #1]
	}
}
    ef26:	4770      	bx	lr

0000ef28 <chunk_size>:
{
	return chunk_field(h, c, SIZE_AND_USED) & 1;
}

static inline size_t chunk_size(struct z_heap *h, chunkid_t c)
{
    ef28:	b508      	push	{r3, lr}
	return chunk_field(h, c, SIZE_AND_USED) >> 1;
    ef2a:	2201      	movs	r2, #1
    ef2c:	f7ff ffe6 	bl	eefc <chunk_field>
}
    ef30:	0840      	lsrs	r0, r0, #1
    ef32:	bd08      	pop	{r3, pc}

0000ef34 <set_chunk_used>:
static inline void set_chunk_used(struct z_heap *h, chunkid_t c, bool used)
{
	chunk_unit_t *buf = chunk_buf(h);
	void *cmem = &buf[c];

	if (big_heap(h)) {
    ef34:	6883      	ldr	r3, [r0, #8]
	void *cmem = &buf[c];
    ef36:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
	if (big_heap(h)) {
    ef3a:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    ef3e:	d308      	bcc.n	ef52 <set_chunk_used+0x1e>
		if (used) {
    ef40:	684b      	ldr	r3, [r1, #4]
    ef42:	b11a      	cbz	r2, ef4c <set_chunk_used+0x18>
			((uint32_t *)cmem)[SIZE_AND_USED] |= 1;
    ef44:	f043 0301 	orr.w	r3, r3, #1
		} else {
			((uint32_t *)cmem)[SIZE_AND_USED] &= ~1;
    ef48:	604b      	str	r3, [r1, #4]
    ef4a:	4770      	bx	lr
    ef4c:	f023 0301 	bic.w	r3, r3, #1
    ef50:	e7fa      	b.n	ef48 <set_chunk_used+0x14>
		}
	} else {
		if (used) {
    ef52:	884b      	ldrh	r3, [r1, #2]
    ef54:	b11a      	cbz	r2, ef5e <set_chunk_used+0x2a>
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1;
    ef56:	f043 0301 	orr.w	r3, r3, #1
		} else {
			((uint16_t *)cmem)[SIZE_AND_USED] &= ~1;
    ef5a:	804b      	strh	r3, [r1, #2]
		}
	}
}
    ef5c:	4770      	bx	lr
			((uint16_t *)cmem)[SIZE_AND_USED] &= ~1;
    ef5e:	f023 0301 	bic.w	r3, r3, #1
    ef62:	e7fa      	b.n	ef5a <set_chunk_used+0x26>

0000ef64 <set_chunk_size>:
 * when its size is modified, and potential set_chunk_used() is always
 * invoked after set_chunk_size().
 */
static inline void set_chunk_size(struct z_heap *h, chunkid_t c, size_t size)
{
	chunk_set(h, c, SIZE_AND_USED, size << 1);
    ef64:	0053      	lsls	r3, r2, #1
    ef66:	2201      	movs	r2, #1
    ef68:	f7ff bfd3 	b.w	ef12 <chunk_set>

0000ef6c <bucket_idx>:
	return big_heap(h) && chunk_size(h, c) == 1;
}

static inline size_t chunk_header_bytes(struct z_heap *h)
{
	return big_heap(h) ? 8 : 4;
    ef6c:	6883      	ldr	r3, [r0, #8]
	return bytes_to_chunksz(h, 1);
}

static inline int bucket_idx(struct z_heap *h, size_t sz)
{
	size_t usable_sz = sz - min_chunk_size(h) + 1;
    ef6e:	1c48      	adds	r0, r1, #1
	return (bytes + CHUNK_UNIT - 1) / CHUNK_UNIT;
    ef70:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    ef74:	bf2c      	ite	cs
    ef76:	2302      	movcs	r3, #2
    ef78:	2301      	movcc	r3, #1
	size_t usable_sz = sz - min_chunk_size(h) + 1;
    ef7a:	1ac0      	subs	r0, r0, r3
	return 31 - __builtin_clz(usable_sz);
    ef7c:	fab0 f080 	clz	r0, r0
}
    ef80:	f1c0 001f 	rsb	r0, r0, #31
    ef84:	4770      	bx	lr

0000ef86 <free_list_add>:
		set_prev_free_chunk(h, second, c);
	}
}

static void free_list_add(struct z_heap *h, chunkid_t c)
{
    ef86:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    ef8a:	4604      	mov	r4, r0
    ef8c:	460d      	mov	r5, r1
	return sizeof(void *) > 4 || chunks > 0x7fff;
    ef8e:	f7ff ffcb 	bl	ef28 <chunk_size>
	return big_heap(h) && chunk_size(h, c) == 1;
    ef92:	68a3      	ldr	r3, [r4, #8]
    ef94:	4601      	mov	r1, r0
    ef96:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    ef9a:	d301      	bcc.n	efa0 <free_list_add+0x1a>
	if (!solo_free_header(h, c)) {
    ef9c:	2801      	cmp	r0, #1
    ef9e:	d035      	beq.n	f00c <free_list_add+0x86>
		int bidx = bucket_idx(h, chunk_size(h, c));
    efa0:	4620      	mov	r0, r4
    efa2:	f7ff ffe3 	bl	ef6c <bucket_idx>
	if (b->next == 0) {
    efa6:	eb04 0280 	add.w	r2, r4, r0, lsl #2
    efaa:	6916      	ldr	r6, [r2, #16]
    efac:	b99e      	cbnz	r6, efd6 <free_list_add+0x50>
		h->avail_buckets |= (1 << bidx);
    efae:	2301      	movs	r3, #1
    efb0:	fa03 f000 	lsl.w	r0, r3, r0
    efb4:	68e3      	ldr	r3, [r4, #12]
	chunk_set(h, c, FREE_PREV, prev);
    efb6:	4629      	mov	r1, r5
    efb8:	4303      	orrs	r3, r0
    efba:	60e3      	str	r3, [r4, #12]
    efbc:	4620      	mov	r0, r4
		b->next = c;
    efbe:	6115      	str	r5, [r2, #16]
    efc0:	462b      	mov	r3, r5
    efc2:	2202      	movs	r2, #2
    efc4:	f7ff ffa5 	bl	ef12 <chunk_set>
	chunk_set(h, c, FREE_NEXT, next);
    efc8:	2203      	movs	r2, #3
    efca:	4629      	mov	r1, r5
	chunk_set(h, c, FREE_PREV, prev);
    efcc:	4620      	mov	r0, r4
		free_list_add_bidx(h, c, bidx);
	}
}
    efce:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    efd2:	f7ff bf9e 	b.w	ef12 <chunk_set>
	return chunk_field(h, c, FREE_PREV);
    efd6:	2202      	movs	r2, #2
    efd8:	4631      	mov	r1, r6
    efda:	4620      	mov	r0, r4
    efdc:	f7ff ff8e 	bl	eefc <chunk_field>
    efe0:	4607      	mov	r7, r0
	chunk_set(h, c, FREE_PREV, prev);
    efe2:	4603      	mov	r3, r0
    efe4:	2202      	movs	r2, #2
    efe6:	4629      	mov	r1, r5
    efe8:	4620      	mov	r0, r4
    efea:	f7ff ff92 	bl	ef12 <chunk_set>
	chunk_set(h, c, FREE_NEXT, next);
    efee:	4633      	mov	r3, r6
    eff0:	2203      	movs	r2, #3
    eff2:	4629      	mov	r1, r5
    eff4:	4620      	mov	r0, r4
    eff6:	f7ff ff8c 	bl	ef12 <chunk_set>
    effa:	2203      	movs	r2, #3
    effc:	4639      	mov	r1, r7
    effe:	462b      	mov	r3, r5
    f000:	4620      	mov	r0, r4
    f002:	f7ff ff86 	bl	ef12 <chunk_set>
	chunk_set(h, c, FREE_PREV, prev);
    f006:	2202      	movs	r2, #2
    f008:	4631      	mov	r1, r6
    f00a:	e7df      	b.n	efcc <free_list_add+0x46>
    f00c:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

0000f010 <sys_heap_init>:
	return big_heap_bytes(size) ? 8 : 4;
    f010:	f5b2 2f80 	cmp.w	r2, #262144	; 0x40000
	set_chunk_used(h, c, true);
	return mem;
}

void sys_heap_init(struct sys_heap *heap, void *mem, size_t bytes)
{
    f014:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    f016:	bf2c      	ite	cs
    f018:	2508      	movcs	r5, #8
    f01a:	2504      	movcc	r5, #4
	CHECK(end > addr);
	__ASSERT(buf_sz > chunksz(sizeof(struct z_heap)), "heap size is too small");

	struct z_heap *h = (struct z_heap *)addr;
	heap->heap = h;
	h->chunk0_hdr_area = 0;
    f01c:	2300      	movs	r3, #0
	bytes -= heap_footer_bytes(bytes);
    f01e:	1b55      	subs	r5, r2, r5
	h->chunk0_hdr_area = 0;
    f020:	2200      	movs	r2, #0
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
    f022:	1dcc      	adds	r4, r1, #7
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
    f024:	440d      	add	r5, r1
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
    f026:	f024 0407 	bic.w	r4, r4, #7
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
    f02a:	f025 0507 	bic.w	r5, r5, #7
	size_t buf_sz = (end - addr) / CHUNK_UNIT;
    f02e:	1b2d      	subs	r5, r5, r4
    f030:	08ed      	lsrs	r5, r5, #3
	heap->heap = h;
    f032:	6004      	str	r4, [r0, #0]
	h->len = buf_sz;
	h->avail_buckets = 0;

	int nb_buckets = bucket_idx(h, buf_sz) + 1;
    f034:	4629      	mov	r1, r5
	h->chunk0_hdr_area = 0;
    f036:	e9c4 2300 	strd	r2, r3, [r4]
	h->avail_buckets = 0;
    f03a:	e9c4 5202 	strd	r5, r2, [r4, #8]
	int nb_buckets = bucket_idx(h, buf_sz) + 1;
    f03e:	4620      	mov	r0, r4
    f040:	f7ff ff94 	bl	ef6c <bucket_idx>
	size_t chunk0_size = chunksz(sizeof(struct z_heap) +
				     nb_buckets * sizeof(struct z_heap_bucket));

	__ASSERT(chunk0_size + min_chunk_size(h) < buf_sz, "heap size is too small");

	for (int i = 0; i < nb_buckets; i++) {
    f044:	4613      	mov	r3, r2
	size_t chunk0_size = chunksz(sizeof(struct z_heap) +
    f046:	0086      	lsls	r6, r0, #2
	return (bytes + CHUNK_UNIT - 1) / CHUNK_UNIT;
    f048:	361b      	adds	r6, #27
	int nb_buckets = bucket_idx(h, buf_sz) + 1;
    f04a:	1c47      	adds	r7, r0, #1
    f04c:	08f6      	lsrs	r6, r6, #3
	for (int i = 0; i < nb_buckets; i++) {
    f04e:	f104 0110 	add.w	r1, r4, #16
    f052:	42bb      	cmp	r3, r7
    f054:	db29      	blt.n	f0aa <sys_heap_init+0x9a>
		h->buckets[i].next = 0;
	}

	/* chunk containing our struct z_heap */
	set_chunk_size(h, 0, chunk0_size);
    f056:	4632      	mov	r2, r6
    f058:	4620      	mov	r0, r4
    f05a:	2100      	movs	r1, #0
    f05c:	f7ff ff82 	bl	ef64 <set_chunk_size>
	set_chunk_used(h, 0, true);

	/* chunk containing the free heap */
	set_chunk_size(h, chunk0_size, buf_sz - chunk0_size);
    f060:	1baf      	subs	r7, r5, r6
	set_chunk_used(h, 0, true);
    f062:	4620      	mov	r0, r4
    f064:	2201      	movs	r2, #1
    f066:	2100      	movs	r1, #0
    f068:	f7ff ff64 	bl	ef34 <set_chunk_used>
	set_chunk_size(h, chunk0_size, buf_sz - chunk0_size);
    f06c:	463a      	mov	r2, r7
    f06e:	4631      	mov	r1, r6
    f070:	f7ff ff78 	bl	ef64 <set_chunk_size>
	chunk_set(h, c, LEFT_SIZE, size);
    f074:	4633      	mov	r3, r6
    f076:	4631      	mov	r1, r6
    f078:	4620      	mov	r0, r4
    f07a:	2200      	movs	r2, #0
    f07c:	f7ff ff49 	bl	ef12 <chunk_set>
	set_left_chunk_size(h, chunk0_size, chunk0_size);

	/* the end marker chunk */
	set_chunk_size(h, buf_sz, 0);
    f080:	4629      	mov	r1, r5
    f082:	4620      	mov	r0, r4
    f084:	2200      	movs	r2, #0
    f086:	f7ff ff6d 	bl	ef64 <set_chunk_size>
    f08a:	463b      	mov	r3, r7
    f08c:	4629      	mov	r1, r5
    f08e:	4620      	mov	r0, r4
    f090:	2200      	movs	r2, #0
    f092:	f7ff ff3e 	bl	ef12 <chunk_set>
	set_left_chunk_size(h, buf_sz, buf_sz - chunk0_size);
	set_chunk_used(h, buf_sz, true);
    f096:	4629      	mov	r1, r5
    f098:	4620      	mov	r0, r4
    f09a:	2201      	movs	r2, #1
    f09c:	f7ff ff4a 	bl	ef34 <set_chunk_used>

	free_list_add(h, chunk0_size);
    f0a0:	4631      	mov	r1, r6
}
    f0a2:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
	free_list_add(h, chunk0_size);
    f0a6:	f7ff bf6e 	b.w	ef86 <free_list_add>
		h->buckets[i].next = 0;
    f0aa:	f841 2b04 	str.w	r2, [r1], #4
	for (int i = 0; i < nb_buckets; i++) {
    f0ae:	3301      	adds	r3, #1
    f0b0:	e7cf      	b.n	f052 <sys_heap_init+0x42>

0000f0b2 <_ConfigAbsSyms>:
GEN_ABSOLUTE_SYM(CONFIG_OUTPUT_PRINT_MEMORY_USAGE, 1);
GEN_ABSOLUTE_SYM(CONFIG_BUILD_OUTPUT_BIN, 1);
GEN_ABSOLUTE_SYM(CONFIG_REBOOT, 1);
GEN_ABSOLUTE_SYM(CONFIG_COMPAT_INCLUDES, 1);

GEN_ABS_SYM_END
    f0b2:	4770      	bx	lr

0000f0b4 <z_platform_init>:

void z_platform_init(void)
{
	SystemInit();
    f0b4:	f7fe bdc6 	b.w	dc44 <SystemInit>

0000f0b8 <get_status>:
	return GET_STATUS(get_sub_data(dev, type)->flags);
    f0b8:	230c      	movs	r3, #12
    f0ba:	68c2      	ldr	r2, [r0, #12]
    f0bc:	b2c9      	uxtb	r1, r1
    f0be:	fb01 2303 	mla	r3, r1, r3, r2
    f0c2:	6c18      	ldr	r0, [r3, #64]	; 0x40
}
    f0c4:	f000 0007 	and.w	r0, r0, #7
    f0c8:	4770      	bx	lr

0000f0ca <set_off_state>:
	__asm__ volatile(
    f0ca:	f04f 0320 	mov.w	r3, #32
    f0ce:	f3ef 8211 	mrs	r2, BASEPRI
    f0d2:	f383 8811 	msr	BASEPRI, r3
    f0d6:	f3bf 8f6f 	isb	sy
	uint32_t current_ctx = GET_CTX(*flags);
    f0da:	6803      	ldr	r3, [r0, #0]
	if ((current_ctx != 0) && (current_ctx != ctx)) {
    f0dc:	f013 03c0 	ands.w	r3, r3, #192	; 0xc0
    f0e0:	d001      	beq.n	f0e6 <set_off_state+0x1c>
    f0e2:	428b      	cmp	r3, r1
    f0e4:	d107      	bne.n	f0f6 <set_off_state+0x2c>
		*flags = CLOCK_CONTROL_STATUS_OFF;
    f0e6:	2301      	movs	r3, #1
    f0e8:	6003      	str	r3, [r0, #0]
	int err = 0;
    f0ea:	2000      	movs	r0, #0
	__asm__ volatile(
    f0ec:	f382 8811 	msr	BASEPRI, r2
    f0f0:	f3bf 8f6f 	isb	sy
}
    f0f4:	4770      	bx	lr
		err = -EPERM;
    f0f6:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    f0fa:	e7f7      	b.n	f0ec <set_off_state+0x22>

0000f0fc <set_starting_state>:
{
    f0fc:	b510      	push	{r4, lr}
	__asm__ volatile(
    f0fe:	f04f 0320 	mov.w	r3, #32
    f102:	f3ef 8211 	mrs	r2, BASEPRI
    f106:	f383 8811 	msr	BASEPRI, r3
    f10a:	f3bf 8f6f 	isb	sy
	uint32_t current_ctx = GET_CTX(*flags);
    f10e:	6803      	ldr	r3, [r0, #0]
	if ((*flags & (STATUS_MASK)) == CLOCK_CONTROL_STATUS_OFF) {
    f110:	f003 0407 	and.w	r4, r3, #7
    f114:	2c01      	cmp	r4, #1
    f116:	d106      	bne.n	f126 <set_starting_state+0x2a>
		*flags = CLOCK_CONTROL_STATUS_STARTING | ctx;
    f118:	6001      	str	r1, [r0, #0]
	int err = 0;
    f11a:	2000      	movs	r0, #0
	__asm__ volatile(
    f11c:	f382 8811 	msr	BASEPRI, r2
    f120:	f3bf 8f6f 	isb	sy
}
    f124:	bd10      	pop	{r4, pc}
	uint32_t current_ctx = GET_CTX(*flags);
    f126:	f003 03c0 	and.w	r3, r3, #192	; 0xc0
	} else if (current_ctx != ctx) {
    f12a:	428b      	cmp	r3, r1
		err = -EBUSY;
    f12c:	bf14      	ite	ne
    f12e:	f04f 30ff 	movne.w	r0, #4294967295	; 0xffffffff
    f132:	f06f 000f 	mvneq.w	r0, #15
    f136:	e7f1      	b.n	f11c <set_starting_state+0x20>

0000f138 <set_on_state>:
	__asm__ volatile(
    f138:	f04f 0320 	mov.w	r3, #32
    f13c:	f3ef 8211 	mrs	r2, BASEPRI
    f140:	f383 8811 	msr	BASEPRI, r3
    f144:	f3bf 8f6f 	isb	sy
	*flags = CLOCK_CONTROL_STATUS_ON | GET_CTX(*flags);
    f148:	6803      	ldr	r3, [r0, #0]
    f14a:	f003 03c0 	and.w	r3, r3, #192	; 0xc0
    f14e:	f043 0302 	orr.w	r3, r3, #2
    f152:	6003      	str	r3, [r0, #0]
	__asm__ volatile(
    f154:	f382 8811 	msr	BASEPRI, r2
    f158:	f3bf 8f6f 	isb	sy
}
    f15c:	4770      	bx	lr

0000f15e <onoff_started_callback>:
	return &data->mgr[type];
    f15e:	68c3      	ldr	r3, [r0, #12]
	notify(mgr, 0);
    f160:	201c      	movs	r0, #28
{
    f162:	b410      	push	{r4}
	return &data->mgr[type];
    f164:	b2cc      	uxtb	r4, r1
	notify(mgr, 0);
    f166:	fb04 3000 	mla	r0, r4, r0, r3
    f16a:	2100      	movs	r1, #0
}
    f16c:	bc10      	pop	{r4}
	notify(mgr, 0);
    f16e:	4710      	bx	r2

0000f170 <blocking_start_callback>:
		arch_syscall_invoke1(*(uintptr_t *)&sem, K_SYSCALL_K_SEM_GIVE);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_sem_give(sem);
    f170:	4610      	mov	r0, r2
    f172:	f7ff ba85 	b.w	e680 <z_impl_k_sem_give>

0000f176 <lfclk_stop>:
    nrfx_clock_stop(NRF_CLOCK_DOMAIN_LFCLK);
    f176:	2000      	movs	r0, #0
    f178:	f7fe bdae 	b.w	dcd8 <nrfx_clock_stop>

0000f17c <lfclk_start>:
    nrfx_clock_start(NRF_CLOCK_DOMAIN_LFCLK);
    f17c:	2000      	movs	r0, #0
    f17e:	f7fe bd79 	b.w	dc74 <nrfx_clock_start>

0000f182 <api_stop>:
{
    f182:	b538      	push	{r3, r4, r5, lr}
	err = set_off_state(&subdata->flags, ctx);
    f184:	230c      	movs	r3, #12
    f186:	b2cc      	uxtb	r4, r1
    f188:	4363      	muls	r3, r4
{
    f18a:	4605      	mov	r5, r0
	err = set_off_state(&subdata->flags, ctx);
    f18c:	68c0      	ldr	r0, [r0, #12]
    f18e:	3340      	adds	r3, #64	; 0x40
    f190:	2180      	movs	r1, #128	; 0x80
    f192:	4418      	add	r0, r3
    f194:	f7ff ff99 	bl	f0ca <set_off_state>
	if (err < 0) {
    f198:	2800      	cmp	r0, #0
    f19a:	db05      	blt.n	f1a8 <api_stop+0x26>
	get_sub_config(dev, type)->stop();
    f19c:	6869      	ldr	r1, [r5, #4]
    f19e:	eb01 01c4 	add.w	r1, r1, r4, lsl #3
    f1a2:	684b      	ldr	r3, [r1, #4]
    f1a4:	4798      	blx	r3
	return 0;
    f1a6:	2000      	movs	r0, #0
}
    f1a8:	bd38      	pop	{r3, r4, r5, pc}

0000f1aa <api_start>:
{
    f1aa:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	err = set_starting_state(&subdata->flags, ctx);
    f1ae:	250c      	movs	r5, #12
    f1b0:	b2ce      	uxtb	r6, r1
    f1b2:	4375      	muls	r5, r6
	struct nrf_clock_control_sub_data *subdata = get_sub_data(dev, type);
    f1b4:	68c4      	ldr	r4, [r0, #12]
{
    f1b6:	4607      	mov	r7, r0
	err = set_starting_state(&subdata->flags, ctx);
    f1b8:	f105 0040 	add.w	r0, r5, #64	; 0x40
    f1bc:	2180      	movs	r1, #128	; 0x80
    f1be:	4420      	add	r0, r4
{
    f1c0:	4690      	mov	r8, r2
	err = set_starting_state(&subdata->flags, ctx);
    f1c2:	f7ff ff9b 	bl	f0fc <set_starting_state>
	if (err < 0) {
    f1c6:	2800      	cmp	r0, #0
    f1c8:	db0b      	blt.n	f1e2 <api_start+0x38>
	subdata->cb = data->cb;
    f1ca:	f8d8 3004 	ldr.w	r3, [r8, #4]
    f1ce:	442c      	add	r4, r5
    f1d0:	63a3      	str	r3, [r4, #56]	; 0x38
	subdata->user_data = data->user_data;
    f1d2:	f8d8 3008 	ldr.w	r3, [r8, #8]
    f1d6:	63e3      	str	r3, [r4, #60]	; 0x3c
	 get_sub_config(dev, type)->start();
    f1d8:	687b      	ldr	r3, [r7, #4]
    f1da:	f853 3036 	ldr.w	r3, [r3, r6, lsl #3]
    f1de:	4798      	blx	r3
	return 0;
    f1e0:	2000      	movs	r0, #0
}
    f1e2:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

0000f1e6 <z_clock_isr>:
/* Weak-linked noop defaults for optional driver interfaces: */

void __weak z_clock_isr(void *arg)
{
	__ASSERT_NO_MSG(false);
}
    f1e6:	4770      	bx	lr

0000f1e8 <z_clock_idle_exit>:
{
}

void __weak z_clock_idle_exit(void)
{
}
    f1e8:	4770      	bx	lr

0000f1ea <z_irq_spurious>:
 */
void z_irq_spurious(const void *unused)
{
	ARG_UNUSED(unused);

	z_arm_fatal_error(K_ERR_SPURIOUS_IRQ, NULL);
    f1ea:	2100      	movs	r1, #0
    f1ec:	2001      	movs	r0, #1
    f1ee:	f000 b804 	b.w	f1fa <z_arm_fatal_error>

0000f1f2 <configure_builtin_stack_guard>:
  __ASM volatile ("MSR psplim, %0" : : "r" (ProcStackPtrLimit));
    f1f2:	6e83      	ldr	r3, [r0, #104]	; 0x68
    f1f4:	f383 880b 	msr	PSPLIM, r3
}
    f1f8:	4770      	bx	lr

0000f1fa <z_arm_fatal_error>:
{

	if (esf != NULL) {
		esf_dump(esf);
	}
	z_fatal_error(reason, esf);
    f1fa:	f000 b962 	b.w	f4c2 <z_fatal_error>

0000f1fe <z_do_kernel_oops>:
 *   fault handler will executed insted of the SVC.
 *
 * @param esf exception frame
 */
void z_do_kernel_oops(const z_arch_esf_t *esf)
{
    f1fe:	4601      	mov	r1, r0
	z_fatal_error(reason, esf);
    f200:	6800      	ldr	r0, [r0, #0]
    f202:	f000 b95e 	b.w	f4c2 <z_fatal_error>

0000f206 <z_arm_nmi>:
 *
 * @return N/A
 */

void z_arm_nmi(void)
{
    f206:	b508      	push	{r3, lr}
	handler();
    f208:	f7fd fecc 	bl	cfa4 <z_SysNmiOnReset>
	z_arm_int_exit();
}
    f20c:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_arm_int_exit();
    f210:	f7fd bf0e 	b.w	d030 <z_arm_exc_exit>

0000f214 <mpu_configure_region>:
{
    f214:	b530      	push	{r4, r5, lr}
	region_conf.base = new_region->start;
    f216:	680b      	ldr	r3, [r1, #0]
{
    f218:	b085      	sub	sp, #20
	get_region_attr_from_k_mem_partition_info(&region_conf.attr,
    f21a:	684c      	ldr	r4, [r1, #4]
	p_attr->rbar = attr->rbar &
    f21c:	f89d 2008 	ldrb.w	r2, [sp, #8]
    f220:	890d      	ldrh	r5, [r1, #8]
	p_attr->r_limit = REGION_LIMIT_ADDR(base, size);
    f222:	3c01      	subs	r4, #1
	region_conf.base = new_region->start;
    f224:	9300      	str	r3, [sp, #0]
	p_attr->mair_idx = attr->mair_idx;
    f226:	8949      	ldrh	r1, [r1, #10]
	p_attr->r_limit = REGION_LIMIT_ADDR(base, size);
    f228:	f023 031f 	bic.w	r3, r3, #31
    f22c:	4423      	add	r3, r4
	p_attr->rbar = attr->rbar &
    f22e:	f365 0204 	bfi	r2, r5, #0, #5
	p_attr->mair_idx = attr->mair_idx;
    f232:	f361 1247 	bfi	r2, r1, #5, #3
	p_attr->r_limit = REGION_LIMIT_ADDR(base, size);
    f236:	f023 031f 	bic.w	r3, r3, #31
	if (index > (get_num_regions() - 1)) {
    f23a:	280f      	cmp	r0, #15
	p_attr->mair_idx = attr->mair_idx;
    f23c:	f88d 2008 	strb.w	r2, [sp, #8]
	p_attr->r_limit = REGION_LIMIT_ADDR(base, size);
    f240:	9303      	str	r3, [sp, #12]
    f242:	4604      	mov	r4, r0
    f244:	d805      	bhi.n	f252 <mpu_configure_region+0x3e>
	region_init(index, region_conf);
    f246:	4669      	mov	r1, sp
    f248:	f7fe f84c 	bl	d2e4 <region_init>
}
    f24c:	4620      	mov	r0, r4
    f24e:	b005      	add	sp, #20
    f250:	bd30      	pop	{r4, r5, pc}
		return -EINVAL;
    f252:	f06f 0415 	mvn.w	r4, #21
	return region_allocate_and_init(index,
    f256:	e7f9      	b.n	f24c <mpu_configure_region+0x38>

0000f258 <arm_cmse_mpu_region_get>:
__CMSE_TT_ASM ()

__extension__ static __inline __attribute__ ((__always_inline__))
cmse_address_info_t
cmse_TT (void *__p)
__CMSE_TT_ASM ()
    f258:	e840 f300 	tt	r3, r0

int arm_cmse_mpu_region_get(uint32_t addr)
{
	cmse_address_info_t addr_info =	cmse_TT((void *)addr);

	if (addr_info.flags.mpu_region_valid) {
    f25c:	f413 3f80 	tst.w	r3, #65536	; 0x10000
    f260:	b2d8      	uxtb	r0, r3
		return addr_info.flags.mpu_region;
	}

	return -EINVAL;
}
    f262:	bf08      	it	eq
    f264:	f06f 0015 	mvneq.w	r0, #21
    f268:	4770      	bx	lr

0000f26a <strcmp>:
 * @return negative # if <s1> < <s2>, 0 if <s1> == <s2>, else positive #
 */

int strcmp(const char *s1, const char *s2)
{
	while ((*s1 == *s2) && (*s1 != '\0')) {
    f26a:	3801      	subs	r0, #1
    f26c:	3901      	subs	r1, #1
    f26e:	f810 3f01 	ldrb.w	r3, [r0, #1]!
    f272:	f811 2f01 	ldrb.w	r2, [r1, #1]!
    f276:	4293      	cmp	r3, r2
    f278:	d101      	bne.n	f27e <strcmp+0x14>
    f27a:	2b00      	cmp	r3, #0
    f27c:	d1f7      	bne.n	f26e <strcmp+0x4>
		s1++;
		s2++;
	}

	return *s1 - *s2;
}
    f27e:	1a98      	subs	r0, r3, r2
    f280:	4770      	bx	lr

0000f282 <memcmp>:
 * @brief Compare two memory areas
 *
 * @return negative # if <m1> < <m2>, 0 if <m1> == <m2>, else positive #
 */
int memcmp(const void *m1, const void *m2, size_t n)
{
    f282:	b510      	push	{r4, lr}
	const char *c1 = m1;
	const char *c2 = m2;

	if (!n) {
    f284:	b15a      	cbz	r2, f29e <memcmp+0x1c>
    f286:	3901      	subs	r1, #1
    f288:	1884      	adds	r4, r0, r2
    f28a:	f810 2b01 	ldrb.w	r2, [r0], #1
    f28e:	f811 3f01 	ldrb.w	r3, [r1, #1]!
		return 0;
	}

	while ((--n > 0) && (*c1 == *c2)) {
    f292:	42a0      	cmp	r0, r4
    f294:	d001      	beq.n	f29a <memcmp+0x18>
    f296:	429a      	cmp	r2, r3
    f298:	d0f7      	beq.n	f28a <memcmp+0x8>
		c1++;
		c2++;
	}

	return *c1 - *c2;
    f29a:	1ad0      	subs	r0, r2, r3
}
    f29c:	bd10      	pop	{r4, pc}
		return 0;
    f29e:	4610      	mov	r0, r2
    f2a0:	e7fc      	b.n	f29c <memcmp+0x1a>

0000f2a2 <memcpy>:
 *
 * @return pointer to start of destination buffer
 */

void *memcpy(void *_MLIBC_RESTRICT d, const void *_MLIBC_RESTRICT s, size_t n)
{
    f2a2:	b5f0      	push	{r4, r5, r6, r7, lr}

	unsigned char *d_byte = (unsigned char *)d;
	const unsigned char *s_byte = (const unsigned char *)s;
	const uintptr_t mask = sizeof(mem_word_t) - 1;

	if ((((uintptr_t)d ^ (uintptr_t)s_byte) & mask) == 0) {
    f2a4:	ea81 0400 	eor.w	r4, r1, r0
    f2a8:	07a5      	lsls	r5, r4, #30
    f2aa:	4603      	mov	r3, r0
    f2ac:	d00b      	beq.n	f2c6 <memcpy+0x24>
    f2ae:	3b01      	subs	r3, #1
    f2b0:	440a      	add	r2, r1
		s_byte = (unsigned char *)s_word;
	}

	/* do byte-sized copying until finished */

	while (n > 0) {
    f2b2:	4291      	cmp	r1, r2
    f2b4:	d11a      	bne.n	f2ec <memcpy+0x4a>
		*(d_byte++) = *(s_byte++);
		n--;
	}

	return d;
}
    f2b6:	bdf0      	pop	{r4, r5, r6, r7, pc}
			if (n == 0) {
    f2b8:	2a00      	cmp	r2, #0
    f2ba:	d0fc      	beq.n	f2b6 <memcpy+0x14>
			*(d_byte++) = *(s_byte++);
    f2bc:	f811 4b01 	ldrb.w	r4, [r1], #1
			n--;
    f2c0:	3a01      	subs	r2, #1
			*(d_byte++) = *(s_byte++);
    f2c2:	f803 4b01 	strb.w	r4, [r3], #1
		while (((uintptr_t)d_byte) & mask) {
    f2c6:	079c      	lsls	r4, r3, #30
    f2c8:	d1f6      	bne.n	f2b8 <memcpy+0x16>
    f2ca:	0895      	lsrs	r5, r2, #2
    f2cc:	00ac      	lsls	r4, r5, #2
    f2ce:	1f1e      	subs	r6, r3, #4
    f2d0:	190f      	adds	r7, r1, r4
		while (n >= sizeof(mem_word_t)) {
    f2d2:	42b9      	cmp	r1, r7
    f2d4:	d105      	bne.n	f2e2 <memcpy+0x40>
    f2d6:	f06f 0603 	mvn.w	r6, #3
    f2da:	4423      	add	r3, r4
    f2dc:	fb06 2205 	mla	r2, r6, r5, r2
    f2e0:	e7e5      	b.n	f2ae <memcpy+0xc>
			*(d_word++) = *(s_word++);
    f2e2:	f851 cb04 	ldr.w	ip, [r1], #4
    f2e6:	f846 cf04 	str.w	ip, [r6, #4]!
			n -= sizeof(mem_word_t);
    f2ea:	e7f2      	b.n	f2d2 <memcpy+0x30>
		*(d_byte++) = *(s_byte++);
    f2ec:	f811 4b01 	ldrb.w	r4, [r1], #1
    f2f0:	f803 4f01 	strb.w	r4, [r3, #1]!
		n--;
    f2f4:	e7dd      	b.n	f2b2 <memcpy+0x10>

0000f2f6 <memset>:

void *memset(void *buf, int c, size_t n)
{
	/* do byte-sized initialization until word-aligned or finished */

	unsigned char *d_byte = (unsigned char *)buf;
    f2f6:	4603      	mov	r3, r0
{
    f2f8:	b570      	push	{r4, r5, r6, lr}
	unsigned char c_byte = (unsigned char)c;
    f2fa:	b2c9      	uxtb	r1, r1

	while (((uintptr_t)d_byte) & (sizeof(mem_word_t) - 1)) {
    f2fc:	079c      	lsls	r4, r3, #30
    f2fe:	d110      	bne.n	f322 <memset+0x2c>
	/* do word-sized initialization as long as possible */

	mem_word_t *d_word = (mem_word_t *)d_byte;
	mem_word_t c_word = (mem_word_t)c_byte;

	c_word |= c_word << 8;
    f300:	ea41 2401 	orr.w	r4, r1, r1, lsl #8
	c_word |= c_word << 16;
    f304:	ea44 4504 	orr.w	r5, r4, r4, lsl #16
#if Z_MEM_WORD_T_WIDTH > 32
	c_word |= c_word << 32;
#endif

	while (n >= sizeof(mem_word_t)) {
    f308:	0894      	lsrs	r4, r2, #2
    f30a:	eb03 0684 	add.w	r6, r3, r4, lsl #2
    f30e:	42b3      	cmp	r3, r6
    f310:	d10d      	bne.n	f32e <memset+0x38>
    f312:	f06f 0503 	mvn.w	r5, #3
    f316:	fb05 2404 	mla	r4, r5, r4, r2
    f31a:	441c      	add	r4, r3

	/* do byte-sized initialization until finished */

	d_byte = (unsigned char *)d_word;

	while (n > 0) {
    f31c:	42a3      	cmp	r3, r4
    f31e:	d109      	bne.n	f334 <memset+0x3e>
		*(d_byte++) = c_byte;
		n--;
	}

	return buf;
}
    f320:	bd70      	pop	{r4, r5, r6, pc}
		if (n == 0) {
    f322:	2a00      	cmp	r2, #0
    f324:	d0fc      	beq.n	f320 <memset+0x2a>
		*(d_byte++) = c_byte;
    f326:	f803 1b01 	strb.w	r1, [r3], #1
		n--;
    f32a:	3a01      	subs	r2, #1
    f32c:	e7e6      	b.n	f2fc <memset+0x6>
		*(d_word++) = c_word;
    f32e:	f843 5b04 	str.w	r5, [r3], #4
		n -= sizeof(mem_word_t);
    f332:	e7ec      	b.n	f30e <memset+0x18>
		*(d_byte++) = c_byte;
    f334:	f803 1b01 	strb.w	r1, [r3], #1
		n--;
    f338:	e7f0      	b.n	f31c <memset+0x26>

0000f33a <_stdout_hook_default>:
}
    f33a:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    f33e:	4770      	bx	lr

0000f340 <gpio_nrfx_port_get_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f340:	6843      	ldr	r3, [r0, #4]
}
    f342:	2000      	movs	r0, #0
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f344:	685b      	ldr	r3, [r3, #4]
    return p_reg->IN;
    f346:	691b      	ldr	r3, [r3, #16]
	*value = nrf_gpio_port_in_read(reg);
    f348:	600b      	str	r3, [r1, #0]
}
    f34a:	4770      	bx	lr

0000f34c <gpio_nrfx_port_set_masked_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f34c:	6843      	ldr	r3, [r0, #4]
    f34e:	685b      	ldr	r3, [r3, #4]
    return p_reg->OUT;
    f350:	6858      	ldr	r0, [r3, #4]
	nrf_gpio_port_out_write(reg, value_tmp | (mask & value));
    f352:	4042      	eors	r2, r0
    f354:	400a      	ands	r2, r1
    f356:	4042      	eors	r2, r0
    p_reg->OUT = value;
    f358:	605a      	str	r2, [r3, #4]
}
    f35a:	2000      	movs	r0, #0
    f35c:	4770      	bx	lr

0000f35e <gpio_nrfx_port_set_bits_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f35e:	6843      	ldr	r3, [r0, #4]
}
    f360:	2000      	movs	r0, #0
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f362:	685b      	ldr	r3, [r3, #4]
    p_reg->OUTSET = set_mask;
    f364:	6099      	str	r1, [r3, #8]
}
    f366:	4770      	bx	lr

0000f368 <gpio_nrfx_port_clear_bits_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f368:	6843      	ldr	r3, [r0, #4]
}
    f36a:	2000      	movs	r0, #0
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f36c:	685b      	ldr	r3, [r3, #4]
    p_reg->OUTCLR = clr_mask;
    f36e:	60d9      	str	r1, [r3, #12]
}
    f370:	4770      	bx	lr

0000f372 <gpio_nrfx_port_toggle_bits>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f372:	6843      	ldr	r3, [r0, #4]
}
    f374:	2000      	movs	r0, #0
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f376:	685a      	ldr	r2, [r3, #4]
    return p_reg->OUT;
    f378:	6853      	ldr	r3, [r2, #4]
	nrf_gpio_port_out_write(reg, value ^ mask);
    f37a:	4059      	eors	r1, r3
    p_reg->OUT = value;
    f37c:	6051      	str	r1, [r2, #4]
}
    f37e:	4770      	bx	lr

0000f380 <gpio_nrfx_manage_callback>:
	return gpio_manage_callback(&get_port_data(port)->callbacks,
    f380:	68c3      	ldr	r3, [r0, #12]
{
    f382:	b530      	push	{r4, r5, lr}
Z_GENLIST_IS_EMPTY(slist)
    f384:	6858      	ldr	r0, [r3, #4]
	if (!sys_slist_is_empty(callbacks)) {
    f386:	b158      	cbz	r0, f3a0 <gpio_nrfx_manage_callback+0x20>
 * @return true if node was removed
 */
static inline bool sys_slist_find_and_remove(sys_slist_t *list,
					     sys_snode_t *node);

Z_GENLIST_FIND_AND_REMOVE(slist, snode)
    f388:	2400      	movs	r4, #0
    f38a:	4281      	cmp	r1, r0
    f38c:	d113      	bne.n	f3b6 <gpio_nrfx_manage_callback+0x36>
Z_GENLIST_REMOVE(slist, snode)
    f38e:	6808      	ldr	r0, [r1, #0]
    f390:	b95c      	cbnz	r4, f3aa <gpio_nrfx_manage_callback+0x2a>
    f392:	689c      	ldr	r4, [r3, #8]
	list->head = node;
    f394:	6058      	str	r0, [r3, #4]
Z_GENLIST_REMOVE(slist, snode)
    f396:	42a1      	cmp	r1, r4
    f398:	d100      	bne.n	f39c <gpio_nrfx_manage_callback+0x1c>
	list->tail = node;
    f39a:	6098      	str	r0, [r3, #8]
	parent->next = child;
    f39c:	2000      	movs	r0, #0
    f39e:	6008      	str	r0, [r1, #0]
	if (set) {
    f3a0:	b972      	cbnz	r2, f3c0 <gpio_nrfx_manage_callback+0x40>
	return 0;
    f3a2:	2000      	movs	r0, #0
}
    f3a4:	bd30      	pop	{r4, r5, pc}
Z_GENLIST_FIND_AND_REMOVE(slist, snode)
    f3a6:	4628      	mov	r0, r5
    f3a8:	e7ef      	b.n	f38a <gpio_nrfx_manage_callback+0xa>
	parent->next = child;
    f3aa:	6020      	str	r0, [r4, #0]
Z_GENLIST_REMOVE(slist, snode)
    f3ac:	6898      	ldr	r0, [r3, #8]
    f3ae:	4281      	cmp	r1, r0
	list->tail = node;
    f3b0:	bf08      	it	eq
    f3b2:	609c      	streq	r4, [r3, #8]
    f3b4:	e7f2      	b.n	f39c <gpio_nrfx_manage_callback+0x1c>
Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
    f3b6:	6805      	ldr	r5, [r0, #0]
	return node->next;
    f3b8:	4604      	mov	r4, r0
Z_GENLIST_FIND_AND_REMOVE(slist, snode)
    f3ba:	2d00      	cmp	r5, #0
    f3bc:	d1f3      	bne.n	f3a6 <gpio_nrfx_manage_callback+0x26>
			if (!set) {
    f3be:	b13a      	cbz	r2, f3d0 <gpio_nrfx_manage_callback+0x50>
Z_GENLIST_PREPEND(slist, snode)
    f3c0:	685a      	ldr	r2, [r3, #4]
	parent->next = child;
    f3c2:	600a      	str	r2, [r1, #0]
Z_GENLIST_PREPEND(slist, snode)
    f3c4:	6898      	ldr	r0, [r3, #8]
	list->head = node;
    f3c6:	6059      	str	r1, [r3, #4]
Z_GENLIST_PREPEND(slist, snode)
    f3c8:	2800      	cmp	r0, #0
    f3ca:	d1ea      	bne.n	f3a2 <gpio_nrfx_manage_callback+0x22>
	list->tail = node;
    f3cc:	6099      	str	r1, [r3, #8]
    f3ce:	e7e9      	b.n	f3a4 <gpio_nrfx_manage_callback+0x24>
				return -EINVAL;
    f3d0:	f06f 0015 	mvn.w	r0, #21
	return gpio_manage_callback(&get_port_data(port)->callbacks,
    f3d4:	e7e6      	b.n	f3a4 <gpio_nrfx_manage_callback+0x24>

0000f3d6 <uarte_nrfx_config_get>:
{
    f3d6:	460a      	mov	r2, r1
	*cfg = get_dev_data(dev)->uart_config;
    f3d8:	68c3      	ldr	r3, [r0, #12]
    f3da:	3304      	adds	r3, #4
    f3dc:	e893 0003 	ldmia.w	r3, {r0, r1}
    f3e0:	e882 0003 	stmia.w	r2, {r0, r1}
}
    f3e4:	2000      	movs	r0, #0
    f3e6:	4770      	bx	lr

0000f3e8 <uarte_nrfx_err_check>:
	return config->uarte_regs;
    f3e8:	6843      	ldr	r3, [r0, #4]
    f3ea:	681b      	ldr	r3, [r3, #0]
    uint32_t errsrc_mask = p_reg->ERRORSRC;
    f3ec:	f8d3 0480 	ldr.w	r0, [r3, #1152]	; 0x480
    p_reg->ERRORSRC = errsrc_mask;
    f3f0:	f8c3 0480 	str.w	r0, [r3, #1152]	; 0x480
}
    f3f4:	4770      	bx	lr

0000f3f6 <uarte_nrfx_poll_in>:
	return config->uarte_regs;
    f3f6:	6843      	ldr	r3, [r0, #4]
	const struct uarte_nrfx_data *data = get_dev_data(dev);
    f3f8:	68c2      	ldr	r2, [r0, #12]
	return config->uarte_regs;
    f3fa:	681b      	ldr	r3, [r3, #0]
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    f3fc:	f8d3 0110 	ldr.w	r0, [r3, #272]	; 0x110
	if (!nrf_uarte_event_check(uarte, NRF_UARTE_EVENT_ENDRX)) {
    f400:	b148      	cbz	r0, f416 <uarte_nrfx_poll_in+0x20>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    f402:	2000      	movs	r0, #0
	*c = data->rx_data;
    f404:	7c12      	ldrb	r2, [r2, #16]
    f406:	700a      	strb	r2, [r1, #0]
    f408:	f8c3 0110 	str.w	r0, [r3, #272]	; 0x110
    f40c:	f8d3 2110 	ldr.w	r2, [r3, #272]	; 0x110
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    f410:	2201      	movs	r2, #1
    f412:	601a      	str	r2, [r3, #0]
	return 0;
    f414:	4770      	bx	lr
		return -1;
    f416:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
}
    f41a:	4770      	bx	lr

0000f41c <uarte_nrfx_poll_out>:
{
    f41c:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
	return config->uarte_regs;
    f420:	6843      	ldr	r3, [r0, #4]
{
    f422:	f88d 1007 	strb.w	r1, [sp, #7]
	return config->uarte_regs;
    f426:	681c      	ldr	r4, [r3, #0]
	struct uarte_nrfx_data *data = get_dev_data(dev);
    f428:	68c6      	ldr	r6, [r0, #12]
	if (!k_is_in_isr()) {
    f42a:	f000 f90d 	bl	f648 <k_is_in_isr>
    f42e:	bb98      	cbnz	r0, f498 <uarte_nrfx_poll_out+0x7c>
    f430:	2564      	movs	r5, #100	; 0x64
	return __atomic_compare_exchange_n(target, &old_value, new_value,
    f432:	f04f 0801 	mov.w	r8, #1
    f436:	f106 070c 	add.w	r7, r6, #12
    f43a:	e8d7 3fef 	ldaex	r3, [r7]
    f43e:	2b00      	cmp	r3, #0
    f440:	d103      	bne.n	f44a <uarte_nrfx_poll_out+0x2e>
    f442:	e8c7 8fe2 	stlex	r2, r8, [r7]
    f446:	2a00      	cmp	r2, #0
    f448:	d1f7      	bne.n	f43a <uarte_nrfx_poll_out+0x1e>
		while (atomic_cas((atomic_t *) lock,
    f44a:	d007      	beq.n	f45c <uarte_nrfx_poll_out+0x40>
	return z_impl_k_sleep(timeout);
    f44c:	2021      	movs	r0, #33	; 0x21
    f44e:	2100      	movs	r1, #0
    f450:	3d01      	subs	r5, #1
    f452:	f7ff f8ef 	bl	e634 <z_impl_k_sleep>
			if (--safety_cnt == 0) {
    f456:	f015 05ff 	ands.w	r5, r5, #255	; 0xff
    f45a:	d1ee      	bne.n	f43a <uarte_nrfx_poll_out+0x1e>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    f45c:	2300      	movs	r3, #0
    f45e:	f8c4 3120 	str.w	r3, [r4, #288]	; 0x120
    f462:	f8d4 3120 	ldr.w	r3, [r4, #288]	; 0x120
    p_reg->TXD.PTR    = (uint32_t)p_buffer;
    f466:	f10d 0307 	add.w	r3, sp, #7
    f46a:	f8c4 3544 	str.w	r3, [r4, #1348]	; 0x544
    p_reg->TXD.MAXCNT = length;
    f46e:	2301      	movs	r3, #1
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    f470:	f44f 757a 	mov.w	r5, #1000	; 0x3e8
    p_reg->TXD.MAXCNT = length;
    f474:	f8c4 3548 	str.w	r3, [r4, #1352]	; 0x548
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    f478:	60a3      	str	r3, [r4, #8]
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    f47a:	f8d4 3120 	ldr.w	r3, [r4, #288]	; 0x120
	NRFX_WAIT_FOR(nrf_uarte_event_check(uarte, NRF_UARTE_EVENT_ENDTX),
    f47e:	b923      	cbnz	r3, f48a <uarte_nrfx_poll_out+0x6e>
    f480:	2001      	movs	r0, #1
    f482:	f000 f811 	bl	f4a8 <nrfx_busy_wait>
    f486:	3d01      	subs	r5, #1
    f488:	d1f7      	bne.n	f47a <uarte_nrfx_poll_out+0x5e>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    f48a:	2301      	movs	r3, #1
    f48c:	60e3      	str	r3, [r4, #12]
	*lock = 0;
    f48e:	2300      	movs	r3, #0
    f490:	60f3      	str	r3, [r6, #12]
}
    f492:	b002      	add	sp, #8
    f494:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
		*lock = 1;
    f498:	2301      	movs	r3, #1
    f49a:	60f3      	str	r3, [r6, #12]
    f49c:	e7de      	b.n	f45c <uarte_nrfx_poll_out+0x40>

0000f49e <k_sys_fatal_error_handler>:

extern void sys_arch_reboot(int type);

void k_sys_fatal_error_handler(unsigned int reason,
			       const z_arch_esf_t *esf)
{
    f49e:	b508      	push	{r3, lr}
	ARG_UNUSED(reason);

	LOG_PANIC();

	LOG_ERR("Resetting system");
	sys_arch_reboot(0);
    f4a0:	2000      	movs	r0, #0
    f4a2:	f7fd feab 	bl	d1fc <sys_arch_reboot>

0000f4a6 <nrfx_isr>:
#include <nrfx.h>
#include <kernel.h>

void nrfx_isr(const void *irq_handler)
{
	((nrfx_irq_handler_t)irq_handler)();
    f4a6:	4700      	bx	r0

0000f4a8 <nrfx_busy_wait>:
	z_impl_k_busy_wait(usec_to_wait);
    f4a8:	f000 b8d4 	b.w	f654 <z_impl_k_busy_wait>

0000f4ac <nrfx_clock_enable>:
{
    f4ac:	b508      	push	{r3, lr}
    priority = NRFX_CLOCK_DEFAULT_CONFIG_IRQ_PRIORITY;
#else
    #error "This code is not supposed to be compiled when neither POWER nor CLOCK is enabled."
#endif

    if (!NRFX_IRQ_IS_ENABLED(nrfx_get_irq_number(NRF_CLOCK)))
    f4ae:	2005      	movs	r0, #5
    f4b0:	f7fd fca0 	bl	cdf4 <arch_irq_is_enabled>
    f4b4:	b920      	cbnz	r0, f4c0 <nrfx_clock_enable+0x14>
}
    f4b6:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
    {
        NRFX_IRQ_PRIORITY_SET(nrfx_get_irq_number(NRF_CLOCK), priority);
        NRFX_IRQ_ENABLE(nrfx_get_irq_number(NRF_CLOCK));
    f4ba:	2005      	movs	r0, #5
    f4bc:	f7fd bc8a 	b.w	cdd4 <arch_irq_enable>
    f4c0:	bd08      	pop	{r3, pc}

0000f4c2 <z_fatal_error>:
	return 0;
#endif
}

void z_fatal_error(unsigned int reason, const z_arch_esf_t *esf)
{
    f4c2:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    f4c4:	4606      	mov	r6, r0
    f4c6:	460f      	mov	r7, r1
	__asm__ volatile(
    f4c8:	f04f 0320 	mov.w	r3, #32
    f4cc:	f3ef 8511 	mrs	r5, BASEPRI
    f4d0:	f383 8811 	msr	BASEPRI, r3
    f4d4:	f3bf 8f6f 	isb	sy
	return z_impl_k_current_get();
    f4d8:	f7ff f8cc 	bl	e674 <z_impl_k_current_get>
	LOG_ERR("Current thread: %p (%s)", thread,
		log_strdup(thread_name_get(thread)));

	z_coredump(reason, esf, thread);

	k_sys_fatal_error_handler(reason, esf);
    f4dc:	4639      	mov	r1, r7
    f4de:	4604      	mov	r4, r0
    f4e0:	4630      	mov	r0, r6
    f4e2:	f7ff ffdc 	bl	f49e <k_sys_fatal_error_handler>
	__asm__ volatile(
    f4e6:	f385 8811 	msr	BASEPRI, r5
    f4ea:	f3bf 8f6f 	isb	sy
	z_impl_k_thread_abort(thread);
    f4ee:	4620      	mov	r0, r4
#endif /*CONFIG_ARCH_HAS_NESTED_EXCEPTION_DETECTION */
	}

	arch_irq_unlock(key);
	k_thread_abort(thread);
}
    f4f0:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
    f4f4:	f7fd bea0 	b.w	d238 <z_impl_k_thread_abort>

0000f4f8 <z_sys_power_save_idle_exit>:
	z_clock_idle_exit();
    f4f8:	f7ff be76 	b.w	f1e8 <z_clock_idle_exit>

0000f4fc <z_reschedule_irqlock>:
	return arch_irq_unlocked(key) && !arch_is_in_isr();
    f4fc:	4603      	mov	r3, r0
    f4fe:	b920      	cbnz	r0, f50a <z_reschedule_irqlock+0xe>
  __ASM volatile ("MRS %0, ipsr" : "=r" (result) );
    f500:	f3ef 8205 	mrs	r2, IPSR
    f504:	b90a      	cbnz	r2, f50a <z_reschedule_irqlock+0xe>
    f506:	f7fd bc4b 	b.w	cda0 <arch_swap>
    f50a:	f383 8811 	msr	BASEPRI, r3
    f50e:	f3bf 8f6f 	isb	sy
}
    f512:	4770      	bx	lr

0000f514 <z_reschedule_unlocked>:
	__asm__ volatile(
    f514:	f04f 0320 	mov.w	r3, #32
    f518:	f3ef 8011 	mrs	r0, BASEPRI
    f51c:	f383 8811 	msr	BASEPRI, r3
    f520:	f3bf 8f6f 	isb	sy
	(void) z_reschedule_irqlock(arch_irq_lock());
    f524:	f7ff bfea 	b.w	f4fc <z_reschedule_irqlock>

0000f528 <unpend_thread_no_timeout>:
{
    f528:	b510      	push	{r4, lr}
    f52a:	4604      	mov	r4, r0
	_priq_wait_remove(&pended_on(thread)->waitq, thread);
    f52c:	4601      	mov	r1, r0
    f52e:	6880      	ldr	r0, [r0, #8]
    f530:	f7fe fdf6 	bl	e120 <z_priq_dumb_remove>
	thread->base.thread_state &= ~_THREAD_PENDING;
    f534:	7b63      	ldrb	r3, [r4, #13]
    f536:	f023 0302 	bic.w	r3, r3, #2
    f53a:	7363      	strb	r3, [r4, #13]
	thread->base.pended_on = NULL;
    f53c:	2300      	movs	r3, #0
    f53e:	60a3      	str	r3, [r4, #8]
}
    f540:	bd10      	pop	{r4, pc}

0000f542 <z_priq_dumb_best>:
	return list->head == list;
    f542:	6803      	ldr	r3, [r0, #0]
}
    f544:	4298      	cmp	r0, r3
    f546:	bf14      	ite	ne
    f548:	4618      	movne	r0, r3
    f54a:	2000      	moveq	r0, #0
    f54c:	4770      	bx	lr

0000f54e <z_ready_thread>:
{
    f54e:	b510      	push	{r4, lr}
    f550:	f04f 0320 	mov.w	r3, #32
    f554:	f3ef 8411 	mrs	r4, BASEPRI
    f558:	f383 8811 	msr	BASEPRI, r3
    f55c:	f3bf 8f6f 	isb	sy
		ready_thread(thread);
    f560:	f7fe fe34 	bl	e1cc <ready_thread>
	__asm__ volatile(
    f564:	f384 8811 	msr	BASEPRI, r4
    f568:	f3bf 8f6f 	isb	sy
}
    f56c:	bd10      	pop	{r4, pc}

0000f56e <z_thread_timeout>:
{
    f56e:	b570      	push	{r4, r5, r6, lr}
    f570:	4604      	mov	r4, r0
	__asm__ volatile(
    f572:	f04f 0320 	mov.w	r3, #32
    f576:	f3ef 8611 	mrs	r6, BASEPRI
    f57a:	f383 8811 	msr	BASEPRI, r3
    f57e:	f3bf 8f6f 	isb	sy
		if (thread->base.pended_on != NULL) {
    f582:	f850 3c10 	ldr.w	r3, [r0, #-16]
		struct k_thread *thread = CONTAINER_OF(timeout,
    f586:	f1a0 0518 	sub.w	r5, r0, #24
		if (thread->base.pended_on != NULL) {
    f58a:	b113      	cbz	r3, f592 <z_thread_timeout+0x24>
			unpend_thread_no_timeout(thread);
    f58c:	4628      	mov	r0, r5
    f58e:	f7ff ffcb 	bl	f528 <unpend_thread_no_timeout>
	thread->base.thread_state &= ~_THREAD_SUSPENDED;
    f592:	f814 3c0b 	ldrb.w	r3, [r4, #-11]
		ready_thread(thread);
    f596:	4628      	mov	r0, r5
    f598:	f023 0314 	bic.w	r3, r3, #20
    f59c:	f804 3c0b 	strb.w	r3, [r4, #-11]
    f5a0:	f7fe fe14 	bl	e1cc <ready_thread>
	__asm__ volatile(
    f5a4:	f386 8811 	msr	BASEPRI, r6
    f5a8:	f3bf 8f6f 	isb	sy
}
    f5ac:	bd70      	pop	{r4, r5, r6, pc}

0000f5ae <add_to_waitq_locked>:
{
    f5ae:	b538      	push	{r3, r4, r5, lr}
    f5b0:	4604      	mov	r4, r0
    f5b2:	460d      	mov	r5, r1
	unready_thread(thread);
    f5b4:	f7fe ff62 	bl	e47c <unready_thread>
	thread->base.thread_state |= _THREAD_PENDING;
    f5b8:	7b63      	ldrb	r3, [r4, #13]
    f5ba:	f043 0302 	orr.w	r3, r3, #2
    f5be:	7363      	strb	r3, [r4, #13]
	if (wait_q != NULL) {
    f5c0:	b17d      	cbz	r5, f5e2 <add_to_waitq_locked+0x34>
    f5c2:	682b      	ldr	r3, [r5, #0]
		thread->base.pended_on = wait_q;
    f5c4:	60a5      	str	r5, [r4, #8]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    f5c6:	429d      	cmp	r5, r3
    f5c8:	d012      	beq.n	f5f0 <add_to_waitq_locked+0x42>
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    f5ca:	b18b      	cbz	r3, f5f0 <add_to_waitq_locked+0x42>
	if (thread_1->base.prio < thread_2->base.prio) {
    f5cc:	f994 200e 	ldrsb.w	r2, [r4, #14]
    f5d0:	f993 100e 	ldrsb.w	r1, [r3, #14]
    f5d4:	4291      	cmp	r1, r2
    f5d6:	dd05      	ble.n	f5e4 <add_to_waitq_locked+0x36>
	node->prev = successor->prev;
    f5d8:	685a      	ldr	r2, [r3, #4]
	node->next = successor;
    f5da:	e9c4 3200 	strd	r3, r2, [r4]
	successor->prev->next = node;
    f5de:	6014      	str	r4, [r2, #0]
	successor->prev = node;
    f5e0:	605c      	str	r4, [r3, #4]
}
    f5e2:	bd38      	pop	{r3, r4, r5, pc}
	return (node == list->tail) ? NULL : node->next;
    f5e4:	6869      	ldr	r1, [r5, #4]
    f5e6:	428b      	cmp	r3, r1
    f5e8:	d002      	beq.n	f5f0 <add_to_waitq_locked+0x42>
    f5ea:	681b      	ldr	r3, [r3, #0]
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    f5ec:	2b00      	cmp	r3, #0
    f5ee:	d1ef      	bne.n	f5d0 <add_to_waitq_locked+0x22>
	node->prev = list->tail;
    f5f0:	686b      	ldr	r3, [r5, #4]
	node->next = list;
    f5f2:	6025      	str	r5, [r4, #0]
	node->prev = list->tail;
    f5f4:	6063      	str	r3, [r4, #4]
	list->tail->next = node;
    f5f6:	686b      	ldr	r3, [r5, #4]
    f5f8:	601c      	str	r4, [r3, #0]
	list->tail = node;
    f5fa:	606c      	str	r4, [r5, #4]
}
    f5fc:	e7f1      	b.n	f5e2 <add_to_waitq_locked+0x34>

0000f5fe <z_unpend_first_thread>:
{
    f5fe:	b538      	push	{r3, r4, r5, lr}
	__asm__ volatile(
    f600:	f04f 0320 	mov.w	r3, #32
    f604:	f3ef 8211 	mrs	r2, BASEPRI
    f608:	f383 8811 	msr	BASEPRI, r3
    f60c:	f3bf 8f6f 	isb	sy
		ret = _priq_wait_best(&wait_q->waitq);
    f610:	f7ff ff97 	bl	f542 <z_priq_dumb_best>
    f614:	4604      	mov	r4, r0
	__asm__ volatile(
    f616:	f382 8811 	msr	BASEPRI, r2
    f61a:	f3bf 8f6f 	isb	sy

static inline struct k_thread *z_unpend1_no_timeout(_wait_q_t *wait_q)
{
	struct k_thread *thread = z_find_first_thread_to_unpend(wait_q, NULL);

	if (thread != NULL) {
    f61e:	b188      	cbz	r0, f644 <z_unpend_first_thread+0x46>
	__asm__ volatile(
    f620:	f04f 0320 	mov.w	r3, #32
    f624:	f3ef 8511 	mrs	r5, BASEPRI
    f628:	f383 8811 	msr	BASEPRI, r3
    f62c:	f3bf 8f6f 	isb	sy
		unpend_thread_no_timeout(thread);
    f630:	f7ff ff7a 	bl	f528 <unpend_thread_no_timeout>
	__asm__ volatile(
    f634:	f385 8811 	msr	BASEPRI, r5
    f638:	f3bf 8f6f 	isb	sy
	return z_abort_timeout(&thread->base.timeout);
    f63c:	f104 0018 	add.w	r0, r4, #24
    f640:	f000 f80a 	bl	f658 <z_abort_timeout>
}
    f644:	4620      	mov	r0, r4
    f646:	bd38      	pop	{r3, r4, r5, pc}

0000f648 <k_is_in_isr>:
    f648:	f3ef 8005 	mrs	r0, IPSR
}
    f64c:	3000      	adds	r0, #0
    f64e:	bf18      	it	ne
    f650:	2001      	movne	r0, #1
    f652:	4770      	bx	lr

0000f654 <z_impl_k_busy_wait>:
	arch_busy_wait(usec_to_wait);
    f654:	f7fd b916 	b.w	c884 <arch_busy_wait>

0000f658 <z_abort_timeout>:
{
    f658:	b510      	push	{r4, lr}
	__asm__ volatile(
    f65a:	f04f 0220 	mov.w	r2, #32
    f65e:	f3ef 8411 	mrs	r4, BASEPRI
    f662:	f382 8811 	msr	BASEPRI, r2
    f666:	f3bf 8f6f 	isb	sy
		if (sys_dnode_is_linked(&to->node)) {
    f66a:	6803      	ldr	r3, [r0, #0]
    f66c:	b13b      	cbz	r3, f67e <z_abort_timeout+0x26>
			remove_timeout(to);
    f66e:	f7ff f8e7 	bl	e840 <remove_timeout>
			ret = 0;
    f672:	2000      	movs	r0, #0
	__asm__ volatile(
    f674:	f384 8811 	msr	BASEPRI, r4
    f678:	f3bf 8f6f 	isb	sy
}
    f67c:	bd10      	pop	{r4, pc}
	int ret = -EINVAL;
    f67e:	f06f 0015 	mvn.w	r0, #21
    f682:	e7f7      	b.n	f674 <z_abort_timeout+0x1c>

0000f684 <z_get_next_timeout_expiry>:
{
    f684:	b510      	push	{r4, lr}
	__asm__ volatile(
    f686:	f04f 0320 	mov.w	r3, #32
    f68a:	f3ef 8411 	mrs	r4, BASEPRI
    f68e:	f383 8811 	msr	BASEPRI, r3
    f692:	f3bf 8f6f 	isb	sy
		ret = next_timeout();
    f696:	f7ff f8ed 	bl	e874 <next_timeout>
	__asm__ volatile(
    f69a:	f384 8811 	msr	BASEPRI, r4
    f69e:	f3bf 8f6f 	isb	sy
}
    f6a2:	bd10      	pop	{r4, pc}

0000f6a4 <z_set_timeout_expiry>:
{
    f6a4:	b570      	push	{r4, r5, r6, lr}
    f6a6:	4604      	mov	r4, r0
    f6a8:	460e      	mov	r6, r1
	__asm__ volatile(
    f6aa:	f04f 0320 	mov.w	r3, #32
    f6ae:	f3ef 8511 	mrs	r5, BASEPRI
    f6b2:	f383 8811 	msr	BASEPRI, r3
    f6b6:	f3bf 8f6f 	isb	sy
		int next_to = next_timeout();
    f6ba:	f7ff f8db 	bl	e874 <next_timeout>
		if (!imminent && (sooner || IS_ENABLED(CONFIG_SMP))) {
    f6be:	2801      	cmp	r0, #1
    f6c0:	dd05      	ble.n	f6ce <z_set_timeout_expiry+0x2a>
    f6c2:	42a0      	cmp	r0, r4
    f6c4:	dd03      	ble.n	f6ce <z_set_timeout_expiry+0x2a>
			z_clock_set_timeout(ticks, is_idle);
    f6c6:	4631      	mov	r1, r6
    f6c8:	4620      	mov	r0, r4
    f6ca:	f7fd fae9 	bl	cca0 <z_clock_set_timeout>
	__asm__ volatile(
    f6ce:	f385 8811 	msr	BASEPRI, r5
    f6d2:	f3bf 8f6f 	isb	sy
}
    f6d6:	bd70      	pop	{r4, r5, r6, pc}

0000f6d8 <z_tick_get_32>:

uint32_t z_tick_get_32(void)
{
    f6d8:	b508      	push	{r3, lr}
#ifdef CONFIG_TICKLESS_KERNEL
	return (uint32_t)z_tick_get();
    f6da:	f7ff f9e9 	bl	eab0 <z_tick_get>
#else
	return (uint32_t)curr_tick;
#endif
}
    f6de:	bd08      	pop	{r3, pc}

0000f6e0 <k_heap_init>:
{
    f6e0:	b410      	push	{r4}
    f6e2:	f100 040c 	add.w	r4, r0, #12
	list->tail = (sys_dnode_t *)list;
    f6e6:	e9c0 4403 	strd	r4, r4, [r0, #12]
}
    f6ea:	bc10      	pop	{r4}
	sys_heap_init(&h->heap, mem, bytes);
    f6ec:	f7ff bc90 	b.w	f010 <sys_heap_init>

0000f6f0 <_OffsetAbsSyms>:
#include "offsets_aarch64.c"
#else
#include "offsets_aarch32.c"
#endif

GEN_ABS_SYM_END
    f6f0:	4770      	bx	lr
